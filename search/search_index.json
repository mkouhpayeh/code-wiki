{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to my Coding Journey Documentation, a comprehensive and evolving collection of my experiences, challenges, and insights as a developer. This site is designed to document and share the lessons I've learned, solutions I've discovered, and the best practices I've adopted along the way.</p>"},{"location":"#about-this-documentation","title":"\ud83c\udf1f About This Documentation","text":"<p>This project serves as a central hub for: - Coding Tips &amp; Tricks: Practical guidance for writing better, cleaner, and more efficient code. - Challenges &amp; Solutions: Real-world problems I encountered and the creative solutions I implemented. - Best Practices: Industry-standard practices for coding, debugging, and collaborating. - Technical Notes: Useful notes and resources for tools, frameworks, and programming languages. </p>"},{"location":"#what-youll-find-here","title":"\ud83d\udcda What You\u2019ll Find Here","text":"<p>Here\u2019s an overview of what this site offers:</p>"},{"location":"#guides-and-tutorials","title":"\ud83d\udcd6 Guides and Tutorials","text":"<p>Step-by-step guides to help you understand complex concepts and implement them effectively.</p>"},{"location":"#tips-and-insights","title":"\ud83d\udca1 Tips and Insights","text":"<p>Quick and actionable tips to improve your workflow and coding skills.</p>"},{"location":"#tools-and-technologies","title":"\ud83d\udee0\ufe0f Tools and Technologies","text":"<p>In-depth notes and best practices for popular tools and frameworks: - Languages: C#, JavaScript, SQL, Markdown and more. - Tools: Git, Docker, VisualStudio, and others. - Frameworks: .NET, .NET Core etc.  </p>"},{"location":"#get-started","title":"\ud83d\ude80 Get Started","text":"<ul> <li>Explore the Docs: Use the navigation on the left to browse topics.  </li> <li>Search: Use the search bar to quickly find the information you need.  </li> <li>Tags: Navigate by tags to discover related topics and resources.  </li> </ul>"},{"location":"#why-this-exists","title":"\u2728 Why This Exists","text":"<p>The purpose of this documentation is to:  </p> <ul> <li>Learn Continuously: Keep track of my growth as a developer.  </li> <li>Share Knowledge: Provide a resource for others in their learning journey.  </li> <li>Solve Problems: Document challenges and solutions for future reference.  </li> </ul>"},{"location":"#stay-connected","title":"\ud83d\udceb Stay Connected","text":"<p>Feel free to reach out or contribute: - Email: mhb.kouhpayeh[at]gmail.com - GitHub: code-wiki</p>"},{"location":"assets/mkdocs/","title":"mkdocs Materials","text":"<p>Material for MkDocs</p>"},{"location":"assets/mkdocs/#add-note","title":"Add note","text":"<pre><code>!!! note \"CAUTION!\"\n\n    xxx\n    xxx\n</code></pre>"},{"location":"assets/windows-cmd/","title":"Windows Command","text":""},{"location":"assets/windows-cmd/#copy-files","title":"Copy files","text":"<pre><code>robocopy \"C:\\SourceFolder\" \"Z:\\DestinationFolder\" /E /Z /MT:32 /R:1 /W:1\n</code></pre> <p>Options <code>/E</code> \u2192 Copy subfolders, including empty ones. <code>/Z</code> \u2192 Restartable mode (resumes if interrupted). <code>/MT:32</code> \u2192 Multi-threaded copy (32 threads; up to 128). <code>/R:1</code> \u2192 Retry 1 time on copy failure. <code>/W:1</code> \u2192 Wait 1 second between retries. <code>/LOG:file.txt</code> \u2192 Write operation log to <code>file.txt</code>. <code>/MIR</code> \u2192 Mirror source to destination (WARNING: can delete files at destination).</p> <p>Notes - Use an elevated command prompt (Run as Administrator) if you encounter permission errors. - For large transfers consider increasing <code>/MT</code> but monitor CPU and disk I/O. - When using network drives, map them first or use UNC paths (<code>\\\\server\\share</code>).</p>"},{"location":"assets/windows-cmd/#get-pid-find-running-process","title":"Get PID / Find running process","text":"<pre><code>tasklist /fi \"IMAGENAME eq AsyncTest.exe\"\n</code></pre> <p>Tip To get more details including the PID, use: <pre><code>tasklist /v /fi \"IMAGENAME eq AsyncTest.exe\"\n</code></pre> Or filter by window title or username: <pre><code>tasklist /fi \"WINDOWTITLE eq MyApp*\" /fi \"USERNAME eq DOMAIN\\User\"\n</code></pre></p>"},{"location":"assets/windows-cmd/#tls-protocol","title":"TLS protocol","text":""},{"location":"assets/windows-cmd/#showset-tls","title":"Show/Set TLS","text":"<pre><code># Show current value\n[Net.ServicePointManager]::SecurityProtocol\n\n# Force .NET to use TLS 1.2 only\n[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12\n</code></pre>"},{"location":"assets/windows-cmd/#check-enabled-protocol","title":"Check Enabled Protocol","text":"<p>SSL Test </p> <p>nartac</p>"},{"location":"assets/windows-cmd/#check-cipher-suites","title":"Check Cipher Suites","text":"<pre><code>Get-TlsCipherSuite\n</code></pre>"},{"location":"automation/ansible-intro/","title":"Ansible","text":"<p>Written in Python. The Ansible controller requires Python. Ansible follows the principle of idempotence \u2014 you can run automation repeatedly and it only makes changes when necessary. Ansible uses the Jinja2 templating engine for variable replacement, loops, conditionals, and data manipulation.</p>"},{"location":"automation/ansible-intro/#keywords","title":"Keywords","text":"<ul> <li> <p>Community   The easiest way for most admins to run Ansible. It contains Ansible binaries and many commonly used components packaged and ready to go.</p> </li> <li> <p>Core   A minimal distribution containing only essential components. Developers or admins who want a lightweight install use this; additional components may be required to automate most hosts.</p> </li> <li> <p>Navigator   Builds on top of Ansible Core by allowing executions inside containers called Execution Environments (EEs).</p> </li> <li> <p>Container   A portable unit bundling code, runtime, libraries, and dependencies to run an application consistently across environments.</p> </li> <li> <p>API   Application Programming Interface.</p> </li> <li> <p>Playbooks   Scripts consumed by the Ansible binary to perform automation.</p> <ul> <li>A playbook tells each play where to run and what to do.</li> <li>A playbook can contain multiple plays (different sets of hosts).</li> <li>The <code>name</code> field is optional but highly recommended \u2014 it documents intent and appears in output.</li> </ul> </li> <li> <p>Tasks   Ordered list of discrete automation steps executed in sequence. By default Ansible completes the first task for all hosts before moving to the next.</p> </li> <li> <p>Module   A piece of code (usually Python or PowerShell) that performs an automation action.</p> </li> <li> <p>Collection   An archive (tar) that installs modules, roles, plugins, playbooks, docs, and other objects. Use the Fully Qualified Collection Name (FQCN) to reference modules.</p> </li> <li> <p>Inventory   A list of hosts you can operate against. Think of the inventory as a menu \u2014 the <code>hosts</code> declaration in a playbook is the specific order you pick from that menu. Inventories are typically stored as INI or YAML files.</p> </li> <li> <p>YAML   Defines layout and structure \u2014 indentation matters:</p> <ul> <li>Use spaces, not tabs.</li> <li>Tabs will break playbooks.</li> <li>Two spaces is a common indentation rule.</li> <li>Many mistakes are due to incorrect spacing.</li> </ul> </li> <li> <p>Variables   Important for flexibility and fact gathering. Ansible has many precedence levels (22 levels). Use variables as <code>{{ variable_name }}</code>.</p> </li> <li> <p>AWX   A web UI and job controller for Ansible. AWX provides:</p> <ul> <li>Role-based access control (RBAC)</li> <li>A GUI and REST API</li> <li>Job logging and execution control</li> </ul> </li> <li> <p>Python Virtual Environment (PVE)   Lets you manage different Python package versions per environment. When managing many dependencies, consider Execution Environments and Ansible Navigator instead.</p> </li> </ul>"},{"location":"automation/ansible-intro/#installation","title":"Installation","text":"<pre><code># Install Python (Fedora/RHEL example)\nsudo dnf install -y python3\n\n# Install pip\nsudo dnf install -y python3-pip\n\n# Install Ansible\npip install ansible\n\n# Update Ansible\npip install --upgrade ansible\n\n# Verify\nansible --version\n</code></pre> <p>If you have SSH issues from macOS hosts, you may need Paramiko: <pre><code>pip install paramiko\n</code></pre></p>"},{"location":"automation/ansible-intro/#commands","title":"Commands","text":"<ul> <li><code>pwd</code> \u2014 Present Working Directory  </li> <li><code>ls</code> \u2014 List files  </li> <li><code>clear</code> \u2014 Clear terminal  </li> <li><code>--ask-pass</code> \u2014 Prompt for SSH password  </li> <li><code>--ask-become-pass</code> \u2014 Prompt for privilege escalation (become) password</li> </ul>"},{"location":"automation/ansible-intro/#examples","title":"Examples","text":"<ol> <li>Gather facts and display them <pre><code>---\n- name: Gather facts and display them\n  hosts: LL-Test\n  tasks:\n    - name: Display all gathered facts\n      ansible.builtin.debug:\n        var: ansible_facts\n\n    - name: Display the currently running kernel version and distro\n      ansible.builtin.debug:\n        msg: \"The kernel version is {{ ansible_facts.kernel }} and the distribution is {{ ansible_facts.distribution }}\"\n</code></pre> Run: <pre><code>ansible-playbook -i inventory gather-facts.yml\n</code></pre></li> </ol> <ol> <li>Quick webserver install and config <pre><code>---\n- name: Quick webserver install and config\n  hosts: LL-Test\n  gather_facts: false\n  become: true\n  tasks:\n    - name: Install apache webserver\n      ansible.builtin.package:\n        name: httpd\n        state: present\n\n    - name: Start and enable apache\n      ansible.builtin.service:\n        name: httpd\n        state: started\n        enabled: true\n\n    - name: Write a simple index.html file\n      ansible.builtin.lineinfile:\n        path: /var/www/html/index.html\n        line: \"&lt;h1&gt;Hello world!&lt;/h1&gt;\"\n        create: true\n</code></pre> Run: <pre><code>ansible-playbook -i inventory webserver.yml\n# then test with:\ncurl http://127.0.0.1\n</code></pre></li> </ol> <ol> <li>Vars, conditionals and loops <pre><code>---\n- name: Vars, conditionals and loops\n  hosts: LL-Test\n  gather_facts: false\n  vars:\n    nums:\n      - 1\n      - 10\n      - 20\n      - 25\n      - 30\n  tasks:\n    - name: Display any numbers larger than 10\n      ansible.builtin.debug:\n        msg: \"{{ item }}\"\n      loop: \"{{ nums }}\"\n      when: item &gt; 10\n</code></pre></li> </ol>"},{"location":"automation/ansible-intro/#idempotence-output","title":"Idempotence output","text":"<ul> <li>OK \u2014 Task completed successfully and no change was needed.  </li> <li>Changed \u2014 Task completed and made a change on the host.  </li> <li>Failed \u2014 Task failed for this host (error details are shown).  </li> <li>Skipping \u2014 Condition not met, so task was skipped.</li> </ul>"},{"location":"automation/ansible-intro/#installing-collections","title":"Installing Collections","text":"<ol> <li>Install a collection: <pre><code>ansible-galaxy collection install &lt;namespace.collection_name&gt;\n</code></pre></li> <li>Check repository <code>requirements.txt</code> for Python dependencies. If a <code>requirements.txt</code> URL is provided, you can install its Python deps: <pre><code>pip install -r &lt;requirements.txt-raw-url&gt;\n</code></pre></li> </ol>"},{"location":"automation/ansible-playbook/","title":"Ansible Playbook","text":"<p>An Ansible playbook is a YAML file that defines a set of tasks to automate configuration and management of one or more hosts.</p>"},{"location":"automation/ansible-playbook/#linux-hosts","title":"Linux Hosts","text":"ansible.cfg<pre><code>[defaults]\n# disable SSH key host checking\nhost_key_checking = False\n\n# smart - gather by default, but don't regather if already gathered\ngathering = smart\n</code></pre> inventory (put in the same directory as playbooks)<pre><code>[rocky9]  # group name\nLL-rocky9-01 ansible_host=10.0.50.43 new_user=test1\n\n[rocky9:vars]\nansible_user=ansible\nansible_ssh_pass=gregsowell\nansible_become_pass=gregsowell\n\n[windows]\nwindows-01 ansible_host=10.0.50.31\n\n[windows:vars]\nansible_connection=winrm\nansible_winrm_scheme=http\nansible_port=5985\nansible_winrm_transport=ntlm\nansible_user=administrator\nansible_become_method=runas\nansible_become_user=administrator\n\n[nexus]\nsw1 ansible_host=10.0.50.27\n\n[nexus:vars]\nansible_connection=ansible.netcommon.network_cli\nansible_network_os=cisco.nxos.nxos\nansible_user=admin\nansible_ssh_pass=lab\nansible_become_pass=lab\n</code></pre> <p>variables.yml<pre><code>---\n- name: A simple playbook to add users to the host\n  hosts: LL-Test\n  gather_facts: false\n  vars_files:\n    - files/users.yml\n  vars:\n    # new_user = test1\n  tasks:\n    - name: Add user to the host\n      ansible.builtin.user:\n        # use variable stored in inventory: LL-Test new_user=test1\n        name: \"{{ hostvars[inventory_hostname].new_user }}\"\n        state: present\n      become: true\n</code></pre> Run: <pre><code>ansible-playbook -i inventory -e \"new_user=test1\" variables.yml\n</code></pre></p> loop.yml<pre><code>---\n- name: A simple playbook to add users to the host\n  hosts: LL-Test\n  gather_facts: false\n  vars:\n    new_user:\n      - test1\n      - test2\n      - test3\n  tasks:\n    - name: Add user to the host\n      ansible.builtin.user:\n        name: \"{{ item }}\"\n        state: present\n      become: true\n      loop: \"{{ new_user }}\"\n</code></pre> conditions.yml<pre><code>---\n- name: A simple playbook to add users to the host\n  hosts: LL-Test\n  gather_facts: false\n  vars_files:\n    - files/users.yml\n  vars:\n    ignore_users:\n      - root\n      - test1\n    new_user:\n      - test1\n      - test2\n      - test3\n  tasks:\n    - name: Add user to the host (skip ignored)\n      when: item not in (ignore_users | default([]))\n      ansible.builtin.user:\n        name: \"{{ item }}\"\n        state: present\n      become: true\n      loop: \"{{ new_user }}\"\n</code></pre> blocks.yml<pre><code>---\n- name: Add nginx webserver to hosts\n  hosts: LL-Test\n  become: true\n  tasks:\n    - name: Block for Rocky hosts\n      when: \"'Rocky' in ansible_facts['distribution'] | default('')\"\n      block:\n        - name: Install nginx webserver\n          ansible.builtin.dnf:\n            name: nginx\n            state: present\n        - name: Start and enable nginx service\n          ansible.builtin.systemd:\n            name: nginx\n            enabled: yes\n            state: started\n\n    - name: Block for Ubuntu hosts\n      when: \"'Ubuntu' in ansible_facts['distribution'] | default('')\"\n      block:\n        - name: Install nginx webserver\n          ansible.builtin.apt:\n            name: nginx\n            state: present\n        - name: Start and enable nginx service\n          ansible.builtin.systemd:\n            name: nginx\n            enabled: yes\n            state: started\n</code></pre> <p>Block sections</p> <ul> <li>always: runs after the block's tasks complete. It runs even if some tasks failed.</li> <li>rescue: runs only if a failure occurred inside the block.</li> <li>You cannot loop over a block. You can loop over tasks inside the block, but not the whole block.</li> </ul> templates.yml<pre><code>---\n- name: Add nginx webserver and templates\n  hosts: LL-Test\n  become: true\n  vars:\n    owner_name: Test\n    web_path: /home/webserver\n  tasks:\n    - name: Install nginx on Rocky\n      when: \"'Rocky' in ansible_facts['distribution'] | default('')\"\n      block:\n        - name: Install nginx webserver\n          ansible.builtin.dnf:\n            name: nginx\n            state: present\n        - name: Start and enable nginx service\n          ansible.builtin.systemd:\n            name: nginx\n            enabled: yes\n            state: started\n\n    - name: Create web directory\n      ansible.builtin.file:\n        path: \"{{ web_path }}\"\n        state: directory\n        owner: nginx\n        group: nginx\n        mode: '0755'\n\n    - name: Add index.html to webserver directory\n      ansible.builtin.template:\n        src: templates/index.html.j2  # Save HTML with .j2 and use variables like {{ owner_name }}\n        dest: \"{{ web_path }}/index.html\"\n        owner: nginx\n        group: nginx\n        mode: '0644'\n\n    - name: Add nginx config based on template\n      ansible.builtin.template:\n        src: templates/nginx.conf.j2\n        dest: /etc/nginx/nginx.conf\n        owner: nginx\n        group: nginx\n        mode: '0644'\n      register: nginx_config\n\n    - name: Restart nginx service when config changed\n      when: nginx_config.changed\n      ansible.builtin.service:\n        name: nginx\n        state: restarted\n</code></pre> <p>Template plugin <pre><code>- name: Display template plugin\n  ansible.builtin.debug:\n    msg: \"{{ lookup('ansible.builtin.template', './display-template.j2') }}\"\n</code></pre></p> <p>Handlers</p> <p>Handlers run once at the end of a play if notified by tasks that changed.</p> handlers.yml<pre><code>---\n- name: Add nginx webserver to hosts (with handlers)\n  hosts: LL-Test\n  become: true\n  vars:\n    owner_name: Test\n    web_path: /home/webserver\n  tasks:\n    - name: Create nginx config from template\n      ansible.builtin.template:\n        src: templates/nginx.conf.j2\n        dest: /etc/nginx/nginx.conf\n      register: nginx_config\n      notify: Restart nginx\n\n  handlers:\n    - name: Restart nginx\n      ansible.builtin.service:\n        name: nginx\n        state: restarted\n</code></pre> <p>Tags</p> <p>Tags mark tasks so you can run subsets of a playbook:</p> <p>tags.yml<pre><code>---\n- name: Add nginx webserver to hosts (tags example)\n  hosts: LL-Test\n  become: true\n  vars:\n    owner_name: Test\n    web_path: /home/webserver\n  tasks:\n    - name: Install nginx on Rocky\n      when: \"'Rocky' in ansible_facts['distribution'] | default('')\"\n      block:\n        - name: Install nginx webserver\n          ansible.builtin.dnf:\n            name: nginx\n            state: present\n      tags: ['install']\n\n    - name: Configure web directory\n      ansible.builtin.file:\n        path: \"{{ web_path }}\"\n        state: directory\n      tags: ['configure']\n</code></pre> Run: <pre><code>ansible-playbook -i inventory tags.yml --tags \"install\"\nansible-playbook -i inventory tags.yml --skip-tags \"configure\"\n</code></pre></p> <p>Execution modes</p> <ul> <li>run: normal execution (changes applied).</li> <li>check: dry-run \u2014 simulates changes. Note: some tasks do not support check mode.</li> <li>To force specific tasks to run even in check mode, add <code>check_mode: false</code> at task level.</li> </ul> assert.yml<pre><code>---\n- name: Check RAM on a Rocky host\n  hosts: LL-Test\n  tasks:\n    - name: Display ansible_memtotal_mb\n      ansible.builtin.debug:\n        var: ansible_memtotal_mb\n\n    - name: Assert if RAM is at least 10GB\n      ansible.builtin.assert:\n        that:\n          - ansible_memtotal_mb &gt; 10000\n        fail_msg: \"RAM is less than 10GB\"\n</code></pre> <p>Task-level control - <code>changed_when: false</code> - <code>failed_when: false</code></p> <p>Nested loop</p> <p>For complex nested loops prefer splitting logic into task includes or role tasks.</p> <p>Dynamic inventory</p> <p>A dynamic inventory script generates inventory data from external sources (ServiceNow, vCenter, AWS, etc.).</p> dynamic-inventory.yml<pre><code>---\n- name: Dynamic Inventory\n  hosts: all\n  gather_facts: true\n  tasks:\n    - name: Print out the list of inventory hosts\n      ansible.builtin.debug:\n        var: groups['all']\n      run_once: true\n</code></pre> custom_inventory.py<pre><code>#!/usr/bin/env python\nimport json\n# Read JSON payload from file\nwith open('files/json-payload.json', 'r') as file:\n    json_payload = file.read()\n\ninventory_data = json.loads(json_payload)\nansible_inventory = {\n    '_meta': {'hostvars': {}},\n    'all': {'hosts': [], 'vars': {}}\n}\nos_groups = {}\nlocation_groups = {}\n\nfor host in inventory_data['hosts']:\n    hostname = host['hostname']\n    ip_address = host['ip_address']\n    os_name = host['os']\n    location = host['location']\n    owner = host['owner']\n\n    ansible_inventory['all']['hosts'].append(hostname)\n    ansible_inventory['_meta']['hostvars'][hostname] = {\n        'ansible_host': ip_address,\n        'status': host['status'],\n        'os': os_name,\n        'location': location,\n        'owner': owner\n    }\n\n    os_groups.setdefault(os_name, {'hosts': []})['hosts'].append(hostname)\n    location_groups.setdefault(location, {'hosts': []})['hosts'].append(hostname)\n\nansible_inventory.update(os_groups)\nansible_inventory.update(location_groups)\n\nprint(json.dumps(ansible_inventory, indent=4))\n</code></pre> <p>json-payload.json<pre><code>{\n  \"hosts\": [\n    { \"id\": 1, \"hostname\": \"host1.example.com\", \"ip_address\": \"192.168.1.101\", \"status\": \"active\", \"os\": \"Linux\", \"location\": \"dal-dc1\", \"owner\": \"Admin User\" },\n    { \"id\": 2, \"hostname\": \"host2.example.com\", \"ip_address\": \"192.168.1.102\", \"status\": \"inactive\", \"os\": \"Windows\", \"location\": \"dal-dc1\", \"owner\": \"User 1\" }\n  ]\n}\n</code></pre> Run: <pre><code>ansible-playbook -i files/custom_inventory.py dynamic-inventory.yml\n</code></pre></p> <p>Sample play</p> test.yml<pre><code>---\n- name: Test play\n  hosts: LL-rocky9-01\n  vars:\n    new_dirs:\n      - /tmp/test10\n      - /tmp/test11\n      - /tmp/test12\n      - /tmp/test13\n  tasks:\n    - name: Assert that the system has enough memory\n      ansible.builtin.assert:\n        that: ansible_memtotal_mb &gt; 1000\n        fail_msg: \"The system does not have enough memory &lt; 1GB\"\n        success_msg: \"The system has enough memory &gt; 1GB\"\n\n    - name: Create directories based on new_dirs variable\n      ansible.builtin.file:\n        path: \"{{ item }}\"\n        state: directory\n      loop: \"{{ new_dirs }}\"\n\n    - name: Create a file with specific content idempotently if there is a 3 in the dir name\n      ansible.builtin.copy:\n        dest: \"{{ item }}/file.txt\"\n        content: \"This is the content of the file\"\n      when: \"'3' in item\"\n      loop: \"{{ new_dirs }}\"\n\n    - name: Collect the contents of the new_dirs\n      ansible.builtin.shell: \"ls -l {{ item }}\"\n      loop: \"{{ new_dirs }}\"\n      register: ls_output\n      changed_when: false\n\n    - name: Display the contents of the new_dirs\n      when: item.stdout | length &gt; 8\n      ansible.builtin.debug:\n        var: item.stdout\n      loop: \"{{ ls_output.results }}\"\n</code></pre>"},{"location":"automation/ansible-playbook/#roles","title":"Roles","text":"<p>Roles abstract reusable parts of a playbook (like functions). Roles live in a <code>roles/</code> directory and follow a specific layout. Create a role with:</p> <pre><code>ansible-galaxy init nginx\n</code></pre> <p>Example role files:</p> roles/nginx/defaults/main.yml<pre><code>---\nowner_name: Greg Sowell\nweb_path: /home/webserver\n</code></pre> roles/nginx/handlers/main.yml<pre><code>---\n- name: Restart nginx\n  ansible.builtin.service:\n    name: nginx\n    state: restarted\n</code></pre> roles/nginx/tasks/main.yml<pre><code>---\n- name: Block for rocky hosts\n  when: \"'Rocky' in ansible_facts['distribution'] | default('')\"\n  block:\n    - name: Install nginx webserver\n      ansible.builtin.dnf:\n        name: nginx\n        state: present\n    - name: Start and enable nginx service\n      ansible.builtin.systemd:\n        name: nginx\n        enabled: yes\n        state: started\n\n- name: Create /home/webserver directory\n  ansible.builtin.file:\n    path: \"{{ web_path }}\"\n    state: directory\n    owner: nginx\n    group: nginx\n    mode: '0755'\n\n- name: Add nginx config based on template\n  ansible.builtin.template:\n    src: templates/nginx.conf.j2\n    dest: /etc/nginx/nginx.conf\n  register: nginx_config\n  notify: Restart nginx\n</code></pre> <p>Run role via playbook:</p> <p>nginx-role.yml<pre><code>- name: Add/Configure nginx webserver via Roles\n  hosts: LL-rocky9-01\n  become: true\n  roles:\n    - nginx\n</code></pre> Run: <pre><code>ansible-playbook -i inventory nginx-role.yml\n</code></pre></p> <p>Role search path 1. Local <code>roles/</code> directory (relative to playbook) 2. <code>ANSIBLE_ROLES_PATH</code> environment variable 3. <code>roles_path</code> in <code>ansible.cfg</code> 4. System-wide <code>/etc/ansible/roles</code> 5. Hidden Ansible Galaxy directory</p> <p>Acquire roles - Git clone - Ansible Galaxy: <code>ansible-galaxy install &lt;role_name&gt;</code> - Use a requirements file: <code>ansible-galaxy install -r requirements.yml</code></p>"},{"location":"automation/ansible-playbook/#secrets-vault","title":"Secrets (Vault)","text":"<p>Encrypt secrets with Ansible Vault. Decrypt them at runtime with a vault password or vault ID.</p> files/secrets.yml<pre><code>---\nsuper_secret: Greg\n</code></pre> <pre><code>ansible-vault encrypt files/secrets.yml\nansible-vault decrypt files/secrets.yml\n</code></pre> <p>vault.yml<pre><code>---\n- name: Vaulting example\n  hosts: LL-rocky9-01\n  gather_facts: false\n  become: true\n  vars_files:\n    - files/secrets.yml  # Encrypted file\n  tasks:\n    - name: Display the super_secret variable\n      ansible.builtin.debug:\n        var: super_secret\n</code></pre> Run: <pre><code>ansible-playbook -i inventory vault.yml --ask-vault-pass\n</code></pre></p>"},{"location":"automation/ansible-playbook/#windows-hosts","title":"Windows Hosts","text":"<ul> <li>Connections via WinRM</li> <li>Patch management (WSUS, Intune, etc.)</li> <li>Configuration and app deployment (Active Directory tasks, security policies, PowerShell integration)</li> </ul> <p>windows.yml<pre><code>---\n- name: Perform windows updates\n  hosts: windows-01\n  gather_facts: false\n  vars_prompt:\n    - name: \"ansible_ssh_pass\"\n      prompt: Windows password\n      private: true\n  tasks:\n    - name: Update the windows server\n      ansible.windows.win_updates:\n        category_names:\n          - CriticalUpdates\n        state: searched\n      register: update_output\n</code></pre> Run: <pre><code>ansible-playbook -i inventory windows.yml\n</code></pre></p>"},{"location":"automation/ansible-playbook/#network-hosts","title":"Network Hosts","text":"network.yml<pre><code>---\n- name: SNMP updates on a Cisco device\n  hosts: sw1\n  gather_facts: false\n  vars:\n    parse_me: |\n      snmp-server user admin auth md5 0xe2bb3e2405ce601c5c3993262270ace5 priv 0xe2bb3e2405ce601c5c3993262270ace5 localizedkey engineID 128:0:0:9:3:0:80:86:135:240:25\n      snmp-server community private group network-admin\n      snmp-server community public group network-operator\n  tasks:\n    - name: Find current SNMP configuration\n      cisco.nxos.nxos_command:\n        commands: show run | inc snmp-ser\n      register: snmp_output\n\n    - name: Display current SNMP configuration\n      ansible.builtin.debug:\n        var: snmp_output.stdout_lines\n\n    - name: Configure SNMP with the config module\n      cisco.nxos.nxos_config:\n        lines:\n          - snmp-server community public\n          - snmp-server community private\n</code></pre> <p>Notes - You can replace parsed configs with resource modules where supported. - Store desired CLI in files and apply via automation to keep changes auditable.</p>"},{"location":"automation/ansible-playbook/#apis","title":"APIs","text":"<p>Use the <code>uri</code> module to interact with HTTP APIs.</p> api.yml<pre><code>- name: Fetch current weather data\n  hosts: localhost\n  gather_facts: false\n  tasks:\n    - name: Get weather data for College Station, Texas\n      ansible.builtin.uri:\n        url: \"https://api.weather.gov/points/30.6280,-96.3344\"\n        method: GET\n        validate_certs: yes\n      register: weather_response\n\n    - name: Get detailed forecast data\n      ansible.builtin.uri:\n        url: \"{{ weather_response.json.properties.forecast }}\"\n        method: GET\n        validate_certs: true\n      register: forecast_response\n\n    - name: Display detailed forecast data\n      ansible.builtin.debug:\n        var: forecast_response.json\n</code></pre>"},{"location":"automation/ci-cd-github/","title":"CI/CD GitHub","text":"<p>CI/CD is a set of practices and automation that let teams integrate code frequently, build and test artifacts automatically, and deploy them to environments reliably.</p>"},{"location":"automation/ci-cd-github/#overview","title":"Overview","text":"<ul> <li>Continuous Integration (CI): Developers frequently merge code into a shared repository. Each merge (or push) triggers automated checks such as linting, static analysis, and unit tests so problems are discovered early.</li> <li>Continuous Delivery (CD - delivery): After successful CI, code is packaged into a build artifact (a package or container image). Additional higher-level tests (integration, acceptance) run and the artifact is stored in a registry so it\u2019s always ready to be released.</li> <li>Continuous Deployment (CD - deployment): Builds that pass all automated checks are deployed automatically to production without human intervention. This requires strong test coverage and a robust pipeline of validations.</li> </ul> <p>CI/CD Concepts</p> <ul> <li>Workflow \u2014 YAML file that defines automation (triggers, jobs).</li> <li>Event / Trigger \u2014 What starts a workflow (push, pull_request, schedule, workflow_call).</li> <li>Runner \u2014 The compute environment where jobs run (Ubuntu, Windows, macOS).</li> <li>Job \u2014 A group of steps run on a runner.</li> <li>Step \u2014 A single command, script, or action executed inside a job.</li> <li>Action \u2014 A reusable unit (Docker container or JavaScript) to perform a task.</li> <li>Matrix strategy \u2014 Runs the same job multiple times with different parameter values (e.g., different OS or language versions).</li> </ul>"},{"location":"automation/ci-cd-github/#typical-process","title":"Typical process","text":"<ul> <li> <p>Developer pushes code to repository \u2192 workflow triggered.</p> </li> <li> <p>CI workflow:</p> <ul> <li>Lint / static analysis</li> <li>Unit tests</li> <li>Build verification</li> </ul> </li> <li> <p>Delivery workflow:</p> <ul> <li>Build artifact (package/container image)</li> <li>Run integration/acceptance tests</li> <li>Publish to a registry (artifact repository)</li> </ul> </li> <li> <p>Deployment workflow:</p> <ul> <li>Retrieve artifact from registry</li> <li>Deploy to target environment (staging \u2192 production)</li> <li>Optional rollout strategies (canary, blue/green)</li> </ul> </li> </ul> <p>Notes: - Triggering can be per push, on tags, on releases, or on branch events depending on release policy. - Permissions must be configured for workflows that read/write registries (e.g., GitHub Packages) \u2014 e.g., <code>packages: write</code>.</p>"},{"location":"automation/ci-cd-github/#artifacts-registries","title":"Artifacts &amp; Registries","text":"<ul> <li> <p>Artifacts are the output of a build (packages, container images, etc.).</p> </li> <li> <p>Package formats / registries by ecosystem:</p> <ul> <li>Java \u2192 JAR/Gradle/Maven (registry: Maven Central or private Nexus/Artifactory)</li> <li>JavaScript \u2192 npm (registry: npm or GitHub Packages)</li> <li>.NET \u2192 NuGet (registry: nuget.org or private feed)</li> <li>Docker \u2192 container image (registry: Docker Hub, GitHub Container Registry, ECR)</li> </ul> </li> <li> <p>Best practice: Bump the package version on each release so each published artifact has a unique version.</p> </li> <li> <p>Common steps when publishing packages</p> <ol> <li>Authenticate with the registry (handled by build steps).</li> <li>Build the package/artifact.</li> <li>Publish the package to the target registry.</li> <li>Ensure configuration files refer to the correct registry and version (e.g., <code>pom.xml</code>, <code>package.json</code>, <code>.csproj</code>, <code>Dockerfile</code>).</li> </ol> </li> </ul>"},{"location":"automation/ci-cd-github/#reusable-workflows","title":"Reusable workflows","text":"<p>To make a workflow callable from another workflow:</p> <pre><code># .github/workflows/ci.yml\non:\n  workflow_call:\n    inputs:\n      build-type:\n        required: false\n        type: string\n</code></pre> <p>Call it from another repo:</p> <pre><code>jobs:\n  integration:\n    uses: usernme/repoName/.github/workflows/ci.yml@main\n    with:\n      build-type: \"full\"\n    permissions:\n      contents: read\n\n  build:\n    needs: [integration]\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n      # ...\n</code></pre>"},{"location":"automation/ci-cd-github/#deploying-environments-protections","title":"Deploying: Environments &amp; protections","text":"<ul> <li>Use environments to represent targets: <code>staging</code>, <code>production</code>, etc.</li> <li>Reference an environment in a job:</li> </ul> <pre><code>jobs:\n  deploy:\n    runs-on: ubuntu-latest\n    environment: production\n    steps:\n      - uses: actions/checkout@v4\n      - name: Deploy\n        run: ./deploy.sh\n</code></pre> <ul> <li>Protection rules: environments can enforce branch filters and required reviewers before deployments proceed.</li> <li>Variables &amp; secrets: can be scoped at repo or environment level. Use secrets for credentials:</li> </ul> <pre><code>- name: Configure AWS Credentials\n  uses: aws-actions/configure-aws-credentials@v2\n  with:\n    aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n    aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n    aws-region: ${{ vars.AWS_REGION }}\n</code></pre> <ul> <li>Concurrency: prevent conflicting deployments by grouping:</li> </ul> <pre><code>concurrency:\n  group: deploy-production\n  cancel-in-progress: false\n</code></pre> <p>Or per-job concurrency:</p> <pre><code>jobs:\n  deploy_staging:\n    environment: Staging\n    concurrency:\n      group: deploy-staging\n      cancel-in-progress: true\n</code></pre>"},{"location":"automation/ci-cd-github/#recommended-practices","title":"Recommended practices","text":"<ul> <li>Keep CI fast: split quick checks (lint, unit tests) from long-running tests (integration).</li> <li>Fail early: run lightweight validation first so more expensive steps only run on passing builds.</li> <li>Version artifacts reliably (semantic versioning where possible).</li> <li>Use immutable artifacts (tag images with commit SHA and version).</li> <li>Keep secrets out of logs and secure them in the platform\u2019s secret store.</li> <li>Make workflows reusable and parameterizable with <code>workflow_call</code> and inputs.</li> <li>Monitor pipelines and add alerts on failed deployments or repeated flakiness.</li> </ul>"},{"location":"automation/ci-cd-github/#github-pages","title":"GitHub Pages","text":"<ul> <li> <p>Build</p> <ul> <li> <p>Jeykyll is the default static site generator for GitHub Pages. The starter workflow is provided.</p> </li> <li> <p>There are other popular static site generators but for these tools, we would create a custom workflow, with actions that run the selected site generator instead of Jekyll. </p> <ul> <li>Hugo</li> <li>Gatsby </li> </ul> </li> </ul> </li> <li> <p>Deploy</p> <ul> <li> <p>The deployment job transfers the artifact to the GitHub Pages service, where it can be accessed using a dedicated URL on the github.io domain (http(s)://.github.io/). Sites deployed to GitHub Pages can also be configured to use a custom domain.  <li> <p>Configure a workflow for GitHub Pages. Settings &gt; Unser Code and Automating &gt; Pages &gt; Change source to GitHub Actions &gt; With .md file, choose the Github Pages Jekyll</p> </li> <p>Two common approaches to publish a static site with GitHub Pages using GitHub Actions:</p> <p>A. Official Pages workflow \u2014 upload artifact + deploy (recommended when you want to use GitHub Pages as the publishing platform and leverage the Pages API). This is the modern, supported flow using <code>actions/upload-pages-artifact</code> and <code>actions/deploy-pages</code>.</p> <p>How it works (overview) 1. Build your static site into a directory (for example <code>./public</code> or <code>./site</code>). 2. Upload the build output as a Pages artifact using <code>actions/upload-pages-artifact@v1</code>. 3. Deploy the uploaded artifact to GitHub Pages using <code>actions/deploy-pages@v1</code>.</p> <p>Example: generic static-site workflow <pre><code>name: Publish site\non:\n  push:\n    branches: [ main ]\n\npermissions:\n  contents: read\n  pages: write\n  id-token: write\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Node.js (if your site uses Node)\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n\n      - name: Install dependencies and build\n        run: |\n          npm ci\n          npm run build   # produces ./public or ./dist\n\n      - name: Upload Pages artifact\n        uses: actions/upload-pages-artifact@v1\n        with:\n          path: ./public\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    steps:\n      - name: Deploy to GitHub Pages\n        uses: actions/deploy-pages@v1\n</code></pre></p> <p>Notes &amp; tips for the official flow - Make sure <code>path</code> points to the directory containing the static files (html, css, js). The upload step packages them for deployment. If your SSG produces a different folder (e.g., <code>public</code>, <code>dist</code>, <code>site</code>), set <code>path</code> accordingly. - The artifact must be a gzip-compressed tar under 10 GB and must not contain symlinks. The upload action handles packaging automatically. - The <code>pages: write</code> permission is required for the deploy job. - You can keep build and deploy in the same job but splitting them (build job + deploy job) provides clearer logs and separation of concerns. - For Jekyll specifically (see below) you may prefer to let GitHub handle Jekyll builds \u2014 but if you need custom plugins or Ruby gems, build in Actions and use the artifact flow to publish the resulting <code>_site</code> directory.</p> <p>B. Deploy-to-branch flow (peaceiris / gh-pages branch) \u2014 push built static files to the <code>gh-pages</code> branch (commonly used before the official actions existed and still popular for simple setups). Use <code>peaceiris/actions-gh-pages</code> or a deploy key for authenticated push. This method creates/updates the publishing branch (e.g., <code>gh-pages</code>) and GitHub Pages serves the content from that branch.</p> <p>Example: push to <code>gh-pages</code> using peaceiris action <pre><code>name: Deploy to gh-pages\non:\n  push:\n    branches: [ main ]\n\njobs:\n  build-and-deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Build static site\n        run: |\n          npm ci\n          npm run build   # produces ./public\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v4\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./public\n</code></pre></p> <p>Notes for deploy-to-branch - <code>peaceiris/actions-gh-pages</code> supports using a deploy key (<code>deploy_key</code>) if you prefer not to use the repo <code>GITHUB_TOKEN</code> for pushes. - This flow will create commits on the <code>gh-pages</code> branch (or another branch you configure) and GitHub Pages can be set to use that branch as the publishing source.</p> <ul> <li> <p>Jekyll (GitHub's built-in) vs building in Actions</p> <ul> <li>GitHub Pages automatically builds Jekyll sites if you enable Pages and have an appropriate <code>_config.yml</code>. That is convenient but limited: GitHub Pages only allows a vetted set of plugins and an older Ruby/Jekyll toolchain.</li> <li>If you need custom Jekyll plugins or a newer toolchain, build the site in Actions (e.g., <code>bundle install</code> + <code>bundle exec jekyll build</code>) and use the artifact/deploy flow to publish the resulting <code>_site</code> directory.</li> </ul> </li> <li> <p>Custom domain &amp; HTTPS</p> <ul> <li>Add a <code>CNAME</code> file to the root of the published site (or configure the custom domain in repository \u2192 Settings \u2192 Pages). The <code>CNAME</code> file must contain only the domain name (e.g., <code>docs.example.com</code>).</li> <li>Configure DNS: create an <code>A</code> record pointing to GitHub Pages IP addresses (if apex/root domain) and/or a <code>CNAME</code> pointing to <code>&lt;username&gt;.github.io</code> for subdomains. GitHub docs list the exact IPs and recommended records.</li> <li>After adding a custom domain, enable Enforce HTTPS in Pages settings once the DNS and TLS provisioning completes (ACME provisioning is automatic for supported domains).</li> <li>If you use a custom certificate or external CDN, follow GitHub Pages docs for advanced configurations.</li> </ul> </li> <li> <p>Useful tips &amp; gotchas</p> <ul> <li>If your site contains files or folders that start with an underscore (e.g., <code>_assets</code>) and you do not use Jekyll, include a <code>.nojekyll</code> file in the published root to prevent GitHub from running Jekyll processing.</li> <li>For MkDocs, Hugo, or other SSGs, build in Actions (recommended) and publish the output directory.</li> <li>For private repositories, GitHub Pages can publish from Actions; ensure the workflow has correct <code>pages: write</code> permission. Using <code>GITHUB_TOKEN</code> or deploy keys works \u2014 check the action docs for authentication options.</li> <li>To speed up deployments, avoid committing build artifacts to the default branch; build in Actions and deploy artifacts to Pages or <code>gh-pages</code> branch.</li> <li>Monitor the Actions run logs and the Pages deploy history (Settings \u2192 Pages \u2192 Deployment history) to debug failures.</li> </ul> </li> </ul>"},{"location":"automation/ci-cd-github/#service-accounts","title":"Service accounts","text":"<ul> <li> <p>Service accounts provide a secure way for our deployment workflows to interact with services outside of GitHub.</p> </li> <li> <p>Used to manage credentials and permissions</p> </li> <li> <p>Not associated with specific users</p> </li> <li> <p>Permissions are limited to specific tasks</p> </li> <li> <p>Credential types:</p> <ul> <li>Username and password</li> <li>API key</li> <li>Certificate</li> </ul> </li> <li> <p>Store credentials in environment secrets</p> </li> <li> <p>Configure workflows to access and use secrets</p> </li> </ul>"},{"location":"automation/ci-cd-github/#terraform","title":"Terraform","text":"<p>Terraform is a widely adopted open-source tool for working with infrastructure as code. When we run Terraform, a report is generated called the Terraform plan. The plan describes any changes that need to be made to produce the desired state according to the configuration in the repo. We can use command-line tools, like awk and sed, to modify the Terraform plan into a report using Markdown styling. Then we can write the report to GITHUB_STEP_SUMMARY so the plan can be quickly and easily viewed before it gets applied.  - We need to update the permissions on the service account. We should add the AmazonS3FullAccess permission. Terraform will use the service account credentials to read and write state files to an S3 bucket. We need also to create a bucket to hold the Terraform state files. </p>"},{"location":"automation/ci-cd-gitlab/","title":"CI/CD GitLab","text":"<ul> <li> <p>CI/CD pipelines are the fundamental component of GitLab CI/CD. Pipelines are configured in a \".gitlab-ci.yml\" file by using YAML keywords.</p> </li> <li> <p>Pipelines can run automatically for specific events, like when pushing to a branch, creating a merge request, or on a schedule. When needed, you can also run pipelines manually.</p> </li> <li> <p>You can add CI/CD variables to a project\u2019s settings. Projects can have a maximum of 8000 CI/CD variables.</p> <ul> <li>Key: Must be one line, with no spaces, using only letters, numbers, or _.</li> <li>Value: The value is limited to 10,000 characters, but also bounded by any limits in the runner\u2019s operating system. The value has extra limitations if Visibility is set to Masked or Masked and hidden.</li> <li>Type: Variable (default) or File.</li> <li>Environment scope: Optional. All (default) (*), a specific environment, or a wildcard environment scope.</li> <li>Protect variable: Optional. If selected, the variable is only available in pipelines that run on protected branches or tags.</li> <li>Visibility: Select Visible (default), Masked, or Masked and hidden.</li> <li>Expand variable reference: Optional. If selected, the variable can reference another variable. It is not possible to reference another variable if Visibility is set to Masked or Masked and hidden.</li> </ul> </li> <li> <p>Runners are the agents that run the GitLab Runner application, to execute GitLab CI/CD jobs in a pipeline. They are responsible for running your builds, tests, deployments, and other CI/CD tasks defined in .gitlab-ci.yml files.</p> </li> </ul>"},{"location":"automation/ci-cd-gitlab/#deploy-net-web-in-iis-winrm","title":"Deploy .Net Web in IIS (WinRM)","text":"<p>Run test if available on main branche and deploy project manually on IIS when any changes applied to the production branch.</p> <ol> <li> <p>One-time IIS server prep. Do these on the remote server:</p> <ul> <li> <p>Install .NET Hosting Bundle (match your target, e.g. .NET 9). Reboot if the installer asks.</p> </li> <li> <p>Create the site folder</p> </li> </ul> <pre><code>New-Item -ItemType Directory -Force -Path \"C:\\inetpub\\wwwroot\\Hello-World\"\n</code></pre> <ul> <li>Create a deploy user (least-privilege)</li> </ul> <pre><code>New-LocalUser -Name \"gitlab_deploy\" -Password (Read-Host -AsSecureString \"Password\") -FullName \"GitLab Deploy User\" -PasswordNeverExpires\nAdd-LocalGroupMember -Group \"Remote Management Users\" -Member \"gitlab_deploy\"\n# File write permission on the site folder:\n$acl = Get-Acl \"C:\\inetpub\\wwwroot\\Hello-World\"\n$rule = New-Object System.Security.AccessControl.FileSystemAccessRule(\"gitlab_deploy\",\"Modify\",\"ContainerInherit, ObjectInherit\",\"None\",\"Allow\")\n$acl.AddAccessRule($rule)\nSet-Acl \"C:\\inetpub\\wwwroot\\Hello-World\" $acl\n</code></pre> <pre><code>Add-LocalGroupMember -Group \"IIS_IUSRS\" -Member \"gitlab_deploy\"\n</code></pre> <ul> <li>Enable WinRM + HTTPS listener (port 5986)</li> </ul> <pre><code># Enable WinRM\nEnable-PSRemoting -Force\n\n# Create a self-signed cert for WinRM HTTPS\n$cert = New-SelfSignedCertificate -DnsName \"ServerName\" -CertStoreLocation \"Cert:\\LocalMachine\\My\"\n\n# Create HTTPS listener using that cert\n$thumb = $cert.Thumbprint\nwinrm create winrm/config/Listener?Address=*+Transport=HTTPS \"@{Hostname=`\"ServerName`\"; CertificateThumbprint=`\"$thumb`\"}\"\n\n# Open firewall\nNew-NetFirewallRule -DisplayName \"WinRM HTTPS (5986)\" -Direction Inbound -Protocol TCP -LocalPort 5986 -Action Allow\n</code></pre> <ul> <li>Verify:</li> </ul> <pre><code>winrm enumerate winrm/config/Listener\nTest-NetConnection -ComputerName ServerName -Port 5986\n</code></pre> </li> <li> <p>On the Windows GitLab Runner machine (not the IIS server) We need a Windows runner somewhere that can reach ServerName:5986:</p> <ul> <li> <p>Install &amp; register GitLab Runner (executor = shell), tag it windows.</p> </li> <li> <p>Allow connecting to self-signed/hostname-mismatch (we\u2019ll pass flags in the script). (No global TrustedHosts needed because we use HTTPS + skip checks.)</p> </li> </ul> <pre><code>$sec = ConvertTo-SecureString \"YourStrongPassword!\" -AsPlainText -Force\n$cred = New-Object pscredential (\"ServerName\\gitlab_deploy\", $sec)\n$so = New-PSSessionOption -SkipCACheck -SkipCNCheck\nNew-PSSession -ComputerName ServerName -UseSSL -Credential $cred -SessionOption $so\n# If you get a session object (not an error), you\u2019re good. Then:\nGet-PSSession | Remove-PSSession\n</code></pre> </li> <li> <p>Create CI file \".gitlab-ci.yml\" in the project root</p> <pre><code>stages: [build, test, package]\n\n# ---------- CI (build/test/publish) ----------\nimage: mcr.microsoft.com/dotnet/sdk:9.0\n\nvariables:\n  DOTNET_CLI_TELEMETRY_OPTOUT: \"1\"\n  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: \"1\"\n  CONFIGURATION: \"Release\"\n\ncache:\n  key: \"nuget\"\n  paths:\n    - .nuget/packages\n\nbuild:\n  stage: build\n  script:\n    - dotnet --info\n    - dotnet restore\n    - dotnet build -c $CONFIGURATION\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"main\"'\n    - if: '$CI_COMMIT_BRANCH == \"production\"'\n\ntest:\n  stage: test\n  script:\n    - if [ -d \"tests\" ]; then dotnet test --no-build -c $CONFIGURATION; else echo \"No tests found, skipping.\"; fi\n  needs: [build]\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"main\"'\n\npackage:\n  stage: package\n  script:\n    # publish to a fixed folder that we artifact\n    - dotnet publish Hello-World.csproj -c $CONFIGURATION -o publish\n  needs: [build]\n  artifacts:\n    paths:\n      - publish/**          \n      - scripts/**\n    expire_in: 7 days\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"production\"'\n  when: on_success\n</code></pre> </li> <li> <p>Register Runner</p> <ul> <li>Download Runner</li> <li> <p>Register Runner to the Gitlab project</p> <ul> <li>Settings &gt; CI/CD &gt; Runner &gt; Tag: windows</li> </ul> <pre><code>.\\gitlab-runner.exe register  --url https://gitlab-URL  --token xxxxxxxxxxxxxx\n# enter the URL\n# enter the name\n# enter executer: shell\n# edit the config.toml =&gt; shell = \"powershell\"\n</code></pre> <p><pre><code>.\\gitlab-runner.exe run\n</code></pre>     - The runner service will run as gitlab-runner user</p> <ul> <li> <p>Make sure that user has write permission to the IIS site folder (e.g. C:\\inetpub\\wwwroot\\HelloWorld).</p> </li> <li> <p>Make sure the IIS server already has the .NET 9 Hosting Bundle installed.</p> </li> </ul> </li> </ul> </li> <li> <p>Add deploy script to the repo     Create folder scripts/ and add Deploy-IIS-RemoteWinRM.ps1:     <pre><code>param(\n  [Parameter(Mandatory=$true)][string]$PackageDir,          # local publish dir (from artifacts)\n  [Parameter(Mandatory=$true)][string]$ComputerName,        # ServerName\n  [Parameter(Mandatory=$true)][string]$SitePath,            # e.g. C:\\inetpub\\wwwroot\\Hello-World\n  [Parameter(Mandatory=$false)][string]$AppPool,            # optional, e.g. 'HelloWorldPool'\n  [Parameter(Mandatory=$true)][string]$Username,            # e.g. ServerName\\gitlab_deploy\n  [Parameter(Mandatory=$true)][string]$Password\n)\n\n$ErrorActionPreference = 'Stop'\n\n# Prepare credentials &amp; session\n$sec = ConvertTo-SecureString $Password -AsPlainText -Force\n$cred = New-Object System.Management.Automation.PSCredential ($Username, $sec)\n$so = New-PSSessionOption -SkipCACheck -SkipCNCheck\n\n# Create a zip of the publish folder\n$zip = Join-Path $env:TEMP (\"app_\" + [guid]::NewGuid().Guid + \".zip\")\nAdd-Type -AssemblyName System.IO.Compression.FileSystem\nif (Test-Path $zip) { Remove-Item $zip -Force }\n[System.IO.Compression.ZipFile]::CreateFromDirectory($PackageDir, $zip)\n\n# Open remote session over WinRM HTTPS\n$session = New-PSSession -ComputerName $ComputerName -UseSSL -Credential $cred -SessionOption $so\ntry {\n  $remoteTemp = Invoke-Command -Session $session -ScriptBlock {\n    $p = Join-Path $env:TEMP (\"deploy_\" + [guid]::NewGuid().Guid)\n    New-Item -ItemType Directory -Path $p -Force | Out-Null\n    $p\n  }\n\n  # Copy zip to remote\n  Copy-Item -Path $zip -Destination (Join-Path $remoteTemp \"app.zip\") -ToSession $session\n\n  # Remote unpack + mirror + recycle app pool\n  Invoke-Command -Session $session -ScriptBlock {\n    param($zipPath, $targetPath, $appPool)\n    $ErrorActionPreference = 'Stop'\n\n    if (!(Test-Path $targetPath)) { New-Item -ItemType Directory -Force -Path $targetPath | Out-Null }\n\n    # Take app offline to avoid lock issues\n    $offline = Join-Path $targetPath 'app_offline.htm'\n    '&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h3&gt;Updating\u2026&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;' | Out-File -Encoding utf8 $offline\n\n    if ($appPool) {\n      Import-Module WebAdministration\n      if (Test-Path \"IIS:\\AppPools\\$appPool\") { Stop-WebAppPool -Name $appPool }\n    }\n\n    Add-Type -AssemblyName System.IO.Compression.FileSystem\n    $tmpExtract = Join-Path $env:TEMP (\"extract_\" + [guid]::NewGuid().Guid)\n    New-Item -ItemType Directory -Force -Path $tmpExtract | Out-Null\n    [System.IO.Compression.ZipFile]::ExtractToDirectory($zipPath, $tmpExtract)\n\n    # Mirror files (fast &amp; resilient)\n    $rc = robocopy $tmpExtract $targetPath /MIR /NFL /NDL /NP /R:2 /W:2\n    if ($LASTEXITCODE -ge 8) { throw \"Robocopy failed with code $LASTEXITCODE\" }\n\n    Remove-Item $offline -ErrorAction SilentlyContinue\n\n    if ($appPool) { Start-WebAppPool -Name $appPool }\n\n    Remove-Item $tmpExtract -Recurse -Force\n    Remove-Item $zipPath -Force\n  } -ArgumentList (Join-Path $remoteTemp \"app.zip\"), $SitePath, $AppPool\n\n} finally {\n  if ($session) { Remove-PSSession $session }\n  if (Test-Path $zip) { Remove-Item $zip -Force }\n}\n\nWrite-Host \"Remote deploy complete.\"\n</code></pre></p> </li> <li> <p>Add protected CI/CD variables in GitLab</p> <ul> <li> <p>Project \u2192 Settings \u2192 CI/CD \u2192 Variables (mask &amp; protect where appropriate):</p> <ul> <li> <p>PROD_SERVER = ServerName (or 192.168.35.15)</p> </li> <li> <p>PROD_USER = ServerName\\gitlab_deploy</p> </li> <li> <p>PROD_PASSWORD = (the password you set)</p> </li> <li> <p>IIS_SITE_PATH = C:\\inetpub\\wwwroot\\Hello-World</p> </li> <li> <p>(Optional) IIS_APPPOOL = your app pool name if you want to stop/start it</p> </li> </ul> </li> <li> <p>Mark them Protected so they\u2019re only available to the production branch.</p> </li> </ul> </li> <li> <p>Extend the .gitlab-ci.yml with the deploy job (replace it):</p> <pre><code>stages: [build, test, package, deploy]\n\nimage: mcr.microsoft.com/dotnet/sdk:9.0\n\nvariables:\n  DOTNET_CLI_TELEMETRY_OPTOUT: \"1\"\n  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: \"1\"\n  CONFIGURATION: \"Release\"\n\ncache:\n  key: \"nuget\"\n  paths:\n    - .nuget/packages\n\n# 1\ufe0f\u20e3 Build\nbuild:\n  stage: build\n  script:\n    - dotnet restore\n    - dotnet build -c $CONFIGURATION\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"main\"'\n    - if: '$CI_COMMIT_BRANCH == \"production\"'\n\n# 2\ufe0f\u20e3 Test\ntest:\n  stage: test\n  script:\n    - if [ -d \"tests\" ]; then dotnet test --no-build -c $CONFIGURATION; else echo \"No tests found, skipping.\"; fi\n  needs: [build]\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"main\"'\n\n# 3\ufe0f\u20e3 Package\npackage:\n  stage: package\n  script:\n    - dotnet publish Hello-World.csproj -c $CONFIGURATION -o publish\n  needs: [build]\n  artifacts:\n    paths:\n      - publish/**\n      - scripts/**\n    expire_in: 7 days\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"production\"'\n\n# 4\ufe0f\u20e3 Deploy via WinRM\ndeploy_prod_remote_winrm:\n  stage: deploy\n  tags: [\"windows\"]          # runner tag that can run PowerShell + has WinRM access\n  needs: [\"package\"]\n  variables:\n    GIT_STRATEGY: none\n  script:\n    - powershell -NoProfile -ExecutionPolicy Bypass -File \"scripts\\Deploy-IIS-RemoteWinRM.ps1\" `\n        -PackageDir \"$env:CI_PROJECT_DIR\\publish\" `\n        -ComputerName \"$env:PROD_SERVER\" `\n        -SitePath \"$env:IIS_SITE_PATH\" `\n        -AppPool \"$env:IIS_APPPOOL\" `\n        -Username \"$env:PROD_USER\" `\n        -Password \"$env:PROD_PASSWORD\"\n  environment:\n    name: production\n    url: http://$env:PROD_SERVER/\n  when: manual\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"production\"'\n</code></pre> </li> <li> <p>Protect the production path (optional but recommended)</p> <ul> <li> <p>Protect production branch: Settings \u2192 Repository \u2192 Protected Branches.</p> </li> <li> <p>Environment approvals: Deployments \u2192 Environments \u2192 production \u2192 Protect, add at least one approver.</p> </li> </ul> </li> <li> <p>Test the full flow</p> <ul> <li> <p>Push to production branch (your pipeline will run build \u2192 package \u2192 deploy).</p> </li> <li> <p>In Pipelines, click \u201cPlay\u201d on deploy_prod_remote_winrm.</p> </li> <li> <p>Watch the logs \u2014 it should:</p> <ul> <li> <p>Zip publish/</p> </li> <li> <p>Open WinRM session to ws2019dggweb</p> </li> <li> <p>Copy zip \u2192 extract \u2192 mirror into C:\\inetpub\\wwwroot\\Hello-World</p> </li> <li> <p>(Optionally) stop/start the app pool</p> </li> </ul> </li> <li> <p>Browse to http://ws2019dggweb/ (or the site binding you use) and verify the app.</p> </li> </ul> </li> </ol>"},{"location":"automation/ci-cd-gitlab/#deploy-net-web-in-iis","title":"Deploy .Net Web in IIS","text":"<p>Runner installed on the IIS Server</p> <ol> <li> <p>Prereqs (one-time on the IIS server)</p> <ul> <li> <p>Install .NET Hosting Bundle (match your target, e.g. .NET 9). Reboot if the installer asks.</p> </li> <li> <p>Create the site folder</p> </li> </ul> <pre><code>New-Item -ItemType Directory -Force -Path \"C:\\inetpub\\wwwroot\\Hello-World\"\n</code></pre> <ul> <li>(Optional) App Pool     In IIS Manager create an App Pool, e.g. HelloWorldPool (No Managed Code, Integrated).</li> </ul> </li> <li> <p>Install GitLab Runner on the IIS server (Windows)</p> <pre><code># choose a folder, e.g.:\nmkdir C:\\gitlab-runner\ncd C:\\gitlab-runner\n\n# download runner (if you haven't)\n# (Or copy gitlab-runner.exe here)\n\n# install as a Windows service\n.\\gitlab-runner.exe install\n.\\gitlab-runner.exe start\n</code></pre> <ul> <li> <p>Register the runner (project-scoped)</p> <ul> <li> <p>Get the registration token from your project: Project \u2192 Settings \u2192 CI/CD \u2192 Runners \u2192 \u201cNew project runner\u201d</p> </li> <li> <p>Then register:</p> </li> </ul> <pre><code>  .\\gitlab-runner.exe register `\n  --url https://&lt;your-gitlab-host&gt;/ `\n  --registration-token &lt;PROJECT_TOKEN&gt; `\n  --executor shell `\n  --shell powershell `\n  --description \"IIS Local Runner\" `\n  --tag-list \"windows,iis-local\" `\n  --non-interactive\n</code></pre> <p>The tags you set here (e.g., iis-local) are what you\u2019ll use in the deploy job.</p> <ul> <li> <p>Adjust runner config (recommended): Open C:\\gitlab-runner\\config.toml and ensure:</p> </li> <li> <p>Then restart:</p> </li> </ul> <pre><code>cd C:\\gitlab-runner\n.\\gitlab-runner.exe stop\n.\\gitlab-runner.exe start\n.\\gitlab-runner.exe verify\n</code></pre> <ul> <li> <p>Service account permissions: The Windows service gitlab-runner runs under Local System by default. That\u2019s usually enough to write to C:\\inetpub\\wwwroot\\Hello-World and control IIS. If you run it under a custom account, give that account:</p> </li> <li> <p>Modify on C:\\inetpub\\wwwroot\\Hello-World</p> </li> <li> <p>Membership in IIS_IUSRS (to start/stop app pool), or grant that right via policy.</p> </li> </ul> </li> </ul> </li> <li> <p>GitLab CI/CD variables (project \u2192 Settings \u2192 CI/CD \u2192 Variables)</p> <ul> <li> <p>Create these (no secrets here, so Masked = OFF; set Protected = ON if branch is protected):</p> <ul> <li> <p>IIS_SITE_PATH = C:\\inetpub\\wwwroot\\Hello-World</p> </li> <li> <p>IIS_APPPOOL = HelloWorldPool (optional; blank if you don\u2019t recycle)     (You do not need PROD_SERVER, PROD_USER, PROD_PASSWORD anymore.)</p> </li> </ul> </li> </ul> </li> <li> <p>Add the local deploy script to your repo</p> <ul> <li>Create scripts/Deploy-IIS-Local.ps1:</li> </ul> <pre><code>param(\n  [Parameter(Mandatory=$true)][string]$PackageDir,   # local publish folder (artifact)\n  [Parameter(Mandatory=$true)][string]$SitePath,     # e.g. C:\\inetpub\\wwwroot\\Hello-World\n  [Parameter(Mandatory=$false)][string]$AppPool      # optional: HelloWorldPool\n)\n\n$ErrorActionPreference = 'Stop'\nWrite-Host \"== Local IIS deploy ==\"\nWrite-Host \"PackageDir: $PackageDir\"\nWrite-Host \"SitePath  : $SitePath\"\nif ($AppPool) { Write-Host \"AppPool   : $AppPool\" }\n\nif (!(Test-Path $PackageDir)) { throw \"PackageDir not found: $PackageDir\" }\n$srcCount = (Get-ChildItem -Recurse -Force $PackageDir | Where-Object { -not $_.PSIsContainer }).Count\nif ($srcCount -eq 0) { throw \"PackageDir is empty.\" }\n\n# Take site offline to avoid file locks\n$offline = Join-Path $SitePath 'app_offline.htm'\n'&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h3&gt;Updating\u2026&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;' | Out-File -Encoding utf8 $offline\n\n# Stop app pool if provided\nif ($AppPool) {\n  Import-Module WebAdministration\n  if (Test-Path \"IIS:\\AppPools\\$AppPool\") {\n    Write-Host \"Stopping AppPool: $AppPool\"\n    Stop-WebAppPool -Name $AppPool\n  } else {\n    Write-Warning \"AppPool $AppPool not found.\"\n  }\n}\n\n# Ensure target exists\nif (!(Test-Path $SitePath)) { New-Item -ItemType Directory -Force -Path $SitePath | Out-Null }\n\n# Mirror files (fast &amp; resilient)\n$before = (Get-ChildItem -Recurse -Force $SitePath | Where-Object { -not $_.PSIsContainer }).Count\n$rc = robocopy $PackageDir $SitePath /MIR /NFL /NDL /NP /R:2 /W:2\nif ($LASTEXITCODE -ge 8) { throw \"Robocopy failed with code $LASTEXITCODE\" }\n$after = (Get-ChildItem -Recurse -Force $SitePath | Where-Object { -not $_.PSIsContainer }).Count\n\nRemove-Item $offline -ErrorAction SilentlyContinue\n\nif ($AppPool) {\n  Write-Host \"Starting AppPool: $AppPool\"\n  Start-WebAppPool -Name $AppPool\n}\n\nWrite-Host \"Files before: $before; after: $after\"\nWrite-Host \"Deploy complete.\"\n</code></pre> </li> <li> <p>Update .gitlab-ci.yml</p> <ul> <li>Keep your working build/test/package jobs. Add a local deploy job that uses the IIS server\u2019s runner tag (e.g., iis-local) and no WinRM.</li> </ul> <pre><code>stages: [build, test, package, deploy]\n\nimage: mcr.microsoft.com/dotnet/sdk:9.0\n\nvariables:\n  DOTNET_CLI_TELEMETRY_OPTOUT: \"1\"\n  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: \"1\"\n  CONFIGURATION: \"Release\"\n\ncache:\n  key: \"nuget\"\n  paths:\n    - .nuget/packages\n\nbuild:\n  stage: build\n  script:\n    - dotnet --info\n    - dotnet restore\n    - dotnet build -c $CONFIGURATION\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"main\"'\n    - if: '$CI_COMMIT_BRANCH == \"production\"'\n\ntest:\n  stage: test\n  script:\n    - if [ -d \"tests\" ]; then dotnet test --no-build -c $CONFIGURATION; else echo \"No tests found, skipping.\"; fi\n  needs: [build]\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"main\"'\n\npackage:\n  stage: package\n  script:\n    - dotnet publish Hello-World.csproj -c $CONFIGURATION -o publish  # replace the name of project\n  needs: [build]\n  artifacts:\n    paths:\n      - publish/**\n      - scripts/**                   # include the deploy script for simplicity\n    expire_in: 7 days\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"production\"'\n\ndeploy_prod_local:\n  stage: deploy\n  tags: [\"iis-local\"]               # &lt;-- tag of the Runner installed on IIS\n  variables:\n    GIT_STRATEGY: none              # only need artifacts, not source checkout\n  needs: [package]\n  script:\n  - powershell -NoProfile -ExecutionPolicy Bypass -File \"scripts\\Deploy-IIS-Local.ps1\" `\n    -PackageDir \"$env:CI_PROJECT_DIR\\publish\" `\n    -SitePath \"$env:IIS_SITE_PATH\" `\n    -AppPool \"$env:IIS_APPPOOL\"\n  environment:\n    name: production\n    url: http://&lt;your-site-binding&gt;/\n  when: manual                      # manual confirmation\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"production\"'\n</code></pre> <p>If your runner tag is just windows, change tags: [\"iis-local\"] to tags: [\"windows\"].</p> </li> <li> <p>Protect the production path (recommended)</p> <ul> <li> <p>Protect branch: Settings \u2192 Repository \u2192 Protected branches \u2192 protect production.</p> </li> <li> <p>Runner Protected: set the runner to Protected = ON (so it only runs on protected branches).</p> </li> <li> <p>Variables Protected: set IIS_SITE_PATH and IIS_APPPOOL to Protected = ON.</p> </li> </ul> </li> <li> <p>Deploy flow</p> <ul> <li> <p>Push to <code>production</code> branch.</p> </li> <li> <p>Pipeline runs <code>build</code> \u2192 <code>package</code>.</p> </li> <li> <p>Click Play on <code>deploy_prod_local</code>.</p> </li> <li> <p>The job runs on the IIS server itself, copies <code>publish/**</code> into <code>C:\\inetpub\\wwwroot\\Hello-World</code>, writes <code>app_offline.htm</code>, mirrors files, removes it, (optionally) recycles the app pool.</p> </li> <li> <p>Browse the site.</p> </li> </ul> </li> <li> <p>Quick verification &amp; common fixes</p> <ul> <li> <p>Job can\u2019t start \u2192 runner tag mismatch or protection mismatch. Fix tags, Protected toggles.</p> </li> <li> <p>Access denied \u2192 run the runner service as Local System (default) or grant your custom account Modify on the site folder and ability to manage IIS.</p> </li> <li> <p>Site locked during copy \u2192 <code>app_offline.htm</code> already included; ensure no antivirus is holding locks.</p> </li> <li> <p>Wrong csproj path \u2192 adjust <code>dotnet publish</code> path in <code>package</code> job.</p> </li> <li> <p>Artifacts missing \u2192 check that <code>package</code> uploaded <code>publish/**</code> and <code>deploy</code> has <code>needs: [package]</code>.</p> </li> <li> <p>Get the real error (enable stdout logs) \u2192  In the deployed site folder (same level as your .dll), open <code>web.config</code> and temporarily <code>enable ANCM stdout logs</code>: </p> <pre><code>&lt;aspNetCore processPath=\"dotnet\" arguments=\".\\YourApp.dll\" stdoutLogEnabled=\"true\" stdoutLogFile=\".\\logs\\stdout\" hostingModel=\"inprocess\" /&gt;\n</code></pre> </li> </ul> </li> </ol>"},{"location":"automation/ci-cd-gitlab/#add-notifications","title":"Add notifications","text":"<ol> <li> <p>Slack (recommended)</p> <ul> <li> <p>In Slack:</p> <ul> <li> <p>Go to your workspace \u2192 Apps \u2192 Manage apps \u2192 Incoming Webhooks</p> </li> <li> <p>Create a new webhook \u2192 choose your channel \u2192 copy the webhook URL.</p> </li> </ul> </li> <li> <p>In GitLab:</p> <ul> <li> <p>Project \u2192 Settings \u2192 Integrations \u2192 Slack notifications</p> </li> <li> <p>Paste the webhook URL.</p> </li> <li> <p>Choose events (Pipeline, Job, Merge Request, etc.).</p> </li> <li> <p>Save.</p> </li> </ul> </li> <li> <p>Now Slack will automatically post updates like:</p> <ul> <li>\u2705 Pipeline succeeded \u2014 production deploy complete</li> </ul> </li> </ul> </li> <li> <p>Microsoft Teams</p> <ul> <li> <p>In your Teams channel:</p> <ul> <li>Go to Connectors \u2192 Incoming Webhook \u2192 Add \u2192 give it a name and copy the webhook URL.</li> </ul> </li> <li> <p>In GitLab:</p> <ul> <li>Go to Settings \u2192 Integrations \u2192 Microsoft Teams notifications \u2192 paste the webhook URL \u2192 select pipeline/job events.</li> </ul> </li> </ul> </li> <li> <p>Email Notifications (simple)</p> <ul> <li> <p>GitLab already emails users automatically on:</p> <ul> <li> <p>failed pipelines (if you\u2019re subscribed),</p> </li> <li> <p>failed jobs you own.</p> </li> </ul> </li> <li> <p>To fine-tune:</p> <ul> <li>GitLab \u2192 User Menu \u2192 Preferences \u2192 Notifications \u2192 choose \u201cParticipating\u201d or \u201cWatch\u201d level for your project.</li> </ul> </li> <li> <p>Or use project-level notifications:</p> <ul> <li>Go to Project \u2192 Settings \u2192 Notifications \u2192 Add custom notification email </li> </ul> </li> </ul> </li> </ol>"},{"location":"backend/ssh-key/","title":"SSH Key","text":"<p>Use this guide to create an SSH key on Windows and add it to your Git hosting service for secure, password-less pushes.</p>"},{"location":"backend/ssh-key/#create-ssh-key","title":"Create SSH Key","text":"<ul> <li>Here is the command to create an SSH key. If you want to start pushing your projects to GIT, it's the first step.  </li> <li>When you log in to the GIT website you will see a notification to add your SSH key. Run this command in PowerShell or CMD:</li> </ul> <pre><code>ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" -f \"C:\\path\\to\\your\\folder\\your_key_name\"\n</code></pre> <ul> <li>Replace the email and the path. Then open the generated <code>.pub</code> file at the specified path with Notepad, copy all text, and paste it into the GitLab/GitHub website.</li> </ul> <p>Optional (recommended): use <code>ed25519</code> for smaller keys and better security: <pre><code>ssh-keygen -t ed25519 -C \"your_email@example.com\" -f \"C:\\path\\to\\your\\folder\\your_ed25519_key\"\n</code></pre></p>"},{"location":"backend/ssh-key/#check-for-existing-key","title":"Check for existing Key","text":"<pre><code>dir C:\\Users\\YourUsername\\.ssh\n</code></pre>"},{"location":"backend/ssh-key/#copy-public-key-windows","title":"Copy public key (Windows)","text":"<pre><code>type C:\\path\\to\\your\\folder\\your_key_name.pub | clip\n</code></pre>"},{"location":"backend/ssh-key/#notes","title":"Notes","text":"<ul> <li>Keep your private key (<code>your_key_name</code> without <code>.pub</code>) secure and never share it.</li> <li>Use <code>ssh-agent</code> to load keys for the session: <pre><code># Start the agent (PowerShell)\nStart-Service ssh-agent\nssh-add C:\\path\\to\\your\\folder\\your_key_name\n</code></pre></li> </ul>"},{"location":"backend/csharp/anonymous-endpoint/","title":"Anonymous Endpoint","text":""},{"location":"backend/csharp/anonymous-endpoint/#allow-anonymous-endpoint","title":"Allow Anonymous Endpoint","text":"program.cs<pre><code>builder.Services.AddAuthorization(options =&gt;\n{\n    // By default, all incoming requests will be authorized according to the default policy.\n    options.FallbackPolicy = options.DefaultPolicy;\n    options.AddPolicy(\"AllowAnonymousPolicy\", policy =&gt;\n    {\n        policy.RequireAssertion(context =&gt;\n            context.Resource is HttpRequest request &amp;&amp;\n            (request.Path.StartsWithSegments(\"/Account/ExternalLogin\") ||\n             request.Path.StartsWithSegments(\"/Account/ExternalLoginCallback\")));\n    });\n});\n</code></pre> Controller<pre><code>[HttpGet]\n[Route(\"ExternalLogin\")]\n[AllowAnonymous]\npublic IActionResult ExternalLogin(string provider, string returnUrl = null)\n</code></pre>"},{"location":"backend/csharp/application-setting/","title":"Application Settings","text":""},{"location":"backend/csharp/application-setting/#powershell-env-config","title":"Powershell env. Config","text":"Set Environment Variable<pre><code>[System.Environment]::SetEnvironmentVariable(\"DB_PASSWORD\", \"MySecret123\", \"Machine\")\n</code></pre> <p>CAUTION!</p> <p>Run the PowerShell as Administrator. Restart the IDE after setting the Environment values.</p>"},{"location":"backend/csharp/application-setting/#set-appsettingsjson","title":"Set appsettings.json","text":"<pre><code>\"ConnectionStrings\": {\n  \"DefaultConnection\": \"Server=...;User Id=...;Password=%DB_PASSWORD%;\"\n},\n\"ExAuthentication\": {\n    \"Facebook\": {\n      \"AppId\": \"facebook\",\n      \"AppSecret\": \"facebook\"\n    },\n    \"Google\": {\n      \"ClientId\": \"\",\n      \"ClientSecret\": \"\"\n    }\n  }\n</code></pre>"},{"location":"backend/csharp/application-setting/#set-programcs","title":"Set Program.cs","text":"program.cs<pre><code>// Register the IConfiguration instance which 'secrets.json', 'appsettings.json', 'EnvironmentVariables' binds against.\n//----------------------------------------\nvar configuration = new ConfigurationBuilder()\n        .SetBasePath(Environment.CurrentDirectory)\n        .AddJsonFile(\"appsettings.json\", optional: true, reloadOnChange: true)\n        .AddUserSecrets&lt;Program&gt;(optional: true, reloadOnChange: true)\n        .AddEnvironmentVariables()\n            .Build();\n\nbuilder.Services.AddSingleton&lt;IConfiguration&gt;(configuration);\n\n//Configure DB Context\n//----------------------------------------\nbuilder.Services.AddDbContext&lt;DBContext&gt;(options =&gt;\n{\n    options.UseSqlServer(configuration.GetConnectionString(\"DefaultConnection\")\n            .Replace(\"%DB_PASSWORD%\", Environment.GetEnvironmentVariable(\"DB_PASSWORD\")));\n}, ServiceLifetime.Scoped);\n</code></pre>"},{"location":"backend/csharp/application-setting/#read-appsettingsjson","title":"Read appsettings.json","text":"usage<pre><code>configuration.GetSection(\"ExAuthentication:Google:ClientId\").Value\n</code></pre>"},{"location":"backend/csharp/application-setting/#cmd-env-config","title":"CMD env. Config","text":"<pre><code>setx ConnectionStrings__DBConnection \"Server=.;Database=DB;User Id=sa;Password=***;TrustServerCertificate=true;\"\n\nsetx ExAuthentication__Facebook__AppId \"facebook\"\nsetx ExAuthentication__Facebook__AppSecret \"facebook\"\n\nsetx ExAuthentication__Google__ClientId \"ClientId\"\nsetx ExAuthentication__Google__ClientSecret \"ClientSecret\"\n</code></pre>"},{"location":"backend/csharp/application-setting/#powershell-env-config_1","title":"Powershell env. Config","text":"<pre><code># If you need to set these variables for the current user only, replace 'Machine' to 'User'\n# -----------------------------------\n[System.Environment]::SetEnvironmentVariable('ConnectionStrings__DBConnection', 'Server=.;Database=DB;User Id=sa;Password=***;TrustServerCertificate=true;', [System.EnvironmentVariableTarget]::Machine)\n\n[System.Environment]::SetEnvironmentVariable('ExAuthentication__Facebook__AppId', 'facebook', [System.EnvironmentVariableTarget]::Machine)\n[System.Environment]::SetEnvironmentVariable('ExAuthentication__Facebook__AppSecret', 'facebook', [System.EnvironmentVariableTarget]::Machine)\n\n[System.Environment]::SetEnvironmentVariable('ExAuthentication__Google__ClientId', 'ClientID', [System.EnvironmentVariableTarget]::Machine)\n[System.Environment]::SetEnvironmentVariable('ExAuthentication__Google__ClientSecret', 'ClientSecret', [System.EnvironmentVariableTarget]::Machine)\n</code></pre>"},{"location":"backend/csharp/application-setting/#user-secrets-file","title":"User Secrets file","text":"<pre><code>install-package Microsoft.Extensions.Configuration.UserSecrets\n\n  &lt;PropertyGroup&gt;\n    &lt;UserSecretsId&gt;SecretId&lt;/UserSecretsId&gt;\n  &lt;/PropertyGroup&gt;\n\nadd settings in Manage user secrets on contextmenu of each project\n</code></pre>"},{"location":"backend/csharp/auth/","title":"Authentication","text":"<ul> <li>Authentication is the process of validating the identity of a registered user who is accessing a service or an application.</li> <li>Authorization is the process of validating the authenticated user if the user has permissions to access a certain service or an application.</li> </ul>"},{"location":"backend/csharp/auth/#cookie-based-auth","title":"Cookie-based Auth","text":"<ul> <li>You typically have a browser and a server. And if you want to be authenticated, you'd send the username and the password to the server. Let's say by using an API endpoint /authenticate.</li> <li>Then the server is going to check if the credentials are correct. And if the credentials are correct, then the server is going to create a session in the server memory.</li> <li>Then it is going to return to the user that sessionId. This sessionId gets stored in a cookie in the browser. tion type cookie-based authentication because the sessionId gets stored in a cookie.</li> <li>Then next, if you want to get some data from the server, you'd pass the sessionId as part of the request as well.</li> <li>There was two problems:<ol> <li>The first problem is that if let's say millions of users try to access your app at the same time, then the server is going to create millions of sessions, which is going to overload your server.</li> <li>The second problem is that if your cookies get stolen from the browser, the sessionIds are stolen as well.</li> </ol> </li> </ul>"},{"location":"backend/csharp/auth/#token-based-auth","title":"Token-based Auth","text":"<ul> <li>Here is the same way we have a browser and a server, if you want to be authenticated, you would send the username and password, and they server would check if these credentials are valid.</li> <li>If the credentials are valid, the server will not create a session, but instead it is going to generate a token.</li> <li>This token is just an encrypted string, which has enough valuable information for the server to find out the identity of a user.</li> <li>After the token is returned to the browser, the token will be stored in the browser, and on the next request when you want to get some data from the server, you'd use the authorization Bearer and pass the token value.</li> <li>The tokens have an expiration time. So even if your token gets stolen, it will expire after typically 5 to 10 minutes, because that is the standard token lifetime.</li> <li>We have the short lived tokens, like the access token, or the token that gets returned from the server.</li> <li>But we also have long lived tokens. We also call them refresh tokens. So once the token is expired, we use our refresh token to generate a new token.</li> </ul>"},{"location":"backend/csharp/auth/#json-web-token","title":"Json Web Token","text":"<ul> <li>The JWT is an open standard that defines a compact and self-contained way for securely transmitting information between parties as a JSON object.</li> <li>It has three parts:<ol> <li>Header: Type of token, signing algorithm</li> <li>Payload: Claims(Registered, Public, Private)</li> <li>Signature: Signature(Secret)</li> </ol> </li> </ul>"},{"location":"backend/csharp/auth/#setup-ef-jwt","title":"Setup EF &amp; JWT","text":"<ul> <li>Install NuGet packages:<ul> <li>Microsoft.EntityFrameworkCore</li> <li>Microsoft.EntityFrameworkCore.SqlServer</li> <li>Microsoft.AspNetCore.Identity.EntityFrameworkCore</li> <li>Microsoft.EntityFrameworkCore.Tools</li> <li>Microsoft.AspNetCore.Authentication.JwtBearer</li> </ul> </li> </ul> appsettings.json<pre><code>\"JwtSettings\":{\n  \"SecretKey\": \"xxxxxxxxxx\",\n  \"Issuer\": \"https://localhost:5002/\",\n  \"Audience\": \"user\",\n  \"AccessTokenMinutes\" : \"10\",\n  \"RefreshTokenDays\" : \"180\"\n}\n</code></pre> Settings POCO<pre><code>public sealed class JwtSettings\n{\n    public string SecretKey { get; set; } = null!;\n    public string Issuer { get; set; } = null!;\n    public string Audience { get; set; } = null!;\n    public int AccessTokenMinutes { get; set; }; \n    public int RefreshTokenDays { get; set; };\n}\n</code></pre> Program.cs<pre><code>var builder = WebApplication.CreateBuilder(args);\nvar configuration = new ConfigurationBuilder()\n    .SetBasePath(Environment.CurrentDirectory)\n    .AddJsonFile(\"appsettings.json\", optional: true, reloadOnChange: true) // lowest priority\n    .AddUserSecrets&lt;Program&gt;(optional: true, reloadOnChange: true)         // overrides json\n    .AddEnvironmentVariables()                                            // highest priority\n    .Build();\n\nbuilder.Services.Configure&lt;JwtSettings&gt;(configuration.GetSection(\"JwtSettings\"));\nvar jwt = configuration.GetSection(\"JwtSettings\").Get&lt;JwtSettings&gt;()!;\n\nbuilder.Services.AddDbContext&lt;AppDbContext&gt;(opt =&gt;\n    opt.UseSqlServer(configuration.GetConnectionString(\"DBConnection\")));\n\nbuilder.Services\n    .AddIdentity&lt;User, Role&gt;(options =&gt;\n    {\n        options.User.RequireUniqueEmail = true;\n        options.Password.RequireDigit = true;\n        options.Password.RequiredLength = 8;\n        options.Password.RequiredUniqueChars = 2;\n        options.Password.RequireLowercase = true;\n        options.Password.RequireNonAlphanumeric = true;\n        options.Password.RequireUppercase = true;\n        options.Lockout.AllowedForNewUsers = true;\n        options.Lockout.DefaultLockoutTimeSpan = TimeSpan.FromMinutes(5);\n        options.Lockout.MaxFailedAccessAttempts = 5;\n        options.SignIn.RequireConfirmedEmail = true;\n    })\n    .AddEntityFrameworkStores&lt;AppDbContext&gt;()\n    .AddDefaultTokenProviders();\n\nvar key = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(jwt.SecretKey));\nvar tokenValidationParameters = new TokenValidationParameters\n{\n    ValidateIssuerSigningKey = true,\n    IssuerSigningKey = key,\n\n    ValidateIssuer = true,\n    ValidIssuer = jwt.Issuer,\n\n    ValidateAudience = true,\n    ValidAudience = jwt.Audience,\n\n    ValidateLifetime = true,\n    ClockSkew = TimeSpan.Zero\n};\nbuilder.Services.AddSingleton(tokenValidationParameters);\n\nbuilder.Services.AddAuthentication(options =&gt;\n{\n    options.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme;\n    options.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme;\n    options.DefaultScheme = JwtBearerDefaults.AuthenticationScheme;\n})\n.AddJwtBearer(options =&gt;\n{\n    options.SaveToken = true;\n    options.RequireHttpsMetadata = false; // set true in production\n    options.TokenValidationParameters = tokenValidationParameters;\n});\n\nvar app = builder.Build();\n\napp.UseRouting();\napp.UseAuthentication();\napp.UseAuthorization();\n\nawait AppDbInitializer.SeedRoles(app);\n\napp.MapControllers();\napp.Run();\n</code></pre> DBContext &amp; Models<pre><code>public class AppDbContext : IdentityDbContext&lt;\n    User, Role, long,\n    IdentityUserClaim&lt;long&gt;, IdentityUserRole&lt;long&gt;, IdentityUserLogin&lt;long&gt;,\n    IdentityRoleClaim&lt;long&gt;, IdentityUserToken&lt;long&gt;&gt;\n{\n    public DbSet&lt;UserProfile&gt; UserProfiles =&gt; Set&lt;UserProfile&gt;();\n    public DbSet&lt;RefreshToken&gt; RefreshTokens =&gt; Set&lt;RefreshToken&gt;();\n\n    public AppDbContext(DbContextOptions&lt;AppDbContext&gt; options) : base(options) { }\n\n    protected override void OnModelCreating(ModelBuilder builder)\n    {\n        base.OnModelCreating(builder);\n\n        modelBuilder.HasDefaultSchema(\"Identity\");\n\n        // Rename Identity tables (remove AspNet*)\n        builder.Entity&lt;User&gt;().ToTable(\"User\");\n        builder.Entity&lt;Role&gt;().ToTable(\"Role\");\n        builder.Entity&lt;IdentityUserRole&lt;long&gt;&gt;().ToTable(\"UserRole\");\n        builder.Entity&lt;IdentityUserClaim&lt;long&gt;&gt;().ToTable(\"UserClaim\");\n        builder.Entity&lt;IdentityUserLogin&lt;long&gt;&gt;().ToTable(\"UserLogin\");\n        builder.Entity&lt;IdentityRoleClaim&lt;long&gt;&gt;().ToTable(\"RoleClaim\");\n        builder.Entity&lt;IdentityUserToken&lt;long&gt;&gt;().ToTable(\"UserToken\");\n\n        // (Optional) tweak PK/indices names if you want consistent naming, EF will generate defaults otherwise\n        // Example:\n        // builder.Entity&lt;User&gt;().HasKey(u =&gt; u.Id).HasName(\"PK_Users\");\n\n        // Ensure FK columns are bigint where needed\u2014Identity generics &lt;long&gt; already do that.\n    }\n}\n\npublic class User : IdentityUser&lt;long&gt;\n{\n    public override long Id { get; set; }\n    public bool IsApproved { get; set; }\n}\n\npublic class Role : IdentityRole&lt;long&gt;\n{\n    public long? ParentRoleId { get; set; }\n    public string? Description { get; set; }\n    public bool IsDeleted { get; set; } = false;\n    public virtual ICollection&lt;IdentityRoleClaim&lt;long&gt;&gt; RoleClaims { get; set; } = new List&lt;IdentityRoleClaim&lt;long&gt;&gt;();\n    [ForeignKey(nameof(ParentRoleId))] public virtual Role? ParentRole { get; set; }\n}\n\npublic class UserProfile\n{\n    [Key, DatabaseGenerated(DatabaseGeneratedOption.Identity)]\n    public long Id { get; set; }\n    public long UserId { get; set; }\n    public string? CompanyName { get; set; }\n    public required string Firstname { get; set; }\n    public required string Lastname { get; set; }\n    public string? PostalCode { get; set; }\n    public string? City { get; set; }\n    public string? Street { get; set; }\n    public string? Description { get; set; }\n    public virtual User User { get; set; } = null!;\n}\n\npublic class RefreshToken\n{\n    [Key] public long Id { get; set; }\n    public string Token { get; set; } = null!;\n    public string JwtId { get; set; } = null!;\n    public bool IsRevoked { get; set; }\n    public DateTime DateAdded { get; set; }\n    public DateTime DateExpire { get; set; }\n\n    public long UserId { get; set; }\n    [ForeignKey(nameof(UserId))] public User User { get; set; } = null!;\n}\n</code></pre> Controller<pre><code>[ApiController]\n[Route(\"[controller]\")]\npublic class AccountController : ControllerBase\n{\n    private readonly UserManager&lt;User&gt; _userManager;\n    private readonly RoleManager&lt;Role&gt; _roleManager;\n    private readonly AppDbContext _context;\n    private readonly JwtSettings _jwt;\n    private readonly TokenValidationParameters _tokenValidationParameters;\n\n    public AccountController(\n        AppDbContext context,\n        UserManager&lt;User&gt; userManager,\n        RoleManager&lt;Role&gt; roleManager,\n        IOptions&lt;JwtSettings&gt; jwt,\n        TokenValidationParameters tokenValidationParameters)\n    {\n        _context = context;\n        _userManager = userManager;\n        _roleManager = roleManager;\n        _jwt = jwt.Value;\n        _tokenValidationParameters = tokenValidationParameters;\n    }\n\n    [HttpPost(\"RegisterWithPassword\")]\n    public async Task&lt;IActionResult&gt; RegisterWithPassword([FromBody] RegisterWithPasswordModel model)\n    {\n        if (!ModelState.IsValid) return BadRequest(\"Provide all fields\");\n\n        var existing = await _userManager.FindByEmailAsync(model.Email);\n        if (existing != null) return BadRequest(\"User exists\");\n\n        using var tx = await _context.Database.BeginTransactionAsync();\n\n        var user = new User { Email = model.Email, UserName = model.Email };\n        var result = await _userManager.CreateAsync(user, model.Password);\n\n        if (!result.Succeeded)\n        {\n            await tx.RollbackAsync();\n            return Unauthorized(\"User creation failed\");\n        }\n\n        await _userManager.AddToRoleAsync(user, \"User\");\n\n        await _context.UserProfiles.AddAsync(new UserProfile\n        {\n            UserId = user.Id,\n            Firstname = model.Firstname,\n            Lastname = model.Lastname\n        });\n        await _context.SaveChangesAsync();\n\n        // send email confirmation\n        await SendConfirmationEmail(user);\n\n        await tx.CommitAsync();\n        return Ok(\"User created. Please confirm your email.\");\n    }\n\n    [HttpPost(\"LoginWithPassword\")]\n    public async Task&lt;IActionResult&gt; LoginWithPassword([FromBody] LoginWithPasswordModel model)\n    {\n        if (!ModelState.IsValid) return BadRequest(\"Not valid\");\n\n        var user = await _userManager.FindByEmailAsync(model.Email);\n        if (user == null) return Unauthorized(\"User does not exist\");\n        if (!await _userManager.IsEmailConfirmedAsync(user)) return Unauthorized(\"Email is not confirmed\");\n\n        if (!await _userManager.CheckPasswordAsync(user, model.Password))\n            return Unauthorized(\"Invalid credentials\");\n\n        var auth = await GenerateJwtTokenAsync(user, null);\n        return Ok(auth);\n    }\n\n    [HttpPost(\"RefreshToken\")]\n    public async Task&lt;IActionResult&gt; RefreshToken([FromBody] TokenRequestModel model)\n    {\n        if (!ModelState.IsValid) return BadRequest(\"Not valid\");\n        var result = await VerifyAndGenerateTokenAsync(model);\n        if (result is null) return Unauthorized(\"Invalid refresh request\");\n        return Ok(result);\n    }\n\n    private async Task&lt;AuthResultModel?&gt; VerifyAndGenerateTokenAsync(TokenRequestModel model)\n    {\n        var stored = await _context.RefreshTokens\n            .Include(r =&gt; r.User)\n            .FirstOrDefaultAsync(x =&gt; x.Token == model.RefreshToken);\n\n        if (stored is null || stored.IsRevoked || stored.DateExpire &lt;= DateTime.UtcNow)\n            return null;\n\n        var handler = new JwtSecurityTokenHandler();\n        SecurityToken validated;\n        try\n        {\n            handler.ValidateToken(model.Token, _tokenValidationParameters, out validated);\n            // If token is still valid, no need to refresh (optional behavior)\n            return null;\n        }\n        catch (SecurityTokenExpiredException)\n        {\n            // Check JTI match\n            var expiredToken = handler.ReadJwtToken(model.Token);\n            var jti = expiredToken.Claims.FirstOrDefault(c =&gt; c.Type == JwtRegisteredClaimNames.Jti)?.Value;\n            if (jti != stored.JwtId) return null;\n\n            return await GenerateJwtTokenAsync(stored.User, stored /* for reuse or rotation */);\n        }\n        catch\n        {\n            return null;\n        }\n    }\n\n    private async Task&lt;AuthResultModel&gt; GenerateJwtTokenAsync(User user, RefreshToken? existingRefresh)\n    {\n        var claims = new List&lt;Claim&gt;\n        {\n            new Claim(ClaimTypes.NameIdentifier, user.Id.ToString()),\n            new Claim(ClaimTypes.Name, user.UserName ?? user.Email ?? user.Id.ToString()),\n            new Claim(JwtRegisteredClaimNames.Sub, user.Email ?? user.UserName ?? user.Id.ToString()),\n            new Claim(JwtRegisteredClaimNames.Email, user.Email ?? string.Empty),\n            new Claim(JwtRegisteredClaimNames.Jti, Guid.NewGuid().ToString())\n        };\n\n        var roles = await _userManager.GetRolesAsync(user);\n        foreach (var role in roles)\n            claims.Add(new Claim(ClaimTypes.Role, role));\n\n        var key = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(_jwt.SecretKey));\n        var creds = new SigningCredentials(key, SecurityAlgorithms.HmacSha256);\n        var token = new JwtSecurityToken(\n            issuer: _jwt.Issuer,\n            audience: _jwt.Audience,\n            claims: claims,\n            expires: DateTime.UtcNow.AddMinutes(_jwt.AccessTokenMinutes),\n            signingCredentials: creds);\n\n        var tokenString = new JwtSecurityTokenHandler().WriteToken(token);\n\n        RefreshToken refresh;\n        if (existingRefresh != null &amp;&amp; existingRefresh.DateExpire &gt; DateTime.UtcNow &amp;&amp; !existingRefresh.IsRevoked)\n        {\n            refresh = existingRefresh; // or rotate if you prefer\n        }\n        else\n        {\n            refresh = new RefreshToken\n            {\n                JwtId = token.Id, // this is the JTI (matches token.Id)\n                IsRevoked = false,\n                UserId = user.Id,\n                DateAdded = DateTime.UtcNow,\n                DateExpire = DateTime.UtcNow.AddDays(_jwt.RefreshTokenDays),\n                Token = $\"{Guid.NewGuid()}-{Guid.NewGuid()}\"\n            };\n            _context.RefreshTokens.Add(refresh);\n            await _context.SaveChangesAsync();\n        }\n\n        return new AuthResultModel\n        {\n            Token = tokenString,\n            RefreshToken = refresh,\n            ExpiresAt = token.ValidTo\n        };\n    }\n\n     private async Task SendConfirmationEmail(User user)\n     {\n        // Generate an email confirmation token for the user\n        var code = await _userManager.GenerateEmailConfirmationTokenAsync(user);\n\n        string expireToken = TokenManager.GenerateToken(Convert.ToInt32(_config.GetSection(\"TimeSettings:AccountActivationTime\").Value));\n\n        // Build the callback URL with the confirmation code\n        //var callbackUrl = Url.Action(\"ConfirmEmail\", \"Account\", new { userId = user.Id.ToString(), code = code, token = expireToken }, protocol: HttpContext.Request.Scheme);\n\n        var callbackUrl = $\"{_config.GetValue&lt;string&gt;(\"Production:ProductionUrl\")}/Account/ConfirmEmail?userId={user.Id}&amp;code={Uri.EscapeDataString(code)}&amp;token={Uri.EscapeDataString(expireToken)}\";\n\n        // Compose the email content with the confirmation link\n        await _emailSender.SendEmailAsync(\n            user.Email,\n            \"Aktivieren Sie Ihr Konto\",\n            GenerateEmailContent(\"EmailConfirmationTemplate\", \"EmailAddress\", user.Email, \"CallbackUrl\", callbackUrl));\n     }\n\n      [HttpGet]\n      [AllowAnonymous]\n      [Route(\"ConfirmEmail\")]\n      public async Task&lt;IActionResult&gt; ConfirmEmail(string userId, string code, string token)\n      {\n        // Check for valid input parameters\n        if (string.IsNullOrEmpty(userId) || string.IsNullOrEmpty(code) || string.IsNullOrEmpty(token))\n        {\n            return BadRequest(\"Invalid request! Make a contact with the administrator.\");\n        }\n\n        // Find the user based on the provided user ID\n        var user = await _userManager.FindByIdAsync(userId);\n\n        // Check if the user exists\n        if (user == null)\n        {\n            //return Unauthorized(\"Invalid request!\");\n        }\n\n        if (TokenManager.IsTokenValid(token))\n        {\n            // Confirm the user's email with the provided confirmation code\n            var result = await _userManager.ConfirmEmailAsync(user, code);\n\n            // Check if the email confirmation was successful\n            if (result.Succeeded)\n            {\n                return Ok(\"Your email has been successfully confirmed. Once your account be activated by Helmsauer's team, you'll be able to log in.\");\n            }\n            return Unauthorized(\"Email confirmation failed!!! Make a contact with the administrator.\");\n        }\n      }\n\n    private string GenerateEmailContent(string template, params object[] data)\n    {\n        try\n        {\n            // Read the HTML content from the external template file\n            string htmlContent = System.IO.File.ReadAllText($\"Models/DataModels/{template}.html\");\n\n            //in html file use {EmailAddress} as placeholder\n\n            if (data != null)\n            {\n                for (int i = 0; i &lt; data.Length; i += 2)\n                {\n                    if (i + 1 &lt; data.Length &amp;&amp; data[i] != null)\n                    {\n                        string placeholder = $\"{{{data[i]}}}\";\n                        htmlContent = htmlContent.Replace(placeholder, data[i + 1].ToString());\n                    }\n                }\n            }\n\n            return htmlContent;\n        }\n        catch\n        {\n            // Propagate any exceptions that occur during template file reading\n            throw;\n        }\n      }\n}\n</code></pre> Role seeding<pre><code>public static class AppDbInitializer\n{\n    public static async Task SeedRoles(IApplicationBuilder appBuilder)\n    {\n        using var scope = appBuilder.ApplicationServices.CreateScope();\n        var roleManager = scope.ServiceProvider.GetRequiredService&lt;RoleManager&lt;Role&gt;&gt;();\n\n        async Task EnsureRole(string name)\n        {\n            if (!await roleManager.RoleExistsAsync(name))\n                await roleManager.CreateAsync(new Role { Name = name });\n        }\n\n        await EnsureRole(\"Admin\");\n        await EnsureRole(\"User\");\n    }\n}\n</code></pre>"},{"location":"backend/csharp/authEx/","title":"External Auth","text":"<p>Install packages:    * Microsoft.AspNetCore.Authentication.JwtBearer    * Microsoft.AspNetCore.Authentication.Negotiate    * Microsoft.AspNetCore.Identity.EntityFrameworkCore    * Microsoft.EntityFrameworkCore.SqlServer    * Microsoft.EntityFrameworkCore.Tools</p>"},{"location":"backend/csharp/authEx/#active-directory","title":"Active Directory","text":"<ol> <li>Install packages </li> <li>Configure authentication/authorization    Program.cs<pre><code>builder.Services.AddAuthentication(NegotiateDefaults.AuthenticationScheme)\n   .AddNegotiate();\n\nbuilder.Services.AddAuthorization(options =&gt;\n{\n    options.FallbackPolicy = options.DefaultPolicy;\n});\n\nvar app = builder.Build();\n\napp.UseAuthentication();\napp.UseAuthorization();\n\napp.MapControllers();\n</code></pre></li> <li>Now any controller/action with [Authorize] (or all, if you used the fallback policy) will require a valid Windows login. You can read the user with:    <pre><code>var user = HttpContext.User;                // ClaimsPrincipal\nvar name = user.Identity?.Name;             // \"DOMAIN\\\\username\"\nvar isAuth = user.Identity?.IsAuthenticated == true; \nUser.Identity?.AuthenticationType; // \"Negotiate\" or \"NTLM\"\n</code></pre></li> <li>In Razor components:    <pre><code>@inject IHttpContextAccessor HttpContextAccessor\n\n@code{\n     private async Task CheckLdapAuthenticationAsync()\n     {\n         var domainUser = HttpContextAccessor.HttpContext?.User?.Identity?.Name;\n          if (domainUser == null)\n          {\n          }\n     }\n}\n</code></pre></li> <li>Development hosting (IIS Express) \u2013 enable Windows auth    In Properties/launchSettings.json (IIS Express profile):    <pre><code>\"iisSettings\": {\n  \"windowsAuthentication\": true,\n  \"anonymousAuthentication\": false\n}\n</code></pre>    Or set this in Visual Studio: Project Properties \u2192 Debug \u2192 App URL (IIS Express) \u2192 Enable Windows Authentication (on) / Anonymous (off).</li> <li>Kestrel/self-host    You can run on Kestrel; negotiation still works. For browsers to SSO without a prompt, the site must be in clients\u2019 Local Intranet zone (IE/Edge) or configured in Chrome/Firefox to allow integrated auth for your domain.</li> <li>Authorize by AD group    <pre><code>[Authorize(Roles = @\"MYDOMAIN\\\\Developers\")]\n[ApiController]\n[Route(\"api/[controller]\")]\npublic class SecureController : ControllerBase\n{\n    [HttpGet(\"me\")]\n    public IActionResult Me() =&gt; Ok(User.Identity?.Name);\n}\n</code></pre>    Or define a policy in AddAuthorization:    <pre><code>options.AddPolicy(\"ITAdmins\", policy =&gt;\n    policy.RequireRole(@\"MYDOMAIN\\\\IT Admins\"));\n</code></pre>    Then:    <pre><code>[Authorize(Policy = \"ITAdmins\")]\npublic IActionResult AdminOnly() =&gt; Ok(\"Hi admin!\");\n</code></pre></li> <li>If you really want to keep ASP.NET Core Identity together with Windows auth    Program.cs<pre><code>app.Use(async (ctx, next) =&gt;\n{\n    if (ctx.User?.Identity?.IsAuthenticated == true)\n    {\n        var sam = ctx.User.Identity.Name; // DOMAIN\\\\user\n        using var scope = ctx.RequestServices.CreateScope();\n        var userManager = scope.ServiceProvider.GetRequiredService&lt;UserManager&lt;ApplicationUser&gt;&gt;();\n        var user = await userManager.FindByNameAsync(sam);\n        if (user is null)\n        {\n            user = new ApplicationUser { UserName = sam };\n            await userManager.CreateAsync(user); // no password\n            // attach app-specific claims/roles if needed\n        }\n    }\n    await next();\n});\n</code></pre></li> </ol> <p>Common pitfalls</p> <p>Anonymous auth left enabled \u2192 everyone gets through. Turn it off (IIS/IIS Express) or enforce [Authorize]. Order of middleware \u2192 UseAuthentication() must come before UseAuthorization(). Cross-domain prompts \u2192 if the browser isn\u2019t configured for integrated auth to your API host, it may prompt for credentials.</p> <ol> <li>Setup IIS</li> <li>Prerequisites (once)<ul> <li>Server is domain-joined.</li> <li>DNS host name clients will use exists (e.g. api.contoso.com) and resolves to the server.</li> <li>TLS cert for that host name is installed in Local Computer \u2192 Personal \u2192 Certificates.</li> <li>Install .NET Hosting Bundle (same major/minor as your app) on the server.</li> <li>In Server Manager \u2192 Add Roles &amp; Features \u2192 Web Server (IIS):</li> <li>Under Web Server \u2192 Security: check Windows Authentication.</li> <li>(Optional) URL Authorization, Logging, etc.</li> </ul> </li> <li>Publish &amp; create the site </li> <li>In IIS Manager:<ul> <li>Application Pools \u2192 Add<ul> <li>Name: MyApiPool</li> <li>.NET CLR: No Managed Code</li> <li>Managed pipeline: Integrated</li> </ul> </li> <li>(Choose identity now or later\u2014see \u00a73.)</li> <li>Sites \u2192 Add Website\u2026<ul> <li>Site name: MyApi</li> <li>Physical path: C:\\Sites\\MyApi</li> <li>Binding:<ul> <li>Type: https</li> <li>Host name: api.contoso.com</li> <li>SSL certificate: pick your cert</li> </ul> </li> <li>Assign Application Pool \u2192 MyApiPool.</li> </ul> </li> </ul> </li> <li>Enable Windows auth in IIS<ul> <li>Select the MyApi site \u2192 Authentication:<ul> <li>Windows Authentication: Enabled</li> <li>Anonymous Authentication: Disabled</li> </ul> </li> <li>Still in Windows Authentication \u2192 Providers\u2026:<ul> <li>Ensure Negotiate is first, NTLM second.</li> </ul> </li> <li>Advanced Settings\u2026:<ul> <li>Enable Kernel-mode authentication: True (default)</li> <li>Extended Protection: Off (while testing; you\u2019ll re-enable later)</li> <li>UseAppPoolCredentials:<ul> <li>True if you\u2019ll run the app pool as a domain service account (option B below).</li> <li>False if using the machine account (option A).</li> </ul> </li> </ul> </li> </ul> </li> <li>Choose app-pool identity &amp; set SPN (Kerberos)       &gt; Kerberos needs an HTTP SPN for the exact DNS name clients use.<ul> <li>Option A \u2014 Use the server\u2019s computer account (simple)<ul> <li>Leave app pool identity as ApplicationPoolIdentity.</li> <li>Register SPN to the computer account:  <pre><code># Run as Domain Admin\nsetspn -S HTTP/api.contoso.com CONTOSO\\SERVERNAME$\n</code></pre></li> <li>Keep UseAppPoolCredentials = False.</li> </ul> </li> <li>Option B \u2014 Use a domain service account (recommended for farms)<ul> <li>Create CONTOSO\\svc-webapi, grant it Log on as a service (GPO or Local Security Policy).</li> <li>Set app pool identity to Custom account \u2192 CONTOSO\\svc-webapi.</li> <li>Register SPN to that account:  powershell<pre><code>setspn -S HTTP/api.contoso.com CONTOSO\\svc-webapi\n</code></pre></li> <li>Set UseAppPoolCredentials = True (Windows Authentication \u2192 Advanced Settings).   <code>shell title=\"powershell\"  setspn -Q HTTP/api.contoso.com</code>  If duplicates exist, Kerberos fails \u2192 browser prompts.</li> </ul> </li> </ul> </li> <li> <p>Configure the ASP.NET Core app       ``` cs title=\"Program.cs\"          using Microsoft.AspNetCore.Server.IISIntegration;</p> <pre><code> var builder = WebApplication.CreateBuilder(args);\n\n // Trust IIS\u2019s Windows auth (Integrated Pipeline)\n builder.Services.AddAuthentication(IISDefaults.AuthenticationScheme);\n builder.Services.AddAuthorization(o =&gt; o.FallbackPolicy = o.DefaultPolicy);\n\n builder.Services.AddControllers();\n\n var app = builder.Build();\n app.UseRouting();\n app.UseAuthentication();\n app.UseAuthorization();\n app.MapControllers();\n app.Run();\n ```\n (Optional) web.config hardening in your site root &lt;br /&gt;\n ``` xml title=\"web.config\"\n &lt;configuration&gt;\n   &lt;system.webServer&gt;\n     &lt;security&gt;\n       &lt;authentication&gt;\n         &lt;windowsAuthentication enabled=\"true\" useKernelMode=\"true\" /&gt;\n         &lt;anonymousAuthentication enabled=\"false\" /&gt;\n       &lt;/authentication&gt;\n     &lt;/security&gt;\n     &lt;handlers&gt;\n       &lt;add name=\"aspNetCore\" path=\"*\" verb=\"*\" modules=\"AspNetCoreModuleV2\" resourceType=\"Unspecified\"/&gt;\n     &lt;/handlers&gt;\n     &lt;aspNetCore processPath=\"dotnet\" arguments=\"MyApi.dll\" stdoutLogEnabled=\"false\" hostingModel=\"InProcess\" /&gt;\n   &lt;/system.webServer&gt;\n &lt;/configuration&gt;\n ```\n</code></pre> <ol> <li>Client/browser settings (for silent SSO)<ul> <li>Access the site via https://api.contoso.com (not IP, not mismatched alias).</li> <li>On domain PCs, add https://api.contoso.com to Local Intranet zone:<ul> <li>Internet Options \u2192 Security \u2192 Local intranet \u2192 Sites \u2192 Advanced \u2192 Add.</li> <li>(Chrome/Edge use these settings.)</li> </ul> </li> <li>For Firefox: about:config \u2192 set<ul> <li>network.automatic-ntlm-auth.trusted-uris = contoso.com <p>Non-domain or off-network clients will see a credential prompt\u2014that\u2019s expected.</p> </li> </ul> </li> </ul> </li> <li>Test Kerberos is actually used</li> <li>From a domain PC:         <code>shell title=\"powershell\"         Invoke-WebRequest https://api.contoso.com/api/secure -UseDefaultCredentials         klist | Select-String HTTP/api.contoso.com</code><ul> <li>In your API (temporary endpoint), log:   <code>cs   User.Identity?.Name;             // CONTOSO\\jdoe   User.Identity?.AuthenticationType; // \"Negotiate\" (Kerberos) or \"NTLM\"</code></li> </ul> </li> <li>If you have a separate frontend origin, enable CORS with credentials in the API:     ``` cs title=\"Program.cs\"         builder.Services.AddCors(o =&gt; o.AddPolicy(\"FrontEnd\", p =&gt;             p.WithOrigins(\"https://app.contoso.com\")              .AllowAnyHeader().AllowAnyMethod().AllowCredentials()));<pre><code>app.UseCors(\"FrontEnd\");\n</code></pre> <p>```           </p> </li> </ol> </li> <li> <p>Info  With Windows/Negotiate, the OS validates the user\u2019s ticket/token. If someone creates a local account called DOMAIN\\jdoe, they still can\u2019t impersonate your AD user unless they can get a valid Kerberos/NTLM token from your domain controller. Still, you should enforce that only users from your AD (or a trusted one) can call the API.</p> </li> </ol> <p>Here\u2019s the secure, practical setup. i. Don\u2019t authorize by username strings. User.Identity.Name (e.g. TEST1\\jdoe) tells you the domain, but treat it as display info only. For authorization, rely on SIDs / AD group membership, not raw names.    * Check membership by group SID (safe &amp; rename-proof). Create (or reuse) an AD group like APP_MyApi_Users in your domain and put allowed users/groups there. Then enforce membership by SID:    Program.cs<pre><code>using System.Security.Principal;\nusing Microsoft.AspNetCore.Authorization;\n\nbuilder.Services.AddAuthorization(options =&gt;\n{\n    options.AddPolicy(\"AppUsersOnly\", policy =&gt;\n        policy.RequireAssertion(ctx =&gt;\n        {\n            if (ctx.User.Identity is WindowsIdentity wi &amp;&amp; wi.Groups is not null)\n            {\n                // SID of your AD group, not its name\n                var requiredSid = new SecurityIdentifier(\"S-1-5-21-xxxxxxxxx-xxxxxxxxx-xxxxxxxxx-12345\");\n                return wi.Groups.Any(g =&gt; g.Equals(requiredSid));\n            }\n            return false;\n        }));\n});\n</code></pre> Controller<pre><code>[Authorize(Policy = \"AppUsersOnly\")]\n[ApiController]\n[Route(\"[controller]\")]\npublic class SecureController : ControllerBase\n{\n    [HttpGet(\"whoami\")]\n    public IActionResult WhoAmI() =&gt; Ok(User.Identity?.Name); // e.g. \"TEST1\\\\jdoe\"\n}\n</code></pre></p> <p>Get your group\u2019s SID once (PowerShell):    <pre><code>Get-ADGroup APP_MyApi_Users | Select -ExpandProperty SID\n</code></pre></p> <p>ii. Prefer Kerberos, avoid NTLM where possible    Kerberos gives you mutual auth and SPN checks (harder to spoof/relay). To steer things to Kerberos and block NTLM:    * Register the SPN for your service (e.g. HTTP/api.contoso.com) on the app pool identity / service account.    * Make clients access the API via the SPN name (https://api.contoso.com, not a raw IP).    * Disable NTLM via Group Policy (server and/or domain policy) or in IIS (remove \u201cNTLM\u201d provider; keep \u201cNegotiate\u201d).    * Put the site in browsers\u2019 Local Intranet zone so they send tickets automatically.</p> <p>iii. Enable TLS and Extended Protection (IIS)    * Use HTTPS only.    * In IIS, turn on Extended Protection for Authentication to bind credentials to the TLS channel (mitigates relay).    * Consider requiring Channel Binding Tokens if your environment supports it.</p> <p>!!!   note \"TL;DR\"</p> <pre><code>     Authentication: let Negotiate/OS validate the token (Kerberos preferred).\n     Authorization: never by raw names; use membership in your AD group\u2019s SID.\n     Constrain domain: check the DOMAIN\\user part if needed, but the group SID is the real gate.\n     Harden: Kerberos + SPN, disable NTLM, HTTPS, Extended Protection.\n</code></pre>"},{"location":"backend/csharp/authEx/#google-ex-auth","title":"Google Ex Auth","text":"<ol> <li>Open Google Cloud Dashboard</li> <li>Create New Project &gt; APIs and services </li> <li>Select OAuth consent screen to Configure Google auth platform &gt; (Name (do not contain \"google\" word), Support Email, External option)</li> <li>Create OAuth client ID &gt; (Application Type, Name, Authorised redirect URIs \"https://localhost:5002/signin-google\")</li> <li>Install package Microsoft.AspNetCore.Authentication.Google    Program.cs<pre><code>   using System.IdentityModel.Tokens.Jwt;\n   using System.Security.Claims;\n   using System.Text;\n   using Microsoft.AspNetCore.Authentication;\n   using Microsoft.AspNetCore.Authentication.JwtBearer;\n   using Microsoft.AspNetCore.Authentication.Negotiate;\n   using Microsoft.AspNetCore.Identity;\n   using Microsoft.EntityFrameworkCore;\n   using Microsoft.IdentityModel.Tokens;\n\n   // --- services ---\n   var builder = WebApplication.CreateBuilder(args);\n   var cfg = builder.Configuration;\n\n   // 1) Identity Core (needed because you use SignInManager/UserManager)\n   builder.Services\n       .AddDbContext&lt;AppDbContext&gt;(o =&gt; o.UseSqlServer(cfg.GetConnectionString(\"Default\")))\n       .AddIdentityCore&lt;ApplicationUser&gt;(o =&gt;\n       {\n           o.SignIn.RequireConfirmedAccount = false;\n           o.User.RequireUniqueEmail = true;\n       })\n       .AddRoles&lt;IdentityRole&gt;()\n       .AddEntityFrameworkStores&lt;AppDbContext&gt;()\n       .AddSignInManager();\n\n   // 2) JWT for protecting API endpoints\n   var issuer = cfg[\"Jwt:Issuer\"]!;\n   var audience = cfg[\"Jwt:Audience\"]!;\n   var key = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(cfg[\"Jwt:Key\"]!));\n\n   builder.Services.AddAuthentication(options =&gt;\n   {\n       // All [Authorize] endpoints require JWT by default\n       options.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme;\n       options.DefaultChallengeScheme    = JwtBearerDefaults.AuthenticationScheme;\n   })\n   .AddJwtBearer(o =&gt;\n   {\n       o.TokenValidationParameters = new TokenValidationParameters\n       {\n           ValidateIssuer = true, ValidateAudience = true,\n           ValidateLifetime = true, ValidateIssuerSigningKey = true,\n           ValidIssuer = issuer, ValidAudience = audience, IssuerSigningKey = key,\n           ClockSkew = TimeSpan.FromMinutes(2)\n       };\n   })\n   // 3) Windows/AD (used only by your /LdapLogin endpoint to mint a JWT)\n   .AddNegotiate()\n   // 4) Identity cookies used only for the external roundtrip (no API auth!)\n   .AddCookie(IdentityConstants.ApplicationScheme, o =&gt;\n   {\n       // prevent HTML redirects for API calls\n       o.Events.OnRedirectToLogin = ctx =&gt; { ctx.Response.StatusCode = 401; return Task.CompletedTask; };\n       o.Cookie.SameSite = SameSiteMode.Lax;\n       o.Cookie.SecurePolicy = CookieSecurePolicy.Always;\n   })\n   .AddCookie(IdentityConstants.ExternalScheme, o =&gt;\n   {\n       // External handshake cookie must be cross-site\n       o.Cookie.SameSite = SameSiteMode.None;\n       o.Cookie.SecurePolicy = CookieSecurePolicy.Always;\n   })\n   // 5) External providers\n   .AddGoogle(\"Google\", o =&gt;\n   {\n       o.ClientId     = cfg[\"ExAuthentication:Google:ClientId\"]!;\n       o.ClientSecret = cfg[\"ExAuthentication:Google:ClientSecret\"]!;\n       o.CallbackPath = \"/signin-google\";                 // must match in Google console\n       o.SignInScheme = IdentityConstants.ExternalScheme; // VERY important\n       o.SaveTokens   = true;\n       o.Scope.Add(\"email\");\n       o.Scope.Add(\"profile\");\n   });\n\n   // (optional) if you add Facebook:\n   // .AddFacebook(\"Facebook\", o =&gt; { ... o.SignInScheme = IdentityConstants.ExternalScheme; });\n\n   builder.Services.AddAuthorization(o =&gt; o.FallbackPolicy = o.DefaultPolicy);\n   builder.Services.AddControllers();\n\n   var app = builder.Build();\n\n   app.UseHttpsRedirection();\n   app.UseRouting();\n   app.UseAuthentication();\n   app.UseAuthorization();\n   app.MapControllers();\n   app.Run();\n</code></pre> <p>Enable both Windows Authentication and Anonymous so your login routes (and Google callback) are reachable. Your API stays protected by JWT because [Authorize] defaults to Bearer.</p> </li> <li>Helper: create JWT    <pre><code>   private string CreateJwt(IEnumerable&lt;Claim&gt; claims, string issuer, string audience, SecurityKey key, TimeSpan lifetime)\n   {\n       var creds = new SigningCredentials(key, SecurityAlgorithms.HmacSha256);\n       var token = new JwtSecurityToken(\n           issuer, audience, claims,\n           notBefore: DateTime.UtcNow,\n           expires: DateTime.UtcNow.Add(lifetime),\n           signingCredentials: creds);\n       return new JwtSecurityTokenHandler().WriteToken(token);\n   }\n</code></pre></li> <li>Windows/AD \u2192 JWT (LdapLogin)    <pre><code>   using Microsoft.AspNetCore.Authentication;\n   using Microsoft.AspNetCore.Authentication.Negotiate;\n   using Microsoft.AspNetCore.Authorization;\n\n   [ApiController]\n   [Route(\"account\")]\n   public class AccountController : ControllerBase\n   {\n       private readonly IConfiguration _cfg;\n       private readonly SecurityKey _signingKey;\n       public AccountController(IConfiguration cfg)\n       {\n           _cfg = cfg;\n           _signingKey = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(_cfg[\"Jwt:Key\"]!));\n       }\n\n       [HttpPost(\"LdapLogin\")]\n       [AllowAnonymous] // we'll trigger Negotiate ourselves\n       public async Task&lt;IActionResult&gt; LdapLogin([FromBody] LdapUserModel model)\n       {\n           // Force a Negotiate challenge if not already authenticated\n           var result = await HttpContext.AuthenticateAsync(NegotiateDefaults.AuthenticationScheme);\n           if (!result.Succeeded)\n               return Challenge(new AuthenticationProperties { RedirectUri = Url.Action(nameof(LdapLogin)) },\n                                NegotiateDefaults.AuthenticationScheme);\n\n           // Windows user is authenticated now\n           var principal = result.Principal!;\n           var name = principal.Identity?.Name; // e.g., \"DOMAIN\\\\user\"\n\n           // (Optional) enforce domain or AD group membership here before issuing JWT\n\n           // Build JWT claims (add what you need)\n           var claims = new List&lt;Claim&gt;\n           {\n               new Claim(ClaimTypes.Name, name ?? string.Empty),\n               new Claim(\"amr\", \"windows\") // auth method reference\n           };\n           var token = CreateJwt(claims,\n               _cfg[\"Jwt:Issuer\"]!, _cfg[\"Jwt:Audience\"]!, _signingKey, TimeSpan.FromHours(8));\n\n           return Ok(new { token, token_type = \"Bearer\" });\n       }\n   }\n</code></pre></li> <li>List external schemes (Google/Facebook)    <pre><code>   private readonly IAuthenticationSchemeProvider _schemes;\n   public AccountController(IAuthenticationSchemeProvider schemes, IConfiguration cfg) { _schemes = schemes; _cfg = cfg; ... }\n\n   [HttpGet(\"GetExternalAuthenticationSchemes\")]\n   [AllowAnonymous]\n   public async Task&lt;IActionResult&gt; GetExternalAuthenticationSchemes()\n   {\n       var all = await _schemes.GetAllSchemesAsync();\n       var externals = all.Where(s =&gt; !string.IsNullOrEmpty(s.DisplayName)); // typically \"Google\",\"Facebook\"\n       var data = externals.Select(s =&gt; new { s.DisplayName, AuthenticationScheme = s.Name });\n       return Ok(new ResponseModel { Status = ResponseStatusEnum.Success, Message = \"OK\", Data = data });\n   }\n</code></pre></li> <li>External login start (Google/Facebook) \u2192 redirect back to the domain    <pre><code>   [HttpGet(\"ExternalLogin\")]\n   [AllowAnonymous]\n   public IActionResult ExternalLogin(string provider, string? returnUrl = \"/\")\n   {\n       // MUST be same-origin as this API (no domain change!)\n       var callbackUrl = Url.Action(nameof(ExternalLoginCallback), \"Account\", new { returnUrl }, Request.Scheme)!;\n\n       var props = _signInManager.ConfigureExternalAuthenticationProperties(provider, callbackUrl);\n       return Challenge(props, provider); // provider name must match AddGoogle(\"Google\") etc.\n   }\n</code></pre></li> <li>External callback \u2192 create (or find) user \u2192 issue JWT (and only then redirect to front-end)    <pre><code>   [HttpGet(\"ExternalLoginCallback\")]\n   [AllowAnonymous]\n   public async Task&lt;IActionResult&gt; ExternalLoginCallback(string? returnUrl = \"/\", string? remoteError = null)\n   {\n       if (!string.IsNullOrEmpty(remoteError))\n           return BadRequest(new { Message = $\"External error: {remoteError}\" });\n\n       var info = await _signInManager.GetExternalLoginInfoAsync();\n       if (info is null)\n           return BadRequest(new { Message = \"No external login info (check callback path, cookies SameSite=None, same domain)\" });\n\n       // Try sign-in by external login\n       var signIn = await _signInManager.ExternalLoginSignInAsync(info.LoginProvider, info.ProviderKey, isPersistent:false);\n       ApplicationUser? user;\n\n       if (signIn.Succeeded)\n       {\n           user = await _userManager.FindByLoginAsync(info.LoginProvider, info.ProviderKey);\n       }\n       else\n       {\n           // Create the user if not exists\n           var email = info.Principal.FindFirstValue(ClaimTypes.Email) ?? $\"{info.ProviderKey}@external.local\";\n           user = await _userManager.FindByEmailAsync(email);\n           if (user is null)\n           {\n               user = new ApplicationUser { UserName = email, Email = email, EmailConfirmed = true };\n               var create = await _userManager.CreateAsync(user);\n               if (!create.Succeeded) return BadRequest(create.Errors);\n           }\n           var addLogin = await _userManager.AddLoginAsync(user, info);\n           if (!addLogin.Succeeded) return BadRequest(addLogin.Errors);\n           // Optional: await _signInManager.SignInAsync(user, isPersistent:false); // not needed for APIs\n       }\n\n       // Build JWT claims\n       var claims = new List&lt;Claim&gt;\n       {\n           new Claim(JwtRegisteredClaimNames.Sub, user!.Id),\n           new Claim(ClaimTypes.Name, user.UserName ?? user.Email ?? \"\"),\n           new Claim(JwtRegisteredClaimNames.Email, user.Email ?? \"\"),\n           new Claim(\"amr\", info.LoginProvider.ToLowerInvariant()) // e.g. \"google\"\n       };\n       // add roles / your app claims here if needed\n\n       var token = CreateJwt(claims, issuer, audience, key, TimeSpan.FromHours(8));\n\n       // If a front-end needs a redirect, you can append the token (or your encrypted blob)\n       // Make sure returnUrl is validated/whitelisted to avoid open redirect\n       var safeReturn = string.IsNullOrEmpty(returnUrl) ? \"/\" : returnUrl;\n       return Ok(new { token, token_type = \"Bearer\", returnUrl = safeReturn });\n\n       // Or:\n       // return Redirect($\"{safeReturn}#token={Uri.EscapeDataString(token)}\");\n   }\n</code></pre> <p>If you must keep your current \u201cencrypt data &amp; redirect\u201d approach, still do the handshake on the same origin first; then from the callback, redirect to the front-end with your encrypted payload. The key is: don\u2019t cross domains before _GetExternalLoginInfoAsync().</p> </li> <li>listing external providers without SignInManager    <pre><code>   [HttpGet(\"external-schemes\")]\n   [AllowAnonymous]\n   public async Task&lt;IActionResult&gt; ExternalSchemes([FromServices] IAuthenticationSchemeProvider schemeProvider)\n   {\n       var schemes = await schemeProvider.GetAllSchemesAsync();\n       var list = schemes.Where(s =&gt; !string.IsNullOrEmpty(s.DisplayName))\n                         .Select(s =&gt; new { s.DisplayName, AuthenticationScheme = s.Name });\n       return Ok(list);\n   }\n</code></pre></li> </ol>"},{"location":"backend/csharp/azure-insights/","title":"Azure Application Insights","text":""},{"location":"backend/csharp/azure-insights/#install-packages","title":"Install Packages","text":"<pre><code>dotnet add package Microsoft.ApplicationInsights.AspNetCore\n</code></pre>"},{"location":"backend/csharp/azure-insights/#configure","title":"Configure","text":"Program.cs<pre><code>using Microsoft.ApplicationInsights;\n\nvar builder = WebApplication.CreateBuilder(args);\n\n// Enable Application Insights\nbuilder.Services.AddApplicationInsightsTelemetry(\n    builder.Configuration[\"ApplicationInsights:ConnectionString\"]);\n\nbuilder.Services.AddSingleton&lt;WeatherService&gt;();\n\nvar app = builder.Build();\n\napp.MapGet(\"/\", () =&gt; \"Hello World with App Insights!\");\n\napp.MapGet(\"/weather\", (WeatherService service) =&gt;\n{\n    service.GetWeather();\n    return Results.Ok(\"Weather checked and telemetry sent!\");\n});\n\napp.Run();\n\npublic class WeatherService\n{\n    private readonly TelemetryClient _telemetry;\n\n    public WeatherService(TelemetryClient telemetry)\n    {\n        _telemetry = telemetry;\n    }\n\n    public void GetWeather()\n    {\n        // Track custom event\n        _telemetry.TrackEvent(\"GetWeatherCalled\");\n\n        // Track custom metric\n        _telemetry.GetMetric(\"WeatherRequests\").TrackValue(1);\n\n        // Simulate error\n        try\n        {\n            throw new Exception(\"Test Exception from WeatherService!\");\n        }\n        catch (Exception ex)\n        {\n            _telemetry.TrackException(ex);\n        }\n    }\n}\n</code></pre>"},{"location":"backend/csharp/azure-insights/#add-connectionstring","title":"Add ConnectionString","text":"appsettings.json<pre><code>{\n  \"ApplicationInsights\": {\n    \"ConnectionString\": \"InstrumentationKey=xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx;IngestionEndpoint=https://&lt;region&gt;.in.applicationinsights.azure.com/\"\n  },\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\",\n      \"Microsoft.AspNetCore\": \"Warning\"\n    }\n  },\n  \"AllowedHosts\": \"*\"\n}\n</code></pre> <ul> <li> <p>Visit /weather \u2192 This will trigger events, metrics, and a sample exception.</p> </li> <li> <p>Open Azure Portal \u2192 Application Insights \u2192 Logs / Live Metrics.</p> </li> <li> <p>You\u2019ll see your requests, events, and errors streaming in real-time. \ud83c\udf89</p> </li> </ul>"},{"location":"backend/csharp/azure-insights/#querying-telemetry-with-kql","title":"Querying Telemetry with KQL","text":"<p>-Application Insights uses Kusto Query Language (KQL) for analyzing telemetry data. For example, </p>"},{"location":"backend/csharp/azure-insights/#see-all-failed-requests","title":"see all failed requests:","text":"<pre><code>requests\n| where success == false\n| order by timestamp desc\n</code></pre>"},{"location":"backend/csharp/azure-insights/#find-the-top-5-slowest-endpoints","title":"find the top 5 slowest endpoints","text":"<pre><code>requests\n| summarize avg(duration) by name\n| top 5 by avg_duration desc\n</code></pre>"},{"location":"backend/csharp/connection-string/","title":"Connection String","text":""},{"location":"backend/csharp/connection-string/#sql-server","title":"SQL Server","text":"<p>!!! note \"Valid SSL certificate\"       - Use a comma to specify a port number with SQL Server: <code>mycomputer.test.xxx.com,1234</code>       - It's not necessary to specify an instance name when specifying the port.</p> AppSettings<pre><code>\"ConnectionStrings\": {\n      \"DBConnection\": \"Server=myServerAddress;Database=myDataBase;User Id=myUsername;Password=myPassword;Encrypt=True;TrustServerCertificate=False;\"\n}\n</code></pre> <p>!!! note \"Valid SSL certificate\"       - Make sure the SQL Server uses a valid SSL certificate:       - Get a Valid SSL Certificate       - Assign the Certificate to SQL Server:  SQL Server Configuration Manager &gt; SQL Server Network Configuration &gt; Protocols for MSSQLSERVER (or instance name) &gt; Right-click \"Properties\" &gt; Certificate tab       - Enable Force Encryption (Optional but Recommended):  SQL Server Configuration Manager &gt; under Protocols for MSSQLSERVER &gt; Right-click &gt; Properties &gt; Under the Flags tab, set Force Encryption to Yes</p> Program.cs<pre><code>//Configure DB Context\n//----------------------------------------\nbuilder.Services.AddDbContext&lt;DBContext&gt;(options =&gt;\n{\n    options.UseSqlServer(builder.Configuration.GetConnectionString(\"DBConnection\"));\n});\n</code></pre>"},{"location":"backend/csharp/connection-string/#postgresql","title":"PostgreSQL","text":"<p>AppSettings<pre><code>\"ConnectionStrings\": {\n  \"DBConnection\": \"User ID=postgres;Password=***;Host=localhost;Port=5432;Database=DB1;Pooling=true;\"\n}\n</code></pre> Program.cs<pre><code>//Configure DB Context\n//----------------------------------------\nbuilder.Services.AddDbContext&lt;DBContext&gt;(options =&gt;\n{\n    options.UseNpgsql(builder.Configuration.GetConnectionString(\"DBConnection\"));\n}, ServiceLifetime.Scoped);\n</code></pre></p>"},{"location":"backend/csharp/controller-attrib/","title":"Controller's Attribute","text":""},{"location":"backend/csharp/controller-attrib/#rest-api-settings","title":"REST API Settings","text":"program.cs<pre><code>var builder = WebApplication.CreateBuilder(args);\n\nbuilder.Services.AddControllers();\n\nvar app = builder.Build();\n\napp.UseHttpsRedirection();\n\napp.UseAuthorization();\n\napp.MapControllers();\n\napp.Run();\n</code></pre>"},{"location":"backend/csharp/controller-attrib/#attributes","title":"Attributes","text":"<p>Controllers<pre><code> [ApiController]\n [Route(\"[controller]\")]\n</code></pre> Actions<pre><code> [Authorize]\n [AllowAnonymous]\n [HttpGet]\n [HttpPost]\n [Route(\"Index\")]\n [ActionName(\"Confirm\")]\n</code></pre> Preventing a Public Method from Being Invoked<pre><code>[NonAction]\n</code></pre></p>"},{"location":"backend/csharp/ef/","title":"Entity Framework","text":""},{"location":"backend/csharp/ef/#install-packages","title":"Install Packages","text":"<p><pre><code>Microsoft.EntityFrameworkCore\n</code></pre> <pre><code>Microsoft.EntityFrameworkCore.Tools\n</code></pre> <pre><code>Microsoft.EntityFrameworkCore.SqlServer\n</code></pre></p>"},{"location":"backend/csharp/ef/#add-di","title":"Add DI","text":"<pre><code>builder.Services.AddDbContext&lt;AppDBContext&gt;(options =&gt;\n  options.UseSqlServer(builder.Configuration.GetConnectionString(\"DefaultConnectionString\"))\n);\n</code></pre>"},{"location":"backend/csharp/ef/#code-first","title":"Code First","text":""},{"location":"backend/csharp/ef/#create-model","title":"Create Model","text":"<pre><code>public class Item\n{\n    public int ID { get; set; } \n    public string Title { get; set; }\n}\n</code></pre>"},{"location":"backend/csharp/ef/#create-dbcontext-model","title":"Create DBContext Model","text":"<pre><code>public class AppDBContext : DbContext\n{\n    public AppDBContext(DbContextOptions&lt;AppDBContext&gt; options) : base(options) { }\n\n    public DbSet&lt;Item&gt; Items { get; set; }\n}\n</code></pre>"},{"location":"backend/csharp/ef/#package-manager-console-cmd","title":"Package Manager Console CMD","text":"<p><pre><code>Add-Migration \"Initial Migration\"\n</code></pre> <pre><code>Update-Database\n</code></pre></p>"},{"location":"backend/csharp/ef/#database-first","title":"Database First","text":""},{"location":"backend/csharp/ef/#package-manager-console-cmd_1","title":"Package Manager Console CMD","text":"<pre><code>Scaffold-DbContext \"Connection String\" Microsoft.EntityFrameworkCore.SqlServer -ContextDir DataFolder -OutputDir Models -DataAnnotation\n</code></pre>"},{"location":"backend/csharp/ef/#usage","title":"Usage","text":"<pre><code>private readonly AppDBContext _context;\n</code></pre>"},{"location":"backend/csharp/ef/#linq-to-sql","title":"Linq to SQL","text":"<pre><code>using (var dbContext = new DbContext())\n{\n  var query = dbContext.Users\n     .Where(u=&gt;u.Age&gt;5)\n     .Orderby (u=&gt;u.Name);\n  string query = query.ToQueryString();\n  Console.WriteLine(query);\n}\n</code></pre>"},{"location":"backend/csharp/ef/#global-query-filter","title":"Global Query Filter","text":"<p>BlogContext.cs<pre><code>public class BlogContext : DbContext\n{\n  protected override void OnConfiguring(ModelBuilder modelBuilder)\n  {\n    modelBuilder.Entity&lt;Blog&gt;().HasQueryFilters().ToListAsync();\n  }\n}\n</code></pre> To disable it<pre><code>val allBlogs = await _context.Blogs.IgnoreQueryFilters().ToListAsync();\n</code></pre></p>"},{"location":"backend/csharp/email-service-cloud/","title":"Mailing Services","text":"<p>1- In-house email services  2- Cloud-based email services </p>"},{"location":"backend/csharp/email-service-cloud/#cloud-services-benefits","title":"Cloud services benefits","text":"<ul> <li>Lower cost</li> <li>Updates</li> <li>Security</li> <li>Pay as you go</li> <li>Expertise</li> <li>Scalability</li> </ul>"},{"location":"backend/csharp/email-service-cloud/#common-mailing-services","title":"Common mailing services","text":"<ul> <li>SendGrid</li> <li>Mandrill</li> <li>Mailgun</li> </ul>"},{"location":"backend/csharp/email-service-cloud/#setup-sendgrid","title":"Setup SendGrid","text":"<p>1- Create an account : https://sendgrid.com  2- Create Sender Identity  3- Reteieve an API Key </p>"},{"location":"backend/csharp/email-service-cloud/#development-env","title":"Development Env","text":"<p>1- Install Sendgrid NuGet package  2- Add API Key to appsettings.json  3- Add IEmailService.cs and EmailService.cs </p> appsettings.json<pre><code>\"SendGrid\":{\n  \"ApiKey\" : \"xxx\"\n},\n</code></pre> \\Data\\ViewModels<pre><code>public class ComposeEmailModel\n{\n  public string Firstname {get;set;}\n  public string Lastname {get;set;}\n  public string Subject {get;set;}\n  public string Email {get;set;}\n  public string Body   {get;set;}\n\n  public IFormFile Attachmetn {get;set;}\n}\n</code></pre> <p>\\Services\\IEmailService.cs<pre><code>public class IEmailService\n{\n  Task&lt;Response&gt; SendSingleEmail(ComposeEmailModel payload);\n  Task&lt;Response&gt; SendMultipleEmails();\n}\n</code></pre> \\Services\\EmailService.cs<pre><code>public class EmailService: IEmailService\n{\n  private readonly IConfiguration _configuration;\n  public EmailService(IConfiguration configuration)\n  {\n    _configuration = configuration;\n  }\n  public Task&lt;Response&gt; SendSingleEmail(ComposeEmailModel payload)\n  {\n    var apiKey = _configuration.GetSection(\"SendGrid\")[\"ApiKey\"];\n    var client = new SendGridClient(apiKey);\n    var from = new EmailAddress(senderEmailAddress, senderName);\n    var subject = payload.Subject;\n    var to = new EmailAddress(receiverEmailAddress, $\"{payload.Firstname} {payload.Lastname}\");\n    var textContent = payload.Body;\n    var htmlContent = $\"&lt;strong&gt;{payload.Body}&lt;/strong&gt;\";\n    var msg = MailHelper.CreateSingleEmail(from, to, textContent, htmlContent);\n    if (payload.Attachment!=null &amp;&amp; payload.Attachment.Length&gt;0)\n    {\n      var fileContent =\"\";\n      using(var reader = new StreamReader(payload.Attachment.OpenReadStream()))\n      {\n        fileContent = reader.ReadToEnd().ToString();\n        byteData = Encoding.ASCII.GetBytes(fileContent);\n      }\n      Attachment attachment = new Attachment()\n      {\n        Content = Convert.ToBase64String(byteData);\n        Filename = payload.Attachment.FileName,\n        Type = payload.Attachment.ContentType,\n        Disposition = \"attachment\"\n      };\n      msg.AddAttachment(attachment);\n    }\n    var response = client.SendEmailAsync(msg);\n    response.wait();\n    var result = response.Result;\n    // Store the result in th DB\n    IEnumerable&lt;string&gt; headerValues;\n    var sendGridMessageID = string.Empty;\n    if(result.Headers.TryGetValues(\"X-Message-ID\", out headerValues))\n    {\n      sendGridMessageID = headerValues.FirstOrDefault();\n      if (!string.IsNullOrEmpty(sendGridMessageID))\n      {\n        var newEmail = new Email()\n        {\n          EmailAddress = payload.Email,\n          Fullname = $\"{payload.Firstname} {payload.Lastname}\",\n          SendGridKey = sendGridMessageID,\n          Status = \"n/a\"\n        };\n        _context.Email.Add(newEmail);\n        _context.SaveChanges();\n      }\n    }\n    return response;\n  }\n\n  public Task&lt;Response&gt; SendMultipleEmails()\n  {\n    var apiKey = _configuration.GetSection(\"SendGrid\")[\"ApiKey\"];\n    var client = new SendGridClient(apiKey);\n    var from = new EmailAddress(senderEmailAddress, senderName);\n    var subject = \"Test Sub\";\n    var tos = new List&lt;EmailAddress&gt;(){\n      new EmailAddress(\"Email1\", \"Name1\"),\n      new EmailAddress(\"Email2\", \"Name2\")\n    };\n    var textContent = \"Body\";\n    var htmlContent = $\"&lt;strong&gt;Body&lt;/strong&gt;\";\n    var msg = MailHelper.CreateSingleEmailToMultipleRecipients(from, tos, textContent, htmlContent);\n    var response = client.SendEmailAsync(msg);\n    response.wait();\n    var result = response.Result;\n    return response;\n  }\n}\n</code></pre> program.cs<pre><code>builder.Services.AddTransient&lt;IEmailService, EmailService&gt;();\n</code></pre></p>"},{"location":"backend/csharp/email-service-cloud/#webhook","title":"Webhook","text":"<ul> <li>Webhooks only work on HTTP or HTTPs and points rhich run on production envirinment.</li> <li>So to be able to run a localhost in a production-like environment, we use a toll named \"ngrok\"</li> <li>ngrok is a cross-platform application that enables developers tp expose a local development</li> </ul>"},{"location":"backend/csharp/email-service-cloud/#setup-ngrok","title":"Setup ngrok","text":"<p>1- Setup an Account: https://ngrok.com  2- Install ngrok  3- Create a Tunnel  4- Run VS as Administrator &gt; Tools &gt; Start ngrok Tunnel </p>"},{"location":"backend/csharp/email-service-cloud/#add-event-webhook","title":"Add Event Webhook","text":"<p>SendGridEvents.cs<pre><code>public class SendGridEvents\n{\n  public string email { get; set; }\n  public long timestamp { get; set; }\n  public string @event { get; set; }\n  [JsonPropertt(\"smtp-id\")]\n  public string smtp_id { get; set; }\n  public string useragent { get; set; }\n  public string ip { get; set; }\n  public string sg_event_id { get; set; }\n  public string sg_message_id { get; set; }\n  public string reason { get; set; }\n  public string status { get; set; }\n  public string  response { get; set; }\n  public string  tls { get; set; }\n  public Uri url { get; set; }\n  public string urloffset { get; set; }\n  public string attempt { get; set; }\n  public string category { get; set; }\n  public string type { get; set; }\n}\n</code></pre> Add an Empty API Controller<pre><code>private readonly AppDbContext _context;\npublic ctor (AppDbContext context)\n{\n  _context = context;\n}\n[HttpPost]\n[Route(\"Webhook\")]\npublic IActionResult WebHook (List&lt;SendGridEvents&gt; data)\n{\n  var debug = data;\n  foreach(var item in data)\n  {\n    var dbEmail = _context.Email.FirstOrDefault(n =&gt; item.sg_message_id.StartsWith(n.SenGridKey));\n    if(dbEmail!=null)\n    {\n      dbEmail.Status = item.@event;\n      _context.SaveChanges();\n    }\n  }\n  return Ok (debug);\n}\n</code></pre></p>"},{"location":"backend/csharp/email-service/","title":"Email Service","text":""},{"location":"backend/csharp/email-service/#net-core","title":".Net Core","text":"<pre><code>Install-Package MimeKit\nInstall-Package MailKit\n</code></pre> <pre><code> public interface IEmailSender\n {\n     Task SendEmailAsync(string emailAddress, string subject, string body);\n }\n</code></pre> <pre><code>  public class MyEmailSender : IEmailSender\n  {\n     private readonly IConfiguration _config;\n\n     public MyEmailSender(IConfiguration config)\n     {\n         _config = config;\n     }\n\n     public MyEmailSender () : this(new ConfigurationBuilder().Build())\n     {\n         _config = new ConfigurationBuilder().Build();\n     }\n\n     public async Task SendEmailAsync(string emailAddress, string subject, string body)\n     {\n        try\n        {\n            var message = new MimeMessage();\n\n            // Configure the sender\n            message.From.Add(new MailboxAddress(\".::GrammFit::.\", \n                            _config.GetSection(\"EmailSettings:NoReply:SmtpAddress\").Value));\n            // Configure the recipient\n            message.To.Add(new MailboxAddress(string.Empty, emailAddress));\n            // Set the subject\n            message.Subject = subject;\n\n            // Add the email body\n            var textPart = new TextPart(MimeKit.Text.TextFormat.Html)\n            {\n                Text = body\n            };\n\n            message.Body = textPart;\n\n            using (var client = new SmtpClient())\n            {\n                // Set up server certificate validation callback\n                client.ServerCertificateValidationCallback = (s, c, h, e) =&gt; true;\n\n                // Connect to the SMTP server with the appropriate security options\n                await client.ConnectAsync(\n                    _config.GetSection(\"EmailSettings:NoReply:SmtpServer\").Value,\n                    int.Parse(_config.GetSection(\"EmailSettings:NoReply:SmtpPort\").Value ?? \"587\"),\n                    SecureSocketOptions.StartTls);\n\n                // Authenticate with the server\n                await client.AuthenticateAsync(\n                    _config.GetSection(\"EmailSettings:NoReply:SmtpUsername\").Value,\n                    _config.GetSection(\"EmailSettings:NoReply:SmtpPassword\").Value);\n\n                // Send the email\n                await client.SendAsync(message);\n\n                // Disconnect cleanly\n                await client.DisconnectAsync(true);\n            }\n        }\n        catch (Exception ex)\n        {\n            Console.WriteLine($\"Email sending error: {ex}\");\n            throw;\n        }\n     }\n   }\n</code></pre> program.cs<pre><code> builder.Services.AddTransient&lt;MyEmailSender&gt;();\n</code></pre>"},{"location":"backend/csharp/email-service/#aspnet-mvc","title":"ASP.Net MVC","text":"<pre><code>using System.Net.Mail;\nusing System.Net.Mime;\n\n SmtpClient mailer = new SmtpClient();\n\n public bool SendMail(string mailTo, string subject, string body, Stream attachment= null)\n {\n     if (!ValidateMailAddress(mailTo)) { return false; }\n\n\n     try\n     {\n\n         ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls13 | SecurityProtocolType.Tls12;\n         var login = new NetworkCredential();\n         login.UserName = \"noreply\";\n         login.Password = \"***\";\n         mailer.UseDefaultCredentials = false;\n         mailer.Host = \"mail.****.com\";\n         mailer.Port = 587;\n         mailer.EnableSsl = false;\n         mailer.Credentials = login;\n\n         var mail = new MailMessage();\n         mail.From = new MailAddress(\"noreply@***.com\");\n         mail.To.Add(mailTo);\n         mail.Subject = subject;\n         mail.Body = body;\n         mail.IsBodyHtml = true;\n\n         if (attachment!= null)\n         {\n             var data = new Attachment(attachment, MediaTypeNames.Application.Octet);\n             var disposition = data.ContentDisposition;\n             disposition.CreationDate = DateTime.Now;\n             disposition.ModificationDate = DateTime.Now;\n             disposition.ReadDate = DateTime.Now;\n             mail.Attachments.Add(data);\n         }\n\n         mailer.Send(mail);\n         return true;\n     }\n     catch (Exception)\n     {\n         return false;\n     }\n }\n</code></pre>"},{"location":"backend/csharp/exception-custom/","title":"Exception Customization","text":"TestException.cs<pre><code>public class TestException : Exception\n{\n  public string Val;\n  public TestException()\n  {\n\n  }\n  public TestException(string message) : base(message)\n  {\n\n  }\n  public TestException(string message, Exception innerException) : base(message, innerException)\n  {\n\n  }\n  public TestException(string message, string val) : base(message)\n  {\n      Val = val;\n  }\n}\n</code></pre> <pre><code>try\n{\n  if (RegEx.IsMatch(value, @\"^\\d\")) throw new TestException(\"Value is a digit\", value);\n}\ncatch(TestException ex)\n{\n  return BadRequest(ex.Message, ex.Value);\n}\n</code></pre>"},{"location":"backend/csharp/exception-filter/","title":"Exception Filter","text":""},{"location":"backend/csharp/exception-filter/#filter-types","title":"Filter Types","text":"<ul> <li>Authorization filters </li> <li>Resources filters (run right after the authorization filters and useful for caching and performance)</li> <li>Action filters (run right before and after the action method)</li> <li>Exception filters (to handle the exceptions before the response body is populated)</li> <li>Result filters (run before and after the execution of the action methods result)</li> </ul>"},{"location":"backend/csharp/exception-filter/#create-exp-filter","title":"Create Exp filter","text":"<ul> <li>In the \"Exceptions\" Folder create another Folder named \"Filters\":</li> </ul> CustomExceptionFilter.cs<pre><code>[AttributeUsage(AttributeTargets.Class | AttributeRargets.Method)] \npublic class CustomExceptionFilter : ExceptionFilterAttribute\n{\n  public override void OnException(ExceptionContext context)\n  {\n    context.HttpContext.Response.ContentType = \"application/json\";\n    var statusCode = HttpStatusCode.InternalServerError;\n    if(context.Exception is TestException)\n    {\n      statusCode = HttpStatusCode.NotFound;\n    }\n    var expString = new ErrorResponseData()\n    {\n      StatusCode = (int)stausCode,\n      Message = context.Exception.Message,\n      Path = context.Exception.StackTrace\n    };\n    context.Result = new JsonResult(expString);\n  }\n}\n</code></pre>"},{"location":"backend/csharp/exception-filter/#use-exp-filter","title":"Use Exp filter","text":"<ul> <li>Just use as an \"Attribute\" on top of each method in the controller for example.</li> </ul>"},{"location":"backend/csharp/exception-handler/","title":"Exception Handler","text":""},{"location":"backend/csharp/exception-handler/#create-exp-handler","title":"Create Exp Handler","text":"<pre><code>public class ErrorResponseData\n{\n  public int StatusCode {get;set}\n  public string Message {get;set;}\n  public string Path {get;set;}\n\n  public override string ToString()\n  {\n    return JsonConvert.SerializeObject(this);\n  }\n}\n</code></pre>"},{"location":"backend/csharp/exception-handler/#exp-handler-extension","title":"Exp Handler Extension","text":"<pre><code>public static class ExceptionMiddlewareExtensions\n{\n  public static void ConfigureBuiltInExceptionHandler(this IApplicationBuilder app)\n  {\n    app.UseExceptionHandler(appError =&gt;\n    {\n      appError.Run(async context =&gt;\n      {\n        var contextFeature = context.Features.Get&lt;IExceptionHandlerFeature&gt;();\n        var contextRequest = context.Features.Get&lt;IHttpRequestFeature&gt;();\n\n        context.Response.ContentType = \"application/json\";\n\n        if (contextFeature != null)\n        {\n          var errorString = new ErrorResponseData()\n            {\n              StatusCode = (int)HttpStatusCode.InternalError,\n              Message = contextFeature.Error.Message,\n              Path = contextRequest.Path\n            }.ToString();\n          await context.Response.WriteAsync(errorString);\n        }\n      });\n    });\n  }\n</code></pre>"},{"location":"backend/csharp/exception-handler/#configure-exp-handler","title":"Configure Exp Handler","text":"Program.cs<pre><code>app.UseAuthorization();\napp.ConfigureBuiltInExceptionHandler();\n</code></pre>"},{"location":"backend/csharp/exception-handler/#create-custom-exp-handler","title":"Create Custom Exp Handler","text":"<pre><code>public class CustomExceptionHandler\n{\n  private readonly RequestDelegate _next;\n\n  public CustomExceptionHandler(RequestDelegate next)\n  {\n    _next=next;\n  }\n\n  public async Task InvokeAsync(HttpContext httpContext)\n  {\n    try\n    {\n      await _next(httpContext);\n    }\n    catch (Exception ex)\n    {\n      await HandleExceptionAsync(httpContext, ex);\n    }\n  }\n\n  private Task HandleExceptionAsync(HttpContext httpContext, Exception ex)\n  {\n    httpContext.Response.ContentType = \"application/json\";\n    var errorMessageString = new ErrorResponseData()\n    {\n      StatusCode = (int)HttpStatusCode.InternalServerError,\n      Message = ex.Message,\n      Path = httpContext.Request.Path\n    }.ToString();\n    return httpContext.Response.WriteAsync(errorMessageString);\n  }\n}\n</code></pre>"},{"location":"backend/csharp/exception-handler/#custom-exp-handler-extension","title":"Custom Exp Handler Extension","text":"<ul> <li>In the ExceptionMiddlewareExtensions.cs class already we have an extension now we will add another one.</li> </ul> <pre><code> public static void ConfigureCustomExceptionHandler(this IApplicationBuilder app)\n  {\n    app.UseMiddleware&lt;CustomExceptionHandler&gt;();\n  }\n</code></pre>"},{"location":"backend/csharp/exception-handler/#configure-custom-exp-handler","title":"Configure Custom Exp Handler","text":"Program.cs<pre><code>app.UseAuthorization();\n//app.ConfigureBuiltInExceptionHandler();\napp.ConfigureCustomExceptionHandler();\n</code></pre>"},{"location":"backend/csharp/google-recaptcha/","title":"Google reCAPTCHA","text":""},{"location":"backend/csharp/google-recaptcha/#recaptcha-v2-component","title":"reCAPTCHA V2 component","text":""},{"location":"backend/csharp/google-recaptcha/#get-google-keys","title":"Get Google Keys","text":"<pre><code>[Create here](https://www.google.com/recaptcha/admin/create)\n</code></pre>"},{"location":"backend/csharp/google-recaptcha/#install","title":"Install","text":"<pre><code>dotnet add package reCAPTCHA.AspNetCore --version 3.0.10\nInstall-Package reCAPTCHA.AspNetCore \n</code></pre>"},{"location":"backend/csharp/google-recaptcha/#di","title":"DI","text":"program.cs<pre><code>builder.Services.AddRecaptcha(options =&gt;\n{\n  options.SiteKey = configuration.GetSection(\"reCAPTCHA:SiteKey\").Value;\n  options.SecretKey = configuration.GetSection(\"reCAPTCHA:SecretKey\").Value;\n});\n</code></pre>"},{"location":"backend/csharp/google-recaptcha/#add-reference","title":"Add reference","text":"<pre><code>&lt;script src=\"https://www.google.com/recaptcha/api.js?render=explicit\" async defer&gt;&lt;/script&gt;\n&lt;script src=\"/js/site.js\"&gt;&lt;/script&gt;\n</code></pre> <p>Two Captcha in one page</p> <p>set render=explicit No need to use two different siteKey and secret  set &amp;hl=de to change language. </p>"},{"location":"backend/csharp/google-recaptcha/#create-page","title":"Create Page","text":"RecaptchaComponent.razor<pre><code>@using reCAPTCHA.AspNetCore\n@inject IRecaptchaService RecaptchaService\n@inject IJSRuntime JSRuntime\n\n&lt;div id=\"@RecaptchaDivId\" class=\"g-recaptcha\" data-sitekey=\"@SiteKey\"&gt;&lt;/div&gt;\n\n@code {\n    [Parameter]\n    public string SiteKey { get; set; }\n\n    private string RecaptchaToken;\n    private string RecaptchaDivId;\n    private int widgetId;\n\n    protected override void OnInitialized()\n    {\n        RecaptchaDivId = $\"recaptcha_{Guid.NewGuid()}\";\n    }\n\n    protected override async Task OnAfterRenderAsync(bool firstRender)\n    {\n        if (firstRender)\n        {\n            widgetId = await JSRuntime.InvokeAsync&lt;int&gt;(\"renderRecaptcha\", RecaptchaDivId, SiteKey);\n        }\n    }\n\n    public async Task&lt;bool&gt; ValidateAsync()\n    {\n        RecaptchaToken = await JSRuntime.InvokeAsync&lt;string&gt;(\"getRecaptchaToken\", widgetId);\n        var result = await RecaptchaService.Validate(RecaptchaToken);\n        return result.success;\n    }\n\n     public async Task ResetRecaptchaAsync()\n {\n     await JSRuntime.InvokeVoidAsync(\"grecaptcha.reset\", widgetId);\n }\n}\n</code></pre>"},{"location":"backend/csharp/google-recaptcha/#add-js-file","title":"Add .js file","text":"<pre><code>window.renderRecaptcha = (elementId, siteKey) =&gt; {\n  var widgetId = grecaptcha.render(elementId, {\n  'sitekey': siteKey\n  });\n  return widgetId;\n  };\n\n  window.getRecaptchaToken = async (widgetId) =&gt; {\n  var recaptchaResponse = grecaptcha.getResponse(widgetId);\n  return recaptchaResponse;\n};\n</code></pre>"},{"location":"backend/csharp/google-recaptcha/#usage-in-page","title":"Usage in page","text":"<pre><code>@using reCAPTCHA.AspNetCore\n@inject IRecaptchaService RecaptchaService\n\n&lt;RecaptchaComponent @ref=\"ForgotPasswordRecaptcha\" SiteKey=\"***\" /&gt;\n\n@code{\n     @if (!String.IsNullOrEmpty(siteKey))\n   {\n     &lt;RecaptchaComponent @ref=\"recaptchaComponent\" SiteKey=@siteKey /&gt;\n   }\n}\n</code></pre>"},{"location":"backend/csharp/google-recaptcha/#validate","title":"Validate","text":"<pre><code>if (await ForgotPasswordRecaptcha.ValidateAsync())\n{\n}\n</code></pre>"},{"location":"backend/csharp/http-request/","title":"HTTP Requests","text":""},{"location":"backend/csharp/http-request/#send-request","title":"Send Request","text":"<p>Use <code>HttpClient</code> class to be able to send get or post http requests.</p> program.cs<pre><code>builder.Services.AddScoped&lt;HttpClient&gt;();\n</code></pre> <pre><code>public class Service\n{\n  private readonly HttpClient _httpClient;\n\n  public Service(IHttpClientFactory httpClientFactory)\n  {\n    _httpClient = httpClientFactory.CreateClient(\"UserApiClient\");\n  }\n}\n</code></pre>"},{"location":"backend/csharp/http-request/#get-request","title":"Get Request","text":""},{"location":"backend/csharp/http-request/#get-with-querystring","title":"Get with QueryString","text":"<pre><code> var response = await _httpClient.GetAsync($\"{this._apiBaseUrl}/Account/ReadUserProfile?email={email}\");\n</code></pre>"},{"location":"backend/csharp/http-request/#get-with-model","title":"Get with Model","text":"<p>Since GET requests don't have a body, the model's properties must be included in the URL as key-value pairs.</p> <pre><code>using System.Web; // Add a reference to System.Web for HttpUtility\n\npublic static string ToQueryString&lt;T&gt;(T obj)\n{\n    var properties = from p in typeof(T).GetProperties()\n                     where p.GetValue(obj, null) != null\n                     select $\"{HttpUtility.UrlEncode(p.Name)}={HttpUtility.UrlEncode(p.GetValue(obj, null).ToString())}\";\n    return string.Join(\"&amp;\", properties);\n}\n</code></pre> <pre><code>var model = new UserProfileRequest\n{\n    Email = \"example@example.com\",\n    Name = \"John Doe\"\n};\n\nvar queryString = ToQueryString(model);\nvar response = await _httpClient.GetAsync($\"{this._apiBaseUrl}/Account/ReadUserProfile?{queryString}\");\n</code></pre> <pre><code>using Microsoft.AspNetCore.Mvc;\n\n[ApiController]\n[Route(\"api/[controller]\")]\npublic class AccountController : ControllerBase\n{\n    [HttpGet(\"ReadUserProfile\")]\n    public IActionResult ReadUserProfile([FromQuery] UserProfileRequest model)\n    {\n        if (model == null)\n        {\n            return BadRequest(\"Invalid request model.\");\n        }\n    }\n}\n</code></pre>"},{"location":"backend/csharp/http-request/#post-request","title":"Post Request","text":""},{"location":"backend/csharp/http-request/#post-with-querystring","title":"Post with QueryString","text":"<pre><code> var response = await _httpClient.PostAsJsonAsync($\"{this._apiBaseUrl}/Account/Verify?email={email}&amp;code={code}\", new StringContent(\"\"));\n</code></pre>"},{"location":"backend/csharp/http-request/#post-with-model","title":"Post with Model","text":"<pre><code> var response = await _httpClient.PostAsJsonAsync($\"{this._apiBaseUrl}/Account/ForgotPassword\", new ForgotPasswordModel { Email = email });\n</code></pre>"},{"location":"backend/csharp/iis-virtualApp/","title":"Deploy to IIS","text":""},{"location":"backend/csharp/iis-virtualApp/#net-core-virtual-app","title":".Net Core - Virtual App","text":"<p>Dont change any directions...</p> program.cs<pre><code> var app = builder.Build();\n\napp.UsePathBase(\"/Vitual Path\");\n</code></pre> _Host.cshtml<pre><code>&lt;base href=\"~/\" /&gt;\n\n&lt;link rel=\"stylesheet\" href=\"_content/Radzen.Blazor/css/standard-base.css\"&gt;\n&lt;link rel=\"stylesheet\" href=\"~/css/bootstrap.min.css\" /&gt;\n&lt;link rel=\"stylesheet\" href=\"~/css/bootstrap-icons.min.css\" /&gt;\n&lt;link rel=\"stylesheet\" href=\"~/css/site.css\" /&gt;\n&lt;link rel=\"icon\" type=\"image/png\" href=\"favicon.png\" /&gt;\n\n&lt;script src=\"~/js/site.js\"&gt;&lt;/script&gt;\n</code></pre> css<pre><code>@font-face {\n    font-family: 'Poppins';\n    src: url('./fonts/Poppins-Regular.ttf') format('truetype');\n    font-weight: normal;\n    font-style: normal;\n}\n</code></pre>"},{"location":"backend/csharp/migrate-sqlserver/","title":"Migrate DB Context","text":""},{"location":"backend/csharp/migrate-sqlserver/#migrate-from-mysql-to-mssql","title":"Migrate from MySQL to MsSQL","text":""},{"location":"backend/csharp/migrate-sqlserver/#install-required-package","title":"Install required package","text":"<pre><code>Install Package Microsoft.EntityFrameworkCore.SqlServer\nInstall Package Microsoft.EntityFrameworkCore\nInstall Package Microsoft.EntityFrameworkCore.Tools\nInstall Package Microsoft.EntityFrameworkCore.Design\n</code></pre>"},{"location":"backend/csharp/migrate-sqlserver/#add-sql-server-db-context","title":"Add SQL Server DB Context","text":"<pre><code>public class SqlServerDbContext : DbContext\n{\n    private const string connectionString = @\"Server=.;Database=DB1;User Id=sa;Password=***;TrustServerCertificate=True\";\n\n    public SqlServerDbContext(DbContextOptions&lt;SqlServerDbContext&gt; options) : base(options) { }\n\n    public DbSet&lt;Arbeitgeber&gt; Arbeitgeber { get; set; }\n    public DbSet&lt;Arbeitgeberstammdaten&gt; Arbeitgeberstammdaten { get; set; }\n    public DbSet&lt;Beratung&gt; Beratungen { get; set; }\n    public DbSet&lt;GehaltsExtra&gt; GehaltsExtras { get; set; }\n    public DbSet&lt;Person&gt; Personen { get; set; }\n    public DbSet&lt;Profil&gt; Profile { get; set; }\n    public DbSet&lt;ProfilGehaltsExtra&gt; ProfilGehaltsExtras { get; set; }\n    public DbSet&lt;ProfilVorsorgevertrag&gt; ProfilVorsorgevertraege { get; set; }\n    public DbSet&lt;Vorsorgevertrag&gt; Vorsorgevertraege { get; set; }\n\n    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)\n    {\n        if (!optionsBuilder.IsConfigured)\n        {\n            optionsBuilder.UseSqlServer(connectionString);\n        }\n    }\n}\n</code></pre>"},{"location":"backend/csharp/migrate-sqlserver/#add-mysql-db-context","title":"Add MySQL DB Context","text":"<pre><code>public class MySqlDbContext : DbContext\n{\n    private const string connectionString = @\"Server=server.com;port=3306;Database=DB2;user=user;password=***\";\n    private readonly MariaDbServerVersion serverVersion = new(new Version(10, 5, 16));\n    public DbSet&lt;Arbeitgeber&gt; Arbeitgeber { get; set; }\n    public DbSet&lt;Arbeitgeberstammdaten&gt; Arbeitgeberstammdaten { get; set; }\n    public DbSet&lt;Beratung&gt; Beratungen { get; set; }\n    public DbSet&lt;GehaltsExtra&gt; GehaltsExtras { get; set; }\n    public DbSet&lt;Person&gt; Personen { get; set; }\n    public DbSet&lt;Profil&gt; Profile { get; set; }\n    public DbSet&lt;ProfilGehaltsExtra&gt; ProfilGehaltsExtras { get; set; }\n    public DbSet&lt;ProfilVorsorgevertrag&gt; ProfilVorsorgevertraege { get; set; }\n    public DbSet&lt;Vorsorgevertrag&gt; Vorsorgevertraege { get; set; }\n    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)\n    {\n        optionsBuilder.UseMySql(connectionString, serverVersion);\n    }\n}\n</code></pre>"},{"location":"backend/csharp/migrate-sqlserver/#add-migration-service","title":"Add migration service","text":"<pre><code>public class MigrationToSqlServerService\n{\n    private readonly MySqlDbContext _mySqlDbContext;\n    private readonly SqlServerDbContext _sqlServerDbContext;\n\n    public MigrationToSqlServerService()\n    {\n        _mySqlDbContext = new MySqlDbContext();\n\n        var sqlServerOptionsBuilder = new DbContextOptionsBuilder&lt;SqlServerDbContext&gt;();\n        sqlServerOptionsBuilder.UseSqlServer(\"Server=.;Database=SimsaTest;User Id=sa;Password=QAZqaz@123;TrustServerCertificate=True\");\n        _sqlServerDbContext = new SqlServerDbContext(sqlServerOptionsBuilder.Options);\n    }\n\n    //public MigrationToSqlServerService(SimsaDb mySqlDbContext, SqlServerDbContext sqlServerDbContext)\n    //{\n    //    _mySqlDbContext = mySqlDbContext;\n    //    _sqlServerDbContext = sqlServerDbContext;\n    //}\n\n    public async Task MigrateDataAsync()\n    {\n        await MigrateTableAsync&lt;Arbeitgeber&gt;(_mySqlDbContext.Arbeitgeber, _sqlServerDbContext.Arbeitgeber);\n        await MigrateTableAsync&lt;Arbeitgeberstammdaten&gt;(_mySqlDbContext.Arbeitgeberstammdaten, _sqlServerDbContext.Arbeitgeberstammdaten);\n        await MigrateTableAsync&lt;Beratung&gt;(_mySqlDbContext.Beratungen, _sqlServerDbContext.Beratungen);\n        await MigrateTableAsync&lt;GehaltsExtra&gt;(_mySqlDbContext.GehaltsExtras, _sqlServerDbContext.GehaltsExtras);\n        await MigrateTableAsync&lt;Person&gt;(_mySqlDbContext.Personen, _sqlServerDbContext.Personen);\n        await MigrateTableAsync&lt;Profil&gt;(_mySqlDbContext.Profile, _sqlServerDbContext.Profile);\n        await MigrateTableAsync&lt;ProfilGehaltsExtra&gt;(_mySqlDbContext.ProfilGehaltsExtras, _sqlServerDbContext.ProfilGehaltsExtras);\n        await MigrateTableAsync&lt;ProfilVorsorgevertrag&gt;(_mySqlDbContext.ProfilVorsorgevertraege, _sqlServerDbContext.ProfilVorsorgevertraege);\n        await MigrateTableAsync&lt;Vorsorgevertrag&gt;(_mySqlDbContext.Vorsorgevertraege, _sqlServerDbContext.Vorsorgevertraege);\n    }\n\n    private async Task MigrateTableAsync&lt;TEntity&gt;(DbSet&lt;TEntity&gt; source, DbSet&lt;TEntity&gt; destination) where TEntity : class\n    {\n        var tableName = _sqlServerDbContext.Model.FindEntityType(typeof(TEntity)).GetTableName();\n        var primaryKeyProperty = _sqlServerDbContext.Model.FindEntityType(typeof(TEntity)).FindPrimaryKey().Properties.FirstOrDefault();\n\n        var hasIdentityColumn = primaryKeyProperty != null &amp;&amp; primaryKeyProperty.ValueGenerated == ValueGenerated.OnAdd;\n        var isUniqueIdentifier = primaryKeyProperty != null &amp;&amp; primaryKeyProperty.ClrType == typeof(Guid);\n\n        await using var transaction = await _sqlServerDbContext.Database.BeginTransactionAsync();\n        try\n        {\n            if (hasIdentityColumn &amp;&amp; !isUniqueIdentifier)\n            {\n                await _sqlServerDbContext.Database.ExecuteSqlRawAsync($\"SET IDENTITY_INSERT {tableName} ON\");\n            }\n\n            var data = await source.AsNoTracking().ToListAsync();\n            await destination.AddRangeAsync(data);\n            await _sqlServerDbContext.SaveChangesAsync();\n\n            if (hasIdentityColumn &amp;&amp; !isUniqueIdentifier)\n            {\n                await _sqlServerDbContext.Database.ExecuteSqlRawAsync($\"SET IDENTITY_INSERT {tableName} OFF\");\n            }\n\n            await transaction.CommitAsync();\n        }\n        catch (Exception ex)\n        {\n            await transaction.RollbackAsync();\n            throw;\n        }\n    }\n</code></pre> <ul> <li>Add DBContext in program.cs (to run add-migration command)</li> </ul> <pre><code>builder.Services.AddDbContext&lt;SqlServerDbContext&gt;(options =&gt;\noptions.UseSqlServer(\"Server=.;Database=DB2;User Id=sa;Password=***;TrustServerCertificate=True\"));\n</code></pre> <ul> <li> <p>Create SQL Server DB with the same name in ConnectionString</p> </li> <li> <p>Add migration with a specific DBContext When you have more than one context</p> </li> <li> <p>Run code in Package Manager Console <pre><code>Add-Migration initialDB -Context SqlServerDbContext\n</code></pre></p> </li> <li> <p>Update database with a specific DBContext <pre><code>Update-Database -Context SqlServerDbContext\n</code></pre></p> </li> <li> <p>Run this code to apply changes <pre><code>var m = new MigrationToSqlServerService().MigrateDataAsync();\n</code></pre></p> </li> </ul>"},{"location":"backend/csharp/security/","title":"Security","text":""},{"location":"backend/csharp/security/#owasp","title":"OWASP","text":"<ul> <li>Open Web Application Security Project</li> </ul>"},{"location":"backend/csharp/security/#common-attacks","title":"Common Attacks","text":""},{"location":"backend/csharp/security/#cross-site-scripting-xss","title":"Cross-Site Scripting (XSS)","text":"<ul> <li>If we are outputting something on a razor page in a razor view as part of ASP.NET Core MVC in a blazer control with the @ character, the data will be automatically HTML escaped.</li> <li>Replacing Html.Raw with @ when outputting data ensures that HTML is encoded, preventing the execution of unintended JavaScript code.</li> <li>So HTML special characters, opening angular bracket, closing angular bracket, double quotes, single quote, and the ampersand character, they are properly escaped. </li> <li>The same functionality is also available using the @HtmlEncode method. That's part of system.web.httpUtility.</li> <li>Do not use @Html.Raw(\"\")</li> <li>. But the \"\\\" character does not escape. So the js script will run, if we use '\\x3c' instead of '&lt;' and '\\x3e' instead of '&gt;' =&gt; \"\\x3cscript\\x3ealert(hello)\\x3c/script\\x3e\".</li> <li>So we should use @System.Web.HttpUtility.JavaScriptStringEncode() in js scripts. =&gt; scapes all \"\\\" characters. Using JavaScriptStringEncode ensures that all JavaScript special characters are properly escaped, preventing code injection vulnerabilities.</li> <li>If you can just avoid using .NET code and binary data with add within JavaScript. Just stick with an HTML.</li> </ul>"},{"location":"backend/csharp/security/#xss-spa","title":"XSS SPA","text":"<ul> <li>Angular has a pretty good security posture. It is also escaping things like the href attribute for links. Use {{}} is HTML-escaped, but [] is not.</li> <li>React {} is HTML-escaped and {{}} is not.</li> <li>Vue.js {{}} is HTML-escaped but v-html=\"\" and innetHTML={} is not.</li> </ul>"},{"location":"backend/csharp/security/#origin-policy","title":"Origin Policy","text":"<ul> <li>It is about the Protocol, Host and Domain.<ul> <li>Protocol: http or https</li> <li>Domain name: https://test.com or https://www.test.com</li> <li>Port</li> </ul> </li> <li>JavaScript has only access to things on the same origin, and the origin is defined by the HTML page that contains the JavaScript code. So if you run an application on one origin and the JavaScript code then tries to access something, for instance, an API on a different origin, then that does not work.<ul> <li>When we use JavaScript to, say, call an API on a different origin, then the browser first contacts that server and asks whether that cross-origin request is in order. The browser does that by sending the Origin HTTP header to the remote server. And the remote server then can, so to speak, green-light a future request from that origin by returning a different HTTP header called Access-Control-Allow-Origin, and the value of that header has to be the same as the value of that Origin header you just saw. And only if that header is returned to the client, the client then knows, okay, JavaScript is allowed to send that HTTP request and then, well, sends the request to the server.</li> </ul> </li> <li>Enabling CORS         - [EnableCors(Policy)] attribute         - [DisableCors] attribute         - Configure in Program.cs                 ``` cs title=\"Program.cs\"                 builder.Services.AddCors(options =&gt;                 {                   options.AddPolicy(                     \"Policy1\",                     builder =&gt;                     {                       builder.WithOrigins(\"https://localhost:5001\");                     });                 });<pre><code>app.UseCors(\"Policy1\");\n```\n</code></pre> </li> </ul>"},{"location":"backend/csharp/security/#sql-injection","title":"SQL Injection","text":"<ul> <li>Do not send the value of ID as a string</li> <li>ADO.net: Do not use string concatanation to write the sql command. (1;Drop table Test1)<ul> <li>Use parametrized queries with @ and the name as a placeholder.</li> </ul> </li> <li>Entity Framework<ul> <li>Avoid execute raw SQL: DbContext.Database.SqlQueryRaw() or DbContext.Database.ExecuteRawQuery() or DbContext.SomeEntity.FromSqlRaw()</li> <li>Return IEnumerable instead of IQueryable</li> </ul> </li> </ul>"},{"location":"backend/csharp/security/#cross-site-request-forgery","title":"Cross-Site Request Forgery","text":"<ul> <li>CSRF (C-Serf) is an attack where malicious actions are executed on behalf of the victim without their consent, leveraging their authenticated session. Using the data saved in sessions.</li> <li>But Asp.net Core has built-in Cross-Site request forgery protection. each request has specific Token. (asp-antiforgery=\"true\")  If you have a form where the method is set to post, then also the request forgery token is automatically added.</li> <li>[ValidateAntiForgeryToken] enables and [IgnoreAntiforgeryToken] will disable the feature.</li> </ul>"},{"location":"backend/csharp/security/#samesite-cookies","title":"SameSite Cookies","text":"<ul> <li>Lax: the cookies only sent on a Cross-Sitee request. If it's an HTTP method, like get, that according to the rest specification does not change the state of the application. For post or put or delete, the cookie is not sent.</li> <li>Strict:  if we have a Cross-Site request, the cookie is not sent at all.</li> <li>None: no protection Program.cs<pre><code>//builder.Services.AddSessions(options =&gt; {options.Cookie.SameSite=SameSite.Mode.None; options.Cookie.SecurePolicy= CookieSecurePolicy.SameRequest;});\nbuilder.Services.AddSessions(); //Lax\n</code></pre></li> </ul>"},{"location":"backend/csharp/security/#encryption","title":"Encryption","text":""},{"location":"backend/csharp/security/#symmetric-key","title":"Symmetric Key","text":"<ul> <li>Symmetric-key encryption means that we can use the key both for encrypting the data and for decrypting it. (AES or DES)</li> </ul>"},{"location":"backend/csharp/security/#public-key","title":"Public Key","text":"<ul> <li>We have a set of keys: a public key and a private key. And the idea is that we could, for instance, use the public key for encryption and then the private key for decrypting the data.</li> </ul>"},{"location":"backend/csharp/security/#storing-data","title":"Storing Data","text":""},{"location":"backend/csharp/security/#secret-manager","title":"Secret Manager","text":"<p>Package Manager Console<pre><code>dotnet user-secret init\n</code></pre> - Then in the SolutionExplore, on right click context menu, select Manage User Secrets. The json file stores in the Profile. Only in local machine.</p>"},{"location":"backend/csharp/security/#app-settings","title":"App Settings","text":"<ul> <li>appsettings.json is a JSON file with settings.</li> <li>There is an extra file, appsettings.development.json. The idea is this, the appsettings.json file contains all of the settings that apply globally, no matter on which environment you are running the application, but per environment you can add specific JSON files that then can have extra settings or override global settings. So appsettings.development.json can override settings from the main appsettings.json file so you could have a different log level for instance. for example the appsettings.production.json</li> <li>In Project Properties, Debug, General, just click on 'Open debug launch profiles UI'. Then shows the environment settings for development json file.</li> </ul>"},{"location":"backend/csharp/security/#environment-variables","title":"Environment Variables","text":"<ul> <li>The option might be that you're using environment variables for those settings and then read out the environment variables and those environment variables are then for instance, created as part of your CI/CD process.</li> </ul>"},{"location":"backend/csharp/security/#data-protection-api","title":"Data Protection API","text":"<ul> <li>You have an API to decrypt and to encrypt data, and all of the heavy lifting is done by .NET.</li> </ul>"},{"location":"backend/csharp/security/#blazor-protected-browser-storage","title":"Blazor Protected Browser Storage","text":"<ul> <li>With a Blazor application that runs in the browser, you can access local storage and session storage, and if you are using the interactive server rendering mode, then the data that you store in local storage and session storage can be encrypted, and the server then leverages the encryption and also the decryption.</li> </ul>"},{"location":"backend/csharp/security/#cloud-storage","title":"Cloud Storage","text":"<ul> <li>Each of the major cloud providers has a mechanism where you can store values and then have an API to retrieve those values. And usually you store the values once and then, you don't really see them, but your application can retrieve them. So in<ul> <li>Azure: Key Vault</li> <li>AWS: Secrets Manager</li> <li>Google Cloud: Secret Manager</li> </ul> </li> </ul>"},{"location":"backend/csharp/security/#hashing-data","title":"Hashing Data","text":"<ul> <li>Hashing means I have a function that cannot be reversed.</li> <li>A hash is like a fingerprint of that specific piece of information. </li> <li>In addition, we are using something called a salt. A salt makes sure that if we are hashing the same password a couple of times, having a different salt means that the hashes are different.</li> <li>There are different algorithms for creating hashes, and a common one is called PBKDF2.</li> </ul>"},{"location":"backend/csharp/security/#security-options","title":"Security Options","text":"<ul> <li>Token-based Authentication:<ul> <li>OpenID Connect: OpenID Connect is a framework on top of OAuth and OpenID Connect is working with identity tokens. So who is the user?</li> <li>OAuth:  OAuth is essentially a standard that works with so-called access tokens. Access tokens basically say, \"What is a user allowed to access?\" <p>UnAuthorized HTTP Status Code: 401</p> </li> </ul> </li> <li>Securing SPAs (Single Page App) with the BFF (Backends for Frontrnds) pattern: st Friends Forever, but Backends for Frontends. So the idea essentially boils down to this. You have a server component. That server component takes care of token management, so it stores the token. It refreshes the token if that's required. And the communication between client and that token management system is done using cookies because, once again, cookies can be secured.</li> <li>Using Identity Provider such as IdentityServer, OpenIddict, Azure</li> </ul>"},{"location":"backend/csharp/security/#secure-configuration","title":"Secure Configuration","text":""},{"location":"backend/csharp/security/#cookies","title":"Cookies","text":"<ul> <li>A client sends an HTTP request to a server, and the server then can start the Cookie process by returning the Set-Cookie HTTP header alongside the HTTP response. Set-Cookie HTTP header sets a Cookie with a name of value and there can also be Metadata like an expiration date. The client then may choose to store the Cookie or not, and on subsequent requests to that server, that Cookie is sent back. But, this time with a different HTTP header name just Cookie. The client is also sending only the name and the value of the Cookie, not the Metadata. That's something that is for client use only.</li> </ul> <p><pre><code>var options = new CookieOptions {\n    Secure = true, //HTTPS\n    HttpOnly = true, //invisible for JS\n    SameSite = SameSiteMode.Lax //Cookie is being sent with a Cross-Site request, but only if you're using an HTTP method \n};\n</code></pre> Program.cs<pre><code>    builder.Services.AddAuthentication(CookieAuthenticationDefaults.AuthenticationScheme)\n        .AddCookie(options =&gt;\n        {\n            options.LoginPath = new PathString(\"Account/Login\");\n            options.Cookie.HttpOnly = true; //ensures that cookies are invisible to JavaScript, adding a layer of security against Cross-Site Scripting (XSS) attacks.\n            options.Cookie.SecurePolicy = CookieSecurePolicy.Always; // ensures cookies are transported via HTTPS but does not control JavaScript visibility.\n            options.Cookie.SameSite = SameSiteMode.Strict; //if cookies are sent with cross-site requests but does not affect JavaScript visibility. Protect cookies from being accessed by JavaScript.\n        });\n</code></pre></p>"},{"location":"backend/csharp/security/#sessions","title":"Sessions","text":"<ul> <li>A client sends a request to the server. The server once again responds with a Set-Cookie HTTP header, sets a cookie and the value of that cookie is a so-called session ID or contains a session ID that's an identifier for that session. We don't want to store cleartext information on the client because the client isn't trustworthy but an ID for something on the server works well. With subsequent requests, the client returns that session cookie. Program.cs<pre><code>builder.Services.AddSession(options =&gt; {\n    options.Cookie.HttpOnly = true; //Set Secure\n    options.Cookie.SecurePolicy = CookieSecurePolicy.Always; // want the secure flag\n    options.Cookie.SameSite = SameSiteMode.Strict\n});\n</code></pre></li> </ul>"},{"location":"backend/csharp/security/#enforcing-https","title":"Enforcing HTTPS","text":""},{"location":"backend/csharp/security/#redirect","title":"Redirect","text":"Program.cs<pre><code>app.UseHttpsRedirection();\n</code></pre>"},{"location":"backend/csharp/security/#rewrite","title":"Rewrite","text":"<ul> <li>Depends on the Web Server. In IIS: Make sure the \"IIS URL Rewrite module\" is installed on your server. IIS<pre><code>&lt;Configuration&gt;\n    &lt;system.webServer&gt;\n      &lt;rewrite&gt;\n        &lt;rules&gt;\n          &lt;rule name=\"Redirect to HTTPS\" enabled=\"true\" stopProcessing=\"true\"&gt;\n            &lt;match url=\"(.*)\" ignoreCase=\"true\" /&gt;\n            &lt;conditions&gt;\n              &lt;add input=\"{HTTPS}\" pattern=\"off\" ignoreCase=\"true\" /&gt;\n            &lt;/conditions&gt;\n            &lt;action type=\"Redirect\" url=\"https://{HTTP_HOST}/{R:1}\" redirectType=\"Permanent\" /&gt;\n          &lt;/rule&gt;\n        &lt;/rules&gt;\n      &lt;/rewrite&gt;\n    &lt;/system.webServer&gt;\n&lt;/Configuration&gt;\n</code></pre></li> </ul>"},{"location":"backend/csharp/security/#hsts","title":"HSTS","text":"<ul> <li>(HTTP Strict Transport Security) depends on the Browser.</li> <li>Refers to an HTTP header called Strict-Transport-Security. If that header is set and it's an HTTP response header, so the server sends it to the client. If that header is set, it instructs the browser to only talk to the server via HTTPS from now on.</li> <li>In the strict transport security HTTP header, you can provide the length. How long shall the browser remember this? By default is 30 days. Program.cs<pre><code>builder.Services.AddHsts(options=&gt; {\n    options.MaxAge = TimeSpan.FromDays(365);\n    options.IncludeSubDomains = true;\n});\n\napp.UseHsts();\n</code></pre></li> </ul>"},{"location":"backend/csharp/security/#error-handling","title":"Error Handling","text":""},{"location":"backend/csharp/security/#error-pages","title":"Error Pages","text":"Program.cs<pre><code>app.UseDeveloperExceptionPage();\napp.AddDatabaseDeveloperPageExceptionFilter();\n</code></pre>"},{"location":"backend/csharp/security/#status-code-pages","title":"Status Code Pages","text":"Program.cs<pre><code>UseStatusCodePages();\n</code></pre>"},{"location":"backend/csharp/security/#custom-exception-handler","title":"Custom Exception Handler","text":"Program.cs<pre><code>app.UseExceptionHandler(\"Home/Error\");\n</code></pre>"},{"location":"backend/csharp/security/#hiding-server-info","title":"Hiding Server Info","text":""},{"location":"backend/csharp/security/#remove-http-headers","title":"Remove HTTP Headers","text":"<ul> <li>Server and X-Powered-By show the Web Server and even more specific and provide minor version numbers, even patch version numbers. It depends of the Web Servers.</li> <li>Kestrel Program.cs<pre><code>builder.WebHost.UseKestrel(options=&gt; {\n    options.AddServerHeader = false;\n});\n</code></pre></li> <li>IIS web.config<pre><code>&lt;Configuration&gt;\n    &lt;system.webServer&gt;\n        &lt;security&gt;\n            &lt;requestFiltering removeServerHeader=\"true\" /&gt;\n        &lt;/security&gt;\n        &lt;httpProtocol&gt;\n            &lt;customHeaders&gt;\n                &lt;remove name= \"X-Powered-By\" /&gt;\n            &lt;/customHeaders&gt;\n        &lt;/httpProtocol&gt;\n    &lt;/system.webServer&gt;\n&lt;/Configuration&gt;\n</code></pre></li> </ul>"},{"location":"backend/csharp/security/#security-http-headers","title":"Security HTTP Headers","text":""},{"location":"backend/csharp/security/#x-frame-options","title":"X-Frame-Options","text":"<ul> <li>You can basically set, this site, or this page must not be put into an iframe, or shall only be put into an iframe of the same origin.</li> </ul>"},{"location":"backend/csharp/security/#content-security-policy","title":"Content-Security-Policy","text":"<ul> <li>Content security policy is a W3C standard that manifests an HTTP header that tells the browser where it may load resources from, including JavaScript. So you can tell the browser, essentially, which JavaScript code to load, or at least where to load it from.</li> </ul>"},{"location":"backend/csharp/security/#refrerrer-policy","title":"Refrerrer-Policy","text":"<ul> <li>Referrer policy takes care of the behavior of the referrer HTTP header, contains essentially the last URL. The URL that was loaded in the browser when the current HTTP request was made. For instance, by following a link, or by including an image. Referrer-Policy controls the referrer information sent with requests.</li> </ul>"},{"location":"backend/csharp/security/#permissions-policy","title":"Permissions-Policy","text":"<ul> <li>Restricts which JavaScript APIs may be called. Today's JavaScript is capable of doing lots of things, including determining the current position of the client, or connecting to Bluetooth low energy devices, and much, much more. And with a permissions policy, you can restrict which of those APIs JavaScript code on the current page may do. Permissions-Policy restricts which JavaScript APIs can be utilized.</li> </ul>"},{"location":"backend/csharp/security/#x-content-type-options","title":"X-Content-Type-Options","text":"<ul> <li> <p>Can prevent that the browser is guessing the content type of the HTTP response, instead of just looking at the content type HTTP header. And there is an exotic attack kind of related to this. I'm not too sure whether this HTTP header is still necessary for modern browsers, but low hanging fruit. Just set one header, probably zero side effects. X-Content-Type-Options prevents the browser from guessing the MIME type of the content.</p> </li> <li> <p>IIS web.config<pre><code>&lt;Configuration&gt;\n    &lt;system.webServer&gt;\n        &lt;httpProtocol&gt;\n            &lt;customHeaders&gt;\n                &lt;add name=\"X-Content-Type-Options\" value=\"nosniff\" /&gt;\n            &lt;/customHeaders&gt;\n        &lt;/httpProtocol&gt;\n    &lt;/system.webServer&gt;\n&lt;/Configuration&gt;\n</code></pre></p> </li> <li>Kestrel Program.cs<pre><code>app.Use(async (context, next) =&gt;\n{\n    context.Response.Headers.Append(\"X-Content-Type-Options\",\"nosniff\");\n    await next.Invoke();\n});\n</code></pre></li> </ul>"},{"location":"backend/csharp/state-service/","title":"Local State Service","text":""},{"location":"backend/csharp/state-service/#add-java-script","title":"Add Java script","text":"site.js<pre><code>window.localStorageHelper = {\n    setItem: function (key, value) {\n        localStorage.setItem(key, JSON.stringify(value));\n    },\n    getItem: function (key) {\n        let value = localStorage.getItem(key);\n        return value ? JSON.parse(value) : null;\n    },\n    removeItem: function (key) {\n        localStorage.removeItem(key);\n    }\n};\n</code></pre>"},{"location":"backend/csharp/state-service/#add-service-model","title":"Add Service Model","text":"PracticeStateService.cs<pre><code>public class PracticeStateService\n{\n    private const string StorageKey = \"PracticeSession\";\n    private readonly IJSRuntime _jsRuntime;\n\n    public long UserId { get; set; }\n    public long ScopeId { get; set; }\n    public string ScopeName { get; set; }\n    public long LevelId { get; set; }\n    public int PracticeQuestionCount { get; set; }\n    public int ReviewQuestionCount { get; set; }\n    public bool IsNew { get; set; } = false;\n    public UserReviewType UserReviewType { get; set; } = UserReviewType.Normal;\n\n    public bool HasData =&gt; UserId &gt; 0 &amp;&amp; ScopeId &gt; 0 &amp;&amp; LevelId &gt; 0 &amp;&amp; PracticeQuestionCount &gt; 0 &amp;&amp; ReviewQuestionCount &gt; 0;\n\n    public PracticeStateService(IJSRuntime jsRuntime)\n    {\n        _jsRuntime = jsRuntime;\n    }\n\n    public async Task SaveStateAsync(long userId, long scopeId, string scopeName, long levelId, int practiceQuestionCount, int reviewQuestionCount, bool isNew, UserReviewType userReviewType = UserReviewType.Normal)\n    {\n        UserId = userId;\n        ScopeId = scopeId;\n        ScopeName = scopeName;\n        LevelId = levelId;\n        PracticeQuestionCount = practiceQuestionCount;\n        ReviewQuestionCount = reviewQuestionCount;\n        IsNew = isNew;\n        UserReviewType = userReviewType;\n\n        PracticeRequestModel sessionData = new PracticeRequestModel\n        {\n            UserId = userId,\n            LevelId = levelId,\n            PracticeQuestionCount = practiceQuestionCount,\n            ReviewQuestionCount = reviewQuestionCount,\n            IsNew = isNew,\n            ScopeId = scopeId,\n            ScopeName = scopeName,\n            UserReviewType = userReviewType\n        };\n\n        await _jsRuntime.InvokeVoidAsync(\"localStorageHelper.setItem\", StorageKey, sessionData);\n    }\n\n    public async Task LoadStateAsync()\n    {\n        var sessionData = await _jsRuntime.InvokeAsync&lt;PracticeRequestModel&gt;(\"localStorageHelper.getItem\", StorageKey);\n        if (sessionData != null)\n        {\n            UserId = sessionData.UserId;\n            IsNew = sessionData.IsNew;\n            LevelId = sessionData.LevelId;\n            PracticeQuestionCount = sessionData.PracticeQuestionCount;\n            ReviewQuestionCount = sessionData.ReviewQuestionCount;\n            ScopeId = sessionData.ScopeId;\n            ScopeName = sessionData.ScopeName;\n            UserReviewType = sessionData.UserReviewType;\n        }\n    }\n\n    public async Task ClearStateAsync()\n    {\n        UserId = 0;\n        IsNew = false;\n        LevelId = 0;\n        PracticeQuestionCount = 0;\n        ReviewQuestionCount = 0;\n        ScopeId = 0;\n        ScopeName = string.Empty;\n        UserReviewType = UserReviewType.Normal;\n\n        await _jsRuntime.InvokeVoidAsync(\"localStorageHelper.removeItem\", StorageKey);\n    }\n}\n</code></pre>"},{"location":"backend/csharp/state-service/#add-di","title":"Add DI","text":"Program.cs<pre><code>builder.Services.AddScoped&lt;PracticeStateService&gt;();\n</code></pre>"},{"location":"backend/csharp/validation-attrib-custom/","title":"Localized Custom Validation","text":""},{"location":"backend/csharp/validation-attrib-custom/#attribute-usage","title":"Attribute Usage","text":"<pre><code>public class ChangePasswordModel\n{\n    public string Email { get; set; }\n\n    [FieldIsRequired(nameof(CurrentPassword))]\n    public string CurrentPassword { get; set; }\n\n    [FieldIsRequired(nameof(NewPassword))]\n    [PasswordRequirements]\n    public string NewPassword { get; set; }\n\n    [CompareText(nameof(NewPassword), nameof(ConfirmPassword))]\n    public string ConfirmPassword { get; set; }\n}\n</code></pre> Resource Files Model<pre><code>public class SharedValidationAttribute\n{\n}\n</code></pre>"},{"location":"backend/csharp/validation-attrib-custom/#compare-text-attribute","title":"Compare Text Attribute","text":"CompareText<pre><code>public class CompareTextAttribute : ValidationAttribute\n{\n    private readonly string _fieldToCompare;\n    private readonly string _currentField;\n    private readonly string _errorTextMessageKey = \"TwoValuesAreNotEqualMessage\";\n\n    public CompareTextAttribute(string fieldToCompare, string currentField)\n    {\n        _fieldToCompare = fieldToCompare;\n        _currentField = currentField;\n    }\n\n    protected override ValidationResult? IsValid(object? value, ValidationContext validationContext)\n    {\n        if (validationContext == null)\n        {\n            throw new ArgumentNullException(nameof(validationContext));\n        }\n\n        var currentValue = value as string;\n\n        PropertyInfo? pInfo = validationContext.ObjectType.GetProperty(_fieldToCompare);\n        if (pInfo == null)\n        {\n            return new ValidationResult($\"Property '{_fieldToCompare}' does not exist.\");\n        }\n\n        var compareValue = pInfo.GetValue(validationContext.ObjectInstance) as string;\n\n        if (currentValue != compareValue)\n        {\n            return new ValidationResult(GetErrorMessage(validationContext));\n        }\n\n        return ValidationResult.Success;\n    }\n\n    private string GetErrorMessage(ValidationContext validationContext)\n    {\n        var localizer = validationContext.GetService(typeof(IStringLocalizer&lt;SharedValidationAttribute&gt;)) as IStringLocalizer&lt;SharedValidationAttribute&gt;;\n\n        if (localizer != null &amp;&amp; localizer[_errorTextMessageKey] != null)\n        {\n            return string.Format(localizer[_errorTextMessageKey], localizer[_currentField], localizer[_fieldToCompare]);\n        }\n        return $\"Fields do not match.\";\n    }\n}\n</code></pre>"},{"location":"backend/csharp/validation-attrib-custom/#email-requirements-attribute","title":"Email Requirements Attribute","text":"EmailRequirements<pre><code>public class EmailRequirementsAttribute : ValidationAttribute\n{\n    protected override ValidationResult? IsValid(object? value, ValidationContext validationContext)\n    {\n        var email = value as string;\n        if (string.IsNullOrWhiteSpace(email))\n        {\n            return new ValidationResult(GetErrorMessage(validationContext, \"EmailIsRequiredMessage\"));\n        }\n\n        // Validate the email format using a simple regular expression\n        if (!IsValid(email))\n        {\n            return new ValidationResult(GetErrorMessage(validationContext, \"EmailIsInvalidMessage\"));\n        }\n\n        return ValidationResult.Success;\n    }\n\n    private string GetErrorMessage(ValidationContext validationContext, string errorTextMessageKey)\n    {\n        var localizer = validationContext.GetService(typeof(IStringLocalizer&lt;SharedValidationAttribute&gt;)) as IStringLocalizer&lt;SharedValidationAttribute&gt;;\n\n        if (localizer != null &amp;&amp; localizer[errorTextMessageKey] != null)\n        {\n            return string.Format(localizer[errorTextMessageKey]);\n        }\n\n        return $\"Email is required in a correct format.\";\n    }\n\n    private bool IsValidEmail(string email)\n    {\n        // Regular expression pattern for validating an email address\n        var pattern = @\"^[^@\\s]+@[^@\\s]+\\.[^@\\s]+$\";\n        return Regex.IsMatch(email, pattern, RegexOptions.IgnoreCase);\n    }\n\n    public bool IsValid(string emailaddress)\n    {\n        try\n        {\n            MailAddress m = new MailAddress(emailaddress);\n\n            return true;\n        }\n        catch (FormatException)\n        {\n            return false;\n        }\n    }\n}\n</code></pre>"},{"location":"backend/csharp/validation-attrib-custom/#field-required-attribute","title":"Field Required Attribute","text":"FieldIsRequired<pre><code>public class FieldIsRequiredAttribute : ValidationAttribute\n{\n    private readonly string _fieldToValidateName;\n    private readonly string _errorTextMessageKey = \"FieldIsRequiredMessage\";\n\n    public FieldIsRequiredAttribute(string fieldName)\n    {\n        _fieldToValidateName = fieldName;\n    }\n\n    protected override ValidationResult? IsValid(object? value, ValidationContext validationContext)\n    {\n        if (validationContext == null)\n        {\n            throw new ArgumentNullException(nameof(validationContext));\n        }\n\n        if (value == null || (value is string str &amp;&amp; string.IsNullOrWhiteSpace(str)))\n        {\n            return new ValidationResult(GetErrorMessage(validationContext));\n        }\n\n        return ValidationResult.Success;\n    }\n\n    private string GetErrorMessage(ValidationContext validationContext)\n    {\n        var localizer = validationContext.GetService(typeof(IStringLocalizer&lt;SharedValidationAttribute&gt;)) as IStringLocalizer&lt;SharedValidationAttribute&gt;;\n\n        if (localizer != null &amp;&amp; localizer[_errorTextMessageKey] != null)\n        {\n            return string.Format(localizer[_errorTextMessageKey], localizer[_fieldToValidateName]);\n        }\n        return $\"Field is required.\";\n    }\n}\n</code></pre>"},{"location":"backend/csharp/validation-attrib-custom/#must-be-true-attribute","title":"Must Be True Attribute","text":"MustBeTrue<pre><code>public class MustBeTrueAttribute : ValidationAttribute\n{\n    private readonly string _fieldToValidateName;\n    private readonly string _errorTextMessageKey = \"FieldMustBeTrueMessage\";\n\n    public MustBeTrueAttribute(string fieldName)\n    {\n        _fieldToValidateName = fieldName;\n    }\n\n    protected override ValidationResult IsValid(object value, ValidationContext validationContext)\n    {\n        if (validationContext == null)\n        {\n            throw new ArgumentNullException(nameof(validationContext));\n        }\n\n        if (value == null || !(value is bool) || !(bool)value)\n        {\n            return new ValidationResult(GetErrorMessage(validationContext));\n        }\n        return ValidationResult.Success;\n    }\n\n    private string GetErrorMessage(ValidationContext validationContext)\n    {\n        var localizer = validationContext.GetService(typeof(IStringLocalizer&lt;SharedValidationAttribute&gt;)) as IStringLocalizer&lt;SharedValidationAttribute&gt;;\n\n        if (localizer != null &amp;&amp; localizer[_errorTextMessageKey] != null)\n        {\n            return string.Format(localizer[_errorTextMessageKey], localizer[_fieldToValidateName]);\n        }\n        return $\"Field must be selected.\";\n    }\n}\n</code></pre>"},{"location":"backend/csharp/validation-attrib-custom/#password-requirements-attribute","title":"Password Requirements Attribute","text":"PasswordRequirements<pre><code>public class PasswordRequirementsAttribute : ValidationAttribute\n{\n    protected override ValidationResult IsValid(object value, ValidationContext validationContext)\n    {\n        var localizer = validationContext.GetService(typeof(IStringLocalizer&lt;PasswordRequirementsAttribute&gt;)) as IStringLocalizer&lt;PasswordRequirementsAttribute&gt;;\n\n        var password = value as string;\n        if (string.IsNullOrWhiteSpace(password))\n        {\n            return new ValidationResult(GetErrorMessage(validationContext, \"PasswordIsRequiredMessage\"));\n        }\n\n        bool hasDigit = password.Any(char.IsDigit);\n        bool hasUpper = password.Any(char.IsUpper);\n        bool hasLower = password.Any(char.IsLower);\n        bool hasMinimumLength = password.Length &gt;= 8;\n        bool hasSpecialChar = password.Any(ch =&gt; !char.IsLetterOrDigit(ch));\n        bool hasRequiredUniqueChars = password.Distinct().Count() &gt;= 2;\n\n        if (!hasDigit)\n            return new ValidationResult(GetErrorMessage(validationContext, \"PasswordRequiresDigitMessage\"));\n\n        if (!hasUpper)\n            return new ValidationResult(GetErrorMessage(validationContext, \"PasswordRequiresUpperCaseMessage\"));\n\n        if (!hasLower)\n            return new ValidationResult(GetErrorMessage(validationContext, \"PasswordRequiresLowerCaseMessage\"));\n\n        if (!hasMinimumLength)\n            return new ValidationResult(GetErrorMessage(validationContext, \"PasswordMinimumLengthMessage\"));\n\n        if (!hasSpecialChar)\n            return new ValidationResult(GetErrorMessage(validationContext, \"PasswordRequiresSpecialCharMessage\"));\n\n        if (!hasRequiredUniqueChars)\n            return new ValidationResult(GetErrorMessage(validationContext, \"PasswordRequiresUniqueCharsMessage\"));\n\n        return ValidationResult.Success;\n    }\n\n    private string GetErrorMessage(ValidationContext validationContext, string errorTextMessageKey)\n    {\n        var localizer = validationContext.GetService(typeof(IStringLocalizer&lt;SharedValidationAttribute&gt;)) as IStringLocalizer&lt;SharedValidationAttribute&gt;;\n\n        if (localizer != null &amp;&amp; localizer[errorTextMessageKey] != null)\n        {\n            return string.Format(localizer[errorTextMessageKey]);\n        }\n\n        return $\"Password is required.\";\n    }\n}\n</code></pre>"},{"location":"backend/csharp/validation-attrib/","title":"Validation Attributes","text":""},{"location":"backend/csharp/validation-attrib/#requiredif","title":"RequiredIf","text":"<pre><code>[RequiredIf(\"Art == 'Gutschrift'\",\n    ErrorMessageResourceName = \"SelectChargeLabel\",\n    ErrorMessageResourceType = typeof(Resources.ObjectText))]  \npublic string GutschriftWann { get; set; } = string.Empty;\n</code></pre>"},{"location":"backend/csharp/validation-attrib/#assertthat","title":"AssertThat","text":"<pre><code>public class MyModel\n{\n    // This method must be accessible (public or internal) to be used in AssertThat\n    public bool IsValidArt(string art)\n    {\n        // Custom validation logic\n        return !string.IsNullOrWhiteSpace(art) &amp;&amp; art.Length &gt; 5;\n    }\n\n    [AssertThat(\"IsValidArt(Art)\", \n        ErrorMessageResourceName = \"InvalidArtMessage\", \n        ErrorMessageResourceType = typeof(Resources.ObjectText))]\n    public string Art { get; set; } = string.Empty;\n}\n</code></pre>"},{"location":"backend/python/extract-firebird/","title":"Extract Firebird .sql data","text":"<pre><code>import os\nimport re\nimport binascii\nimport zlib\n\n# \ud83d\udcd1 File paths\nsql_file_path = r\"Export_Documents.sql\"\noutput_dir = r\"output_files\"\nos.makedirs(output_dir, exist_ok=True)\n\n# \ud83d\udcd1 Regex to match each VALUES row: ('AMSIDNR','BFTYP',0xHEXDATA)\npattern = re.compile(\n    r\"\\(\\s*'(?P&lt;amsidnr&gt;[^']+)',\\s*'(?P&lt;bftyp&gt;[^']+)',\\s*0x(?P&lt;hexdata&gt;[0-9A-F]+)\\s*\\)\"\n)\n\nfile_counter = 0\nparsing_started = False\n\ndef process_line(line):\n    global file_counter\n    matches = pattern.finditer(line)\n    for match in matches:\n        raw_amsidnr = match.group(\"amsidnr\")\n\n    # \ud83d\udcd1 Remove leading zeros\n        amsidnr = raw_amsidnr.lstrip(\"0\")  \n        bftyp = match.group(\"bftyp\")\n        hexdata = match.group(\"hexdata\")\n\n        # \ud83d\udcd1 Clean extension:\n        extension = bftyp.lower()\n\n        # \ud83d\udcd1 Build filename\n        filename = f\"{amsidnr}.{extension}\"\n        filepath = os.path.join(output_dir, filename)\n\n        try:\n            compressed_data = binascii.unhexlify(hexdata)\n\n            # \ud83d\udcd1 Starts with '0x789C' =&gt; zlib-compressed\n            decompressed_data = zlib.decompress(compressed_data)\n\n            with open(filepath, \"wb\") as f:\n                f.write(decompressed_data)\n\n            file_counter += 1\n            if file_counter % 1000 == 0:\n                print(f\"\u2705 Processed {file_counter} files...\")\n        except Exception as e:\n            print(f\"\u274c Error saving {filepath}: {e}\")\n\ndef process_sql_file(file_path):\n    global parsing_started\n    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n        buffer = \"\"\n        for line in file:\n            line = line.strip()\n            if not parsing_started:\n                if \"VALUES\" in line:\n                    parsing_started = True\n                    print(\"\ud83d\udfe2 VALUES section found, starting extraction...\")\n                    buffer = \"\"\n                continue\n\n            if parsing_started:\n                buffer += line\n                if buffer.endswith(\");\") or line.endswith(\"),\"):\n                    process_line(buffer)\n                    buffer = \"\"\n\n# \ud83d\udcd1 Run the extraction\nprocess_sql_file(sql_file_path)\nprint(f\"\ud83c\udf89 All done! {file_counter} files extracted and saved to: {output_dir}\")\n</code></pre>"},{"location":"docker/docker-install/","title":"Docker Installation","text":""},{"location":"docker/docker-install/#docker-desktop","title":"Docker Desktop","text":"<p>Docker Desktop bundles the Docker Engine, CLI, and a friendly GUI for Windows and macOS.</p> <ol> <li>Download and install:</li> <li>https://www.docker.com/products/docker-desktop</li> <li>After installation, verify Docker runs: <pre><code>docker run hello-world\n</code></pre></li> <li>Notes:</li> <li>Docker Desktop requires virtualization enabled in BIOS/UEFI.</li> <li>On Windows, use WSL2 backend for best compatibility (enable WSL2 and install a Linux distro).</li> <li>Use the Docker Desktop UI to configure resources (CPU, memory, disk).</li> </ol>"},{"location":"docker/docker-install/#docker-machine","title":"Docker Machine","text":"<p>Docker Machine historically created a small VM (often using VirtualBox) to run the Docker Engine on platforms that didn't support Docker natively. This is mostly superseded by Docker Desktop and WSL2 on modern systems.</p>"},{"location":"docker/docker-install/#install-on-linux","title":"Install on Linux","text":"<p>Example (Debian/Ubuntu-based systems):</p> <pre><code># Install prerequisites\nsudo apt update\nsudo apt install -y curl\n\n# Download and run the official installer script\ncurl -fsSL https://get.docker.com -o /tmp/get-docker.sh\nsudo sh /tmp/get-docker.sh\n\n# Test Docker\nsudo docker run hello-world\n</code></pre>"},{"location":"docker/docker-install/#post-install","title":"Post-install","text":"<p>To run Docker without <code>sudo</code>, add your user to the <code>docker</code> group:</p> <pre><code>sudo usermod -aG docker $USER\n# Apply the new group membership immediately (without logout) in the current session:\nnewgrp docker\n# or log out and log back in for the change to take effect\n</code></pre> <p>Check group membership:</p> <pre><code>groups\n# or\ngroups $USER\n</code></pre> <p>If <code>docker</code> is listed, you can run Docker commands without <code>sudo</code>:</p> <pre><code>docker run hello-world\n</code></pre>"},{"location":"docker/docker-install/#common-tips","title":"Common tips","text":"<ul> <li>If <code>docker run hello-world</code> fails:</li> <li>Ensure the Docker service is running: <code>sudo systemctl status docker</code></li> <li>Review daemon logs: <code>sudo journalctl -u docker --since \"1 hour ago\"</code></li> <li>On Debian/Ubuntu, the installer script will configure the Docker repository and install Docker Engine and CLI.</li> <li>To manage Docker as a systemd service: <pre><code>sudo systemctl enable docker\nsudo systemctl start docker\n</code></pre></li> <li>If you encounter permission issues after adding your user to the <code>docker</code> group, log out and log back in (or reboot) to refresh group membership.</li> <li>Use <code>docker version</code> to inspect client and server versions, and <code>docker info</code> for environment / runtime details.</li> </ul>"},{"location":"docker/docker-install/#useful-links","title":"Useful links","text":"<ul> <li>Official Docker docs: https://docs.docker.com</li> <li>Docker Desktop: https://www.docker.com/products/docker-desktop</li> <li>Get Docker installer script: https://get.docker.com</li> </ul>"},{"location":"docker/docker-intro/","title":"Docker Introduction","text":"<ul> <li>In Linux, the kernel is the central component of the operating system, acting as a bridge between hardware and software.</li> <li>It manages system resources such as the CPU, memory, and devices, and handles core functions like running programs, managing files, and controlling input/output operations.</li> </ul>"},{"location":"docker/docker-intro/#docker-vs-virtualmachine","title":"Docker vs VirtualMachine","text":"<ul> <li>This is understandable, but incorrect, comparison. The biggest difference is that virtual machines virtualize hardware whereas containers virtualize operating system kernels.</li> <li>Virtual machines run on a platform called a hypervisor. The hypervisor's main job is to translate operations on emulated hardware within virtual machines like memory processors, disks, etc, to operations on real hardware within their hosts.<ul> <li>Run on top of hypervisors</li> <li>Need hardware emulation</li> <li>Require OS Config</li> <li>Can run many apps at once</li> <li>Take up more spaces</li> </ul> </li> <li>Containers run on container run times. Container run times work with the operating system to allocate hardware and copy files and directories, including the parts with your application in it into something that looks more like any other app running on that system.<ul> <li>Run in container runtimes</li> <li>Work alongside OS</li> <li>Do not require OS Config</li> <li>Run one app at a time (usually)</li> <li>Take up less spaces</li> </ul> </li> </ul>"},{"location":"docker/docker-intro/#docker-anatomy","title":"Docker Anatomy","text":"<ul> <li>A container is composed of two things: a Linux namespace (Host) and a Linux control group (Kernel).</li> <li>Namespaces are a Linux kernel feature that provides the ability to expose different \"views\" of your system to applications running within it.</li> <li>Namespace limits \"What you can see\".</li> <li>Control Groups provide the ability to restrict how much hardware (CPU, Network and Disk bandwidth, Memory) each process can use. \"Assign disk quotas\" not supported by Docker.</li> <li>Docker uses control groups for a few things.<ul> <li>First, it uses control groups to monitor and restrict CPU usage, or the amount of CPU time each container can take up.</li> <li>Second to monitor and restrict network and disk bandwidth. And more commonly, Docker uses control groups to monitor and restrict memory consumption. This makes it easy to prevent busier, or larger containers from eating up all the system's resources</li> </ul> </li> <li>Control group limits \"How much you can see\".</li> <li>Today's Linux kernels provide eight namespaces. <ol> <li>USERNS - User management </li> <li>MOUNT - Access File system </li> <li>NET - Network </li> <li>IPC - Inter Process Communication - resources </li> <li>TIME (Not support by Docker due to Technical limitation) </li> <li>PID - Process ID </li> <li>CGROUP - Create control group </li> <li>UTS - Unix Time Stamp </li> </ol> </li> <li>Control groups, another Linux kernel feature, build on this by providing the ability to restrict how much hardware each process can use.</li> <li>Control groups and Namespaces are Linux only features, this means that Docker technically only runs natively on Linux and some newer versions of Windows as well.</li> <li>Containers can run on anything but their images are tied to the kernel they were created from.</li> <li>Containers created from container images configured for Linux kernels can only run on Linux. Conversely, containers created from container images configured for Windows can only run on Windows. </li> </ul>"},{"location":"docker/docker-intro/#docker-advantages","title":"Docker Advantages","text":"<p>1- Docker Files make configuration and packaging apps and their environments really easy.  2- Docker Hub (Global repo of images maintained by Docker) makes sharing images with anyone in the world easy.  3- Docker CLI makes it really easy to start the apps in containers. </p>"},{"location":"docker/docker-intro/#docker-alternatives","title":"Docker Alternatives","text":"<ul> <li>Kuberbetes</li> <li>Podman : developed by Red Hat to provide a more secure, daemon-less approach to container management. Supports rootless containers and can run multiple apps at once with an \"init\" system.</li> <li>It was created to address some concerns around Docker:<ul> <li>Security: Eliminates the need for a privileged daemon (reduces attack surface).</li> <li>Integration with systemd: Containers can run as regular system services.</li> <li>Kubernetes alignment: Uses the same OCI runtime/spec as Kubernetes (CRI-O).</li> </ul> </li> </ul>"},{"location":"docker/docker-useage/","title":"Docker Usage","text":"<ul> <li>Everything you create within a container stays within the container. Once the container stops, the data gets deleted with it.</li> <li>Use only verified images for security. Verified image have a Docker Official Image designation on them to let you know that they are scanned by Docker themselves. There are some image scanners:<ul> <li>Clair</li> <li>Trivy</li> <li>Dagda</li> </ul> </li> <li>When some changes applied to the Docker file, you should remove the container and build it again.</li> <li>I always recommend putting a version tag when creating images, even if they are local. It's easy, quick, and solves a lot of problems in the future.</li> <li>I recommend running containers as a user other than root. You can do this for your own images as well as for containers created from existing images. For containers created from other images, specify the --user option when running Docker Run or Docker Container Create.</li> <li>For your own images, you can specify the user command within your Docker file to tell Docker which user to run your application as by default. You can make certain sections of your Docker file run as root and others run as non-root. It is quite flexible.</li> <li>You can run multiple containers and connect them all through virtual networks and separate data volumes managed entirely by the Docker engine. This is a great way to implement a three-tier architecture, like the one our web app is using.</li> <li>Docker Compose is a tool provided by Docker that makes it really easy to run and connect multiple containers on a single machine. With Compose, you use a single file called the Compose Manifest to define all of your containers and how they relate to each other. Starting those containers together is as easy as running Docker-compose up.</li> <li>While you can link containers together with Docker networks, these networks do not span multiple hosts by default. You can also use the Docker CLI to talk to Docker engines running on remote hosts but it is quite cumbersome, especially when authentication comes into play. Docker also does not have built-in solutions for moving containers between hosts or auto-scaling containers to respond to load. Finally, higher-level concerns like securing traffic between containers or configuring load balancing and routing amongst them are outside of Docker's realm of responsibility. At best, this can make using Docker alone for production-type workloads really, really complex. At worst, it can increase security risk, decrease performance, and make your infrastructure more susceptible to downtime. Container orchestrators solve these problems. Orchestrators use scheduling techniques, networking magic, and service discovery tools to make scaling, moving, and routing traffic to containers really, really easy. If you've ever used VMware's vCenter or tools like Rundeck, you're already familiar with the basic idea. Many container orchestrators have popped up over the years. Docker's own Swarm product, Mesosphere, HashiCorp's Nomad, and cloud offerings like AWS Elastic Container Service or Azure Container Service are examples of some popular container orchestrators in the world. <ul> <li>Docker Swarm</li> <li>Marathob</li> <li>HashiCorp Nomad</li> <li>Cloud offerings (Amazon Elastic Container Service, Azure Container Service)</li> <li>Kubernetes describes itself as a planet-scale container orchestrator for automating the deployment, scaling, and management of containerized applications.<ul> <li>Kubernetes is a distributed system. It is designed from the ground up to run its components and store their data across many machines. This makes it capable of running and connecting hundreds of thousands of containers seamlessly as if they were all running on one machine. This also makes Kubernetes possible to run on almost anything from Raspberry Pis to some of the largest cloud platforms in the world.</li> <li>Kubernetes makes it really easy to group containers together, kind of like Docker Compose. You can also use Kubernetes to scale those container groups up or down to respond to your application's demands without creating more VMs or other hardware. This is typically expensive and sometimes cumbersome but much cheaper to do with Kubernetes.</li> <li>Kubernetes also makes it really easy to secure traffic within your container networks and to or from the outside world. You can use Kubernetes to provide specific rules about how your traffic to or from your containers is routed.</li> <li>Kubernetes can be used as a platform of platforms. </li> </ul> </li> </ul> </li> </ul>"},{"location":"docker/docker-useage/#docker-cli","title":"Docker CLI","text":"Exit the shell<pre><code>ctrl+d\n</code></pre> Find previous command<pre><code>ctrl+r\n</code></pre> Stop the process<pre><code>ctrl+c\n</code></pre> Clear the screen<pre><code>ctrl+l\n</code></pre> List directory<pre><code>ls\n</code></pre>"},{"location":"docker/docker-useage/#create-docker-container","title":"Create Docker Container","text":"Help<pre><code>docker --help\ndocker network --help\ndocker container create --help\n</code></pre> Create new container<pre><code>docker container create hello-world:linux \n</code></pre> Show the actively running containers<pre><code>docker ps\n</code></pre> Show the all containers<pre><code>docker ps --all\ndocker ps -aq\n</code></pre> Start the container<pre><code>docker container start dockerID\ndocker container start --attach\n</code></pre> <pre><code>docker logs three_char_con_id\n</code></pre> docker run =&gt; create, start, attach<pre><code>docker run hello-world:linux\n</code></pre> t: the tag insead of ID and .:  the path of all images to include<pre><code>docker build -t app-1 . \n</code></pre> buildx: use BuildKit<pre><code>docker buildx build -t app-1 --load .\n</code></pre> Use specific docker file<pre><code>docker build --file server.Dockerfile --tag server-1 .\ndocker build -t app-1 -f server.Dockerfile .\n</code></pre> -d: Move to background<pre><code>docker run -d \ndocker kill four_char_con_id\ndocker exec four_char_con_id date\n</code></pre> tty: allocates a pseudo-tty, interactive: keep stdin open even if not attached, tell Docker to enable keystrokes<pre><code>-starts an interactive Bash shell within a container starting with ID 2bf with a pseudo-TTY allocated \ndocker exec --interactive --tty  four_char_con_id date bash\n</code></pre>"},{"location":"docker/docker-useage/#performance-container","title":"Performance Container","text":"Show all images<pre><code>docker images\n</code></pre> Smartly removes useless data<pre><code>docker system prune ID/tag\n</code></pre> Snapshot of the container's performance<pre><code>docker stats [containerName]\n</code></pre> Show what's running inside of the container without having to exec<pre><code>docker top [containerName]\n</code></pre> Show advanced information about a container in JSON format. Its searchable. to quit press 'q'<pre><code>docker inspect ID/tag | less\n</code></pre> Show contexts<pre><code>docker context ls\n</code></pre> Switch to the context created by Docker Desktop<pre><code>docker context use default\n</code></pre> <ul> <li>The context can be overridden with the DOCKER_CONTEXT environment variable and the endpoint can be overridden with DOCKER_HOST. <pre><code>$DOCKER_CONTEXT ; echo $DOCKER_HOST\n</code></pre></li> </ul> in Windows PowerShell<pre><code>$env:DOCKER_CONTEXT ; echo $env:DOCKER_HOST\n</code></pre> <pre><code>export DOCKER_CONTEXT=xxx\nunset DOCKER_CONTEXT\n</code></pre>"},{"location":"docker/docker-useage/#interact-docker-container","title":"Interact Docker Container","text":""},{"location":"docker/docker-useage/#stopremove","title":"Stop/Remove","text":"<pre><code>docker stop four_char_con_id\n</code></pre> Force to terminate<pre><code>docker stop -t 0 four_char_con_id\n</code></pre> Work as a loop, provide IDs from left and applies to the right command<pre><code>docker ps -aq | xargs docker rm -f\n</code></pre> Remove container<pre><code>docker rm four_char_con_id\n</code></pre> Remove images, -f: Force to remove images fast<pre><code>docker rmi \ndocker rmi -f \n</code></pre>"},{"location":"docker/docker-useage/#bind-port","title":"Bind Port","text":"outside port:inside port =&gt; browse 5001<pre><code>docker run -p 5001:5000\n</code></pre>"},{"location":"docker/docker-useage/#save-data","title":"Save Data","text":"<ul> <li>Everything you create within a container stays within the container. Once the container stops, the data gets deleted with it.</li> <li>We can use the volume mounting feature to work around this. Like the port binding feature, this allows Docker to map a folder on our computer to a folder in the container.</li> </ul> --volum: map temp folder in the container to the /tmp/container path =&gt; the file should exists otherwise assumes as a directory<pre><code>docker run -v /tmp/container:/temp\ncat /tmp/container/file\n</code></pre>"},{"location":"docker/docker-useage/#docker-hub","title":"Docker Hub","text":"<ul> <li>A container image registry is a place for storing and tracking container images. Container images are tracked by their tags, a string combining the name of the image, and optionally it's version with a semicolon.</li> <li>Container images that do not have a version automatically get tagged with the version called latest. Like downloading software on Homebrew or GitHub, this naming scheme makes it really easy to download specific versions of images.</li> <li>We'll see what I mean here in a moment. Docker Hub is a default registry used by the Docker client. This is a publicly accessible registry that anyone can push images to.</li> <li>Whenever you pull images or whenever Docker needs to pull an image from the from line of a Docker file, it will fetch an image from Docker Hub.</li> </ul> <pre><code>docker login\n</code></pre> Rename docker images<pre><code>docker tag currentTagName dockerHubUsername/nameInDockerHub:versionNo\n</code></pre> Push the image to Hub<pre><code>docker push dockerHubUsername/nameInDockerHub:versionNo\n</code></pre> Remove the image from Hub<pre><code>remove from the Docker hub website\n</code></pre>"},{"location":"docker/docker-useage/#container-registery","title":"Container Registery","text":"<ul> <li>Self-hosting image registries:<ul> <li>JFrog's Artifactory</li> <li>Sonatype's Nexus</li> <li>Red Hat's Quay.io</li> <li>Project Harbor</li> </ul> </li> </ul>"},{"location":"docker/docker-useage/#commmon-steps","title":"Commmon Steps","text":"<pre><code>docker build -t app-1 -f server.Dockerfile .\ndocker run -d --name app-1 app-1\ndocker ps\ndocker rm -f app-1\ndocker images\ndocker rmi tag-1 tag-2 tag-3\n</code></pre>"},{"location":"docker/docker-useage/#nginx-sample","title":"nginx Sample","text":"<pre><code>docker run --name website -v \"$PWD/website:usr/share/nginx/html\" -p 8080:80 --rm nginx\n</code></pre>"},{"location":"frontend/bootstrap-update/","title":"Bootstrap Update","text":""},{"location":"frontend/bootstrap-update/#update-to-bootstrap-5","title":"Update to Bootstrap 5","text":"<ul> <li>Remove null reference error with adding this reference to each Layout <pre><code>@Scripts.Render(\"~/bundles/bootstrap\")\n</code></pre></li> </ul>"},{"location":"frontend/bootstrap-update/#bundle-changes","title":"Bundle changes","text":"<ul> <li>~/Scripts/umd/popper.min.js is removed and included in bootstrap.bundle.min.js.</li> <li>~/Scripts/bootstrap.min.js is removed and as bootstrap.bundle.min.js already includes Bootstrap's JS.</li> </ul> BundleConfig.cs<pre><code>bundles.Add(new ScriptBundle(\"~/bundles/bootstrap\").Include(\n    //\"~/Scripts/umd/popper.min.js\",\n    //\"~/Scripts/bootstrap.min.js\",\n    \"~/Scripts/bootsrap.bundle.min.js\",\n    \"~/Scripts/jquery.dataTables.min.js\",\n    \"~/Scripts/jquery.unobtrusive-ajax.min.js\",\n    \"~/Scripts/moment.js\",\n    \"~/Scripts/datetime.js\",\n    //\"~/Scripts/dataTables.bootstrap4.min.js\",\n    \"~/Scripts/jszip.min.js\",\n    \"~/Scripts/dataTables.buttons.min.js\",\n    \"~/Scripts/buttons.bootstrap4.min.js\",\n    \"~/Scripts/buttons.html5.min.js\",\n    \"~/Scripts/pdfmake.min.js\",\n    \"~/Scripts/vfs_fonts.js\"\n    ));\n\n// CSS bundle\nbundles.Add(new StyleBundle(\"~/Content/css\").Include(\n   \"~/Content/reset.css\",\n   \"~/Content/bootstrap.min.css\",\n   \"~/Content/jquery.dataTables.min.css\",\n   \"~/Content/buttons.dataTables.min.css\",\n   \"~/Content/font-awesome.min.css\",\n   \"~/Content/Site.css\"\n));\n</code></pre>"},{"location":"frontend/bootstrap-update/#tab-view-changes","title":"Tab view changes","text":"<ul> <li>Replace data-toggle with data-bs-toggle: Bootstrap 5 uses data-bs-toggle instead of data-toggle.</li> </ul> <pre><code>&lt;ul class=\"nav nav-tabs\"&gt;\n    &lt;li class=\"nav-item\"&gt;&lt;a class=\"nav-link active\" style=\"font-size:12px;\" data-bs-toggle=\"tab\" href=\"#persTab\"&gt;Personaler&lt;/a&gt;&lt;/li&gt;\n    &lt;li class=\"nav-item\"&gt;&lt;a class=\"nav-link\" style=\"font-size:12px;\" data-bs-toggle=\"tab\" href=\"#fbTab\"&gt;Firmenbetreuer&lt;/a&gt;&lt;/li&gt;\n    &lt;li class=\"nav-item\"&gt;&lt;a class=\"nav-link\" style=\"font-size:12px;\" data-bs-toggle=\"tab\" href=\"#adTab\"&gt;Admins&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n</code></pre> <pre><code>&lt;script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js\"&gt;&lt;/script&gt;\n</code></pre>"},{"location":"frontend/markdown/","title":"Markdown","text":"<p>You can find complete MKDocs Material Documentation here.</p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#text-annotations","title":"Text Annotations","text":"","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#tables","title":"Tables","text":"Left Center Right text centered 123 <pre><code>| Left      | Center     | Right |\n|:----------|:----------:|------:|\n| text      | centered   |   123 |\n| One       | Line1&lt;br&gt;Line2 |\n</code></pre> <ul> <li>Enable the tables markdown extension in <code>mkdocs.yml</code>: <pre><code>markdown_extensions:\n  - tables\n</code></pre></li> </ul>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#nestingindentation","title":"Nesting/Indentation","text":"<ul> <li> <p>Put a blank line before the list block.</p> </li> <li> <p>Use consistent spaces (avoid tabs) and indent nested list items by 4 spaces (safe and compatible).</p> </li> </ul>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#highlight-inner-text","title":"Highlight inner text","text":"<p>Simply write text between <code>``</code></p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#content-tabs","title":"Content Tabs","text":"<p>Just add <code>=== \"TabName\"</code></p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#unordered-list","title":"Unordered List","text":"<p>Just write <code>* Text</code></p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#ordered-list","title":"Ordered List","text":"<p>Just write <code>1. Text</code></p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#admonitioncallout-with-title","title":"Admonition/callout with title","text":"<p>write <code>!!! note/info/abstract/tip/question/success/ warning/failure \"title\"</code> with an indent with four spaces </p> <p>for Collapsible just write <code>???</code> instead of <code>!!!</code> </p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#codeblocks","title":"Codeblocks","text":"","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#plain-codeblock","title":"Plain codeblock","text":"<p>Simply write code block between <code>```</code></p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#codeblock-for-a-specific-language","title":"Codeblock for a specific language","text":"<p>Write the name of the code language after <code>```</code> like py, cshapr, shell, ...</p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#codeblock-with-a-title","title":"Codeblock with a title","text":"<p>Write after <code>```</code>, <code>title=\"bubble_sort.py</code> </p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#with-line-numbers","title":"With line numbers","text":"<p>Write after <code>```</code>, <code>linenums=\"1\"</code> </p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#highlighting-lines","title":"Highlighting lines","text":"<p>Write after <code>```</code>, <code>hl_lines=\"2 3\"</code> or hl_lines=\"1-6\"</p>","tags":["Markdown","Tips","Documentation"]},{"location":"frontend/markdown/#icons-and-emojs","title":"Icons and Emojs","text":"<p>write <code>:smile:</code> for   write <code>:fontawesome-regular-face-laugh-wink:</code> for  write <code>:fontawesome-brands-twitter:{ .twitter }</code> for  write <code>:octicons-heart-fill-24:{ .heart }</code> for  </p>","tags":["Markdown","Tips","Documentation"]},{"location":"sql/col-max-len/","title":"Column Max Length","text":"SQL Server<pre><code>SELECT COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH \nFROM INFORMATION_SCHEMA.COLUMNS \nWHERE TABLE_NAME = 'xxxx';\n</code></pre>"},{"location":"sql/index-frag/","title":"Index Fragmentation","text":"SQL Server<pre><code>SELECT \n    dbschemas.[name] AS [Schema],\n    dbtables.[name] AS [Table],\n    dbindexes.[name] AS [Index],\n    indexstats.avg_fragmentation_in_percent,\n    indexstats.page_count\nFROM \n    sys.dm_db_index_physical_stats(DB_ID(), NULL, NULL, NULL, 'LIMITED') AS indexstats\nINNER JOIN \n    sys.tables dbtables ON indexstats.object_id = dbtables.object_id\nINNER JOIN \n    sys.schemas dbschemas ON dbtables.schema_id = dbschemas.schema_id\nINNER JOIN \n    sys.indexes AS dbindexes ON dbindexes.object_id = indexstats.object_id \n                              AND indexstats.index_id = dbindexes.index_id\nWHERE \n    indexstats.database_id = DB_ID()\n    AND indexstats.page_count &gt; 100 -- skip small indexes\nORDER BY \n    avg_fragmentation_in_percent DESC;\n</code></pre> Fragmentation % Action 0\u20135% No action needed 5\u201330% Reorganize index (light fix) &gt;30% Rebuild index (full fix) *** Reorganize (lightweight)<pre><code>ALTER INDEX [IndexName] ON [TableName] REORGANIZE;\n</code></pre> Rebuild (heavier, can update stats)<pre><code>ALTER INDEX [IndexName] ON [TableName] REBUILD WITH (ONLINE = ON);\n</code></pre>"},{"location":"sql/index-job/","title":"Index Rebuild Job","text":"Job script<pre><code>USE msdb;\nGO\n\n-- Clean up if the job already exists\nIF EXISTS (SELECT 1 FROM msdb.dbo.sysjobs WHERE name = N'IndexMaintenanceJob')\nBEGIN\n    EXEC msdb.dbo.sp_delete_job @job_name = N'IndexMaintenanceJob', @delete_unused_schedule = 1;\nEND\nGO\n\n-- Create the job (initially disabled)\nEXEC msdb.dbo.sp_add_job\n    @job_name = N'IndexMaintenanceJob',\n    @enabled = 0,  -- Job is created as DISABLED\n    @description = N'Maintenance job to rebuild or reorganize indexes in all user databases',\n    @start_step_id = 1;\nGO\n\n-- Define the full job step command\nDECLARE @JobCommand NVARCHAR(MAX);\nSET @JobCommand =N'SET NOCOUNT ON;\n\nDECLARE @dbName SYSNAME;\nDECLARE @sql NVARCHAR(MAX);\n\nDECLARE db_cursor CURSOR FOR\n    SELECT name FROM sys.databases\n    WHERE database_id &gt; 4 AND state_desc = ''ONLINE''; -- Only user databases\n\nOPEN db_cursor;\nFETCH NEXT FROM db_cursor INTO @dbName;\n\nWHILE @@FETCH_STATUS = 0\nBEGIN\n    PRINT ''Processing database: '' + @dbName;\n\n    SET @sql = ''\n    USE ['' + @dbName + ''];\n\n    DECLARE @objectId INT, \n            @indexId INT, \n            @schemaName SYSNAME, \n            @tableName SYSNAME, \n            @indexName SYSNAME, \n            @frag FLOAT, \n            @sqlCmd NVARCHAR(MAX);\n\n    DECLARE index_cursor CURSOR FOR\n        SELECT \n            ips.[object_id], \n            ips.index_id,\n            ips.avg_fragmentation_in_percent,\n            i.name AS index_name,\n            s.name AS schema_name,\n            t.name AS table_name\n        FROM sys.dm_db_index_physical_stats (DB_ID(), NULL, NULL, NULL, ''''LIMITED'''') ips\n        INNER JOIN sys.indexes i ON ips.[object_id] = i.[object_id] AND ips.index_id = i.index_id\n        INNER JOIN sys.tables t ON ips.[object_id] = t.[object_id]\n        INNER JOIN sys.schemas s ON t.schema_id = s.schema_id\n        WHERE ips.index_id &gt; 0 AND ips.alloc_unit_type_desc = ''''IN_ROW_DATA'''';\n\n    OPEN index_cursor;\n    FETCH NEXT FROM index_cursor INTO @objectId, @indexId, @frag, @indexName, @schemaName, @tableName;\n\n    WHILE @@FETCH_STATUS = 0\n    BEGIN\n        SET @sqlCmd = NULL;\n\n        IF @frag &gt;= 30.0\n            SET @sqlCmd = N''''ALTER INDEX ['''' + @indexName + N''''] ON ['''' + @schemaName + N''''].['''' + @tableName + N''''] REBUILD WITH (ONLINE = ON);'''';\n        ELSE IF @frag &gt;= 5.0\n            SET @sqlCmd = N''''ALTER INDEX ['''' + @indexName + N''''] ON ['''' + @schemaName + N''''].['''' + @tableName + N''''] REORGANIZE;'''';\n\n        IF @sqlCmd IS NOT NULL\n        BEGIN\n            PRINT @sqlCmd;\n            EXEC sp_executesql @sqlCmd;\n        END\n\n        FETCH NEXT FROM index_cursor INTO @objectId, @indexId, @frag, @indexName, @schemaName, @tableName;\n    END\n\n    CLOSE index_cursor;\n    DEALLOCATE index_cursor;\n    '';\n\n    EXEC (@sql); -- Switch to database and execute logic\n\n    FETCH NEXT FROM db_cursor INTO @dbName;\nEND\n\nCLOSE db_cursor;\nDEALLOCATE db_cursor;\n'\n\n-- Add the job step\nEXEC msdb.dbo.sp_add_jobstep\n    @job_name = N'IndexMaintenanceJob',\n    @step_name = N'Check and Optimize Indexes',\n    @subsystem = N'TSQL',\n    @command = @JobCommand,\n    @database_name = N'master',\n    @on_success_action = 1, -- Quit with success\n    @on_fail_action = 2;    -- Quit with failure\nGO\n\n-- Create a daily schedule at 02:00 AM\nEXEC msdb.dbo.sp_add_schedule\n    @schedule_name = N'Daily_2AM',\n    @freq_type = 4,              -- daily {4: daily, 8: weekly, 16: Monthly}\n    @freq_interval = 1,          -- every day {every day, Sunday, Day 1 of the month}\n    @freq_recurrence_factor = 2, -- every 2 months\n    @active_start_time = 020000; -- 2:00 AM\nGO\n\n-- Attach schedule to the job\nEXEC msdb.dbo.sp_attach_schedule\n    @job_name = N'IndexMaintenanceJob',\n    @schedule_name = N'Daily_2AM';\nGO\n\n-- Attach the job to the current server\nEXEC msdb.dbo.sp_add_jobserver\n    @job_name = N'IndexMaintenanceJob';\nGO\n</code></pre> Enable Job<pre><code>EXEC msdb.dbo.sp_update_job @job_name = 'IndexMaintenanceJob', @enabled = 1;\n</code></pre> Day Value Sunday 1 Tuesday 2 Wednesday 4 Thursday 8 Friday 16 Saturday 32 Monday 64 These values can also be combined using addition (e.g. Monday + Thursday = 64 + 8 = 72). ***"},{"location":"sql/index-list/","title":"Schema Index List","text":""},{"location":"sql/index-list/#index-list-for-each-schema","title":"Index list for each schema","text":"SQL Server<pre><code>SELECT\n    tablename,\n    indexname,\n    indexdef\nFROM\n    pg_indexes\nWHERE\n    schemaname = 'public'\nORDER BY\n    tablename,\n    indexname;\n</code></pre>"},{"location":"sql/index-rebuild/","title":"Index Rebuild","text":"<ul> <li> <p>Index = NULL \u2192 It's a heap (no clustered index). Rebuild the heap<pre><code>CREATE CLUSTERED INDEX TempIndex ON dbo.YourTable(YourColumn);\nDROP INDEX TempIndex ON dbo.YourTable;\n</code></pre></p> </li> <li> <p>REBUILD WITH (ONLINE = ON)=&gt; Only applies in SQL Server Enterprise edition</p> </li> </ul> Rebuild Indexes of All Tables<pre><code>SET NOCOUNT ON;\n\nDECLARE @dbName SYSNAME;\nDECLARE @sql NVARCHAR(MAX);\n\nDECLARE db_cursor CURSOR FOR\n    SELECT name FROM sys.databases\n    WHERE database_id &gt; 4 AND state_desc = 'ONLINE'; -- Only user databases\n\nOPEN db_cursor;\nFETCH NEXT FROM db_cursor INTO @dbName;\n\nWHILE @@FETCH_STATUS = 0\nBEGIN\n    PRINT 'Processing database: ' + @dbName;\n\n    SET @sql = '\n    USE [' + @dbName + '];\n\n    DECLARE @objectId INT, \n            @indexId INT, \n            @schemaName SYSNAME, \n            @tableName SYSNAME, \n            @indexName SYSNAME, \n            @frag FLOAT, \n            @sqlCmd NVARCHAR(MAX);\n\n    DECLARE index_cursor CURSOR FOR\n        SELECT \n            ips.[object_id], \n            ips.index_id,\n            ips.avg_fragmentation_in_percent,\n            i.name AS index_name,\n            s.name AS schema_name,\n            t.name AS table_name\n        FROM sys.dm_db_index_physical_stats (DB_ID(), NULL, NULL, NULL, ''LIMITED'') ips\n        INNER JOIN sys.indexes i ON ips.[object_id] = i.[object_id] AND ips.index_id = i.index_id\n        INNER JOIN sys.tables t ON ips.[object_id] = t.[object_id]\n        INNER JOIN sys.schemas s ON t.schema_id = s.schema_id\n        WHERE ips.index_id &gt; 0 AND ips.alloc_unit_type_desc = ''IN_ROW_DATA'';\n\n    OPEN index_cursor;\n    FETCH NEXT FROM index_cursor INTO @objectId, @indexId, @frag, @indexName, @schemaName, @tableName;\n\n    WHILE @@FETCH_STATUS = 0\n    BEGIN\n        SET @sqlCmd = NULL;\n\n        IF @frag &gt;= 30.0\n            SET @sqlCmd = N''ALTER INDEX ['' + @indexName + N''] ON ['' + @schemaName + N''].['' + @tableName + N''] REBUILD WITH (ONLINE = ON);'';\n        ELSE IF @frag &gt;= 5.0\n            SET @sqlCmd = N''ALTER INDEX ['' + @indexName + N''] ON ['' + @schemaName + N''].['' + @tableName + N''] REORGANIZE;'';\n\n        IF @sqlCmd IS NOT NULL\n        BEGIN\n            PRINT @sqlCmd;\n            EXEC sp_executesql @sqlCmd;\n        END\n\n        FETCH NEXT FROM index_cursor INTO @objectId, @indexId, @frag, @indexName, @schemaName, @tableName;\n    END\n\n    CLOSE index_cursor;\n    DEALLOCATE index_cursor;\n    ';\n\n    EXEC (@sql); -- Switch to database and execute logic\n\n    FETCH NEXT FROM db_cursor INTO @dbName;\nEND\n\nCLOSE db_cursor;\nDEALLOCATE db_cursor;\n</code></pre> Rebuild Table's Indexes<pre><code>USE [Databasename];\n\nDECLARE @objectId INT, \n        @indexId INT, \n        @schemaName SYSNAME, \n        @tableName SYSNAME, \n        @indexName SYSNAME, \n        @frag FLOAT, \n        @sqlCmd NVARCHAR(MAX);\n\nDECLARE index_cursor CURSOR FOR\n    SELECT \n        ips.[object_id], \n        ips.index_id,\n        ips.avg_fragmentation_in_percent,\n        i.name AS index_name,\n        s.name AS schema_name,\n        t.name AS table_name\n    FROM sys.dm_db_index_physical_stats (DB_ID(), NULL, NULL, NULL, 'LIMITED') ips\n    INNER JOIN sys.indexes i ON ips.[object_id] = i.[object_id] AND ips.index_id = i.index_id\n    INNER JOIN sys.tables t ON ips.[object_id] = t.[object_id]\n    INNER JOIN sys.schemas s ON t.schema_id = s.schema_id\n    WHERE ips.index_id &gt; 0 AND ips.alloc_unit_type_desc = 'IN_ROW_DATA';\n\nOPEN index_cursor;\nFETCH NEXT FROM index_cursor INTO @objectId, @indexId, @frag, @indexName, @schemaName, @tableName;\n\nWHILE @@FETCH_STATUS = 0\nBEGIN\n    SET @sqlCmd = NULL;\n\n    IF @frag &gt;= 30.0\n        SET @sqlCmd = N'ALTER INDEX [' + @indexName + N'] ON [' + @schemaName + N'].[' + @tableName + N'] REBUILD;';\n    ELSE IF @frag &gt;= 5.0\n        SET @sqlCmd = N'ALTER INDEX [' + @indexName + N'] ON [' + @schemaName + N'].[' + @tableName + N'] REORGANIZE;';\n\n    IF @sqlCmd IS NOT NULL\n    BEGIN\n        PRINT @sqlCmd;\n        EXEC sp_executesql @sqlCmd;\n    END\n\n    FETCH NEXT FROM index_cursor INTO @objectId, @indexId, @frag, @indexName, @schemaName, @tableName;\nEND\n\nCLOSE index_cursor;\nDEALLOCATE index_cursor;\n</code></pre>"},{"location":"sql/vol-space/","title":"Vol space","text":"<pre><code>/* Disk space report per volume\n   Requires: VIEW SERVER STATE permission\n*/\nWITH vols AS\n(\n    SELECT DISTINCT\n        vs.volume_mount_point,\n        vs.total_bytes,\n        vs.available_bytes\n    FROM sys.master_files AS mf\n    CROSS APPLY sys.dm_os_volume_stats(mf.database_id, mf.file_id) AS vs\n)\nSELECT\n    CASE \n        WHEN vols.volume_mount_point LIKE '[A-Z]:\\%' \n            THEN LEFT(vols.volume_mount_point, 2)      -- e.g. 'C:'\n        ELSE vols.volume_mount_point                    -- mount path\n    END AS [Drive],\n    CAST(vols.total_bytes     / 1024.0 / 1024.0 / 1024.0 AS DECIMAL(18,2)) AS [TotalSpace],\n    CAST(vols.available_bytes / 1024.0 / 1024.0 / 1024.0 AS DECIMAL(18,2)) AS [FreeSpace],\n    CAST((vols.total_bytes - vols.available_bytes) / 1024.0 / 1024.0 / 1024.0 AS DECIMAL(18,2)) AS [UsedSpace],\n    CAST(((vols.total_bytes - vols.available_bytes) * 100.0 / vols.total_bytes) AS DECIMAL(5,2)) AS [UsedPercentage],\n    CAST((vols.available_bytes * 100.0 / vols.total_bytes) AS DECIMAL(5,2)) AS [FreePercentage],\n    CASE \n        WHEN (vols.available_bytes * 100.0 / vols.total_bytes) &lt; 10 THEN 'Low'\n        WHEN (vols.available_bytes * 100.0 / vols.total_bytes) &lt; 20 THEN 'Warn'\n        ELSE 'Good'\n    END AS [Status]\nFROM vols\nORDER BY [Drive];\n</code></pre> <pre><code>GRANT VIEW SERVER STATE TO [YourLogin];\n</code></pre>"},{"location":"test/performance/","title":"Performance Tools","text":""},{"location":"test/performance/#load-test-bombardier","title":"Load Test - Bombardier","text":"<p>Bombardier is a HTTP(S) benchmarking tool. It is written in Go programming language and uses excellent FastHTTP instead of Go's default http library, because of its lightning fast performance.</p> Install<pre><code>go install github.com/codesenberg/bombardier@latest\n</code></pre> Usage (500 requests using 50 connections and latency distribution)<pre><code>bombardier [&lt;flags&gt;] &lt;url&gt;\nbombardier -c 50 -n 500 -d 10s -l http://localhost:5005\n</code></pre>"},{"location":"test/performance/#get-process-id","title":"Get Process ID","text":"<pre><code>tasklist /fi \"IMAGENAME eq AsyncTest.exe\"\n</code></pre>"},{"location":"test/performance/#dotnet-counters","title":"dotnet-counters","text":"<pre><code>dotnet-counters monitor --process-id [36541] --counters System.Runtime[threadpool-thhread-count, threadpool-queue-length, monitor-lock-connection-count] --output counters.txt\n</code></pre>"},{"location":"test/performance/#sql-server-connections","title":"SQL Server Connections","text":"<pre><code>SELECT  dbid, DB_NAME(dbid) AS DatabaseName, COUNT(dbid) AS NumberOfConnections\n        FROM sys.sysprocess\n        WHERE DB_NAME(dbid) = 'TestDB'\n        GROUP BY dbid     \n</code></pre>"}]}